{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |default_exp training\n",
    "# |default_cls_lvl 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training\n",
    "\n",
    "Classes and methods for uniformly training, saving, and tuning our topic segmentation and summarization models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "from __future__ import annotations\n",
    "\n",
    "import abc, inspect, os\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import optuna\n",
    "import wandb\n",
    "\n",
    "from course_copilot import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import pdb\n",
    "\n",
    "from fastcore.test import *\n",
    "import nbdev\n",
    "\n",
    "from blurr.utils import print_versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What we're running with at the time this documentation was generated:\n",
      "torch: 1.12.1+cu102\n",
      "fastai: 2.7.9\n",
      "transformers: 4.22.0\n",
      "blurr: 1.0.5\n"
     ]
    }
   ],
   "source": [
    "# | echo: false\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "print(\"What we're running with at the time this documentation was generated:\")\n",
    "print_versions(\"torch fastai transformers blurr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "class TrainConfig:\n",
    "    \"\"\"This class defines a base class for each task to implement. Contains class properties relevant to the training process\"\"\"\n",
    "\n",
    "    training_subset = 1.0\n",
    "    val_pct = 0.25\n",
    "    random_seed = 2022\n",
    "    only_seed_splits = True\n",
    "    preprocess_strategy = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def get_train_config_props(cfg: TrainConfig) -> dict:\n",
    "    \"\"\"Returns a dictionary of all the class properties in `cfg`\"\"\"\n",
    "    log_params = {k: v if not callable(v) else v.__name__ for k, v in inspect.getmembers(cfg) if not k.startswith(\"__\")}\n",
    "    return log_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'only_seed_splits': True,\n",
       " 'preprocess_strategy': None,\n",
       " 'random_seed': 2022,\n",
       " 'training_subset': 1.0,\n",
       " 'val_pct': 0.25}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_train_config_props(TrainConfig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class ModelTrainer(abc.ABC):\n",
    "    def __init__(\n",
    "        self,\n",
    "        # The ML task to run (e.g., topic_segmentation, summarization)\n",
    "        task: str,\n",
    "        # The name of your experiment (e.g., deberta_v3_large). This value is used in conjunction with `task` when\n",
    "        # logging information with W&B or else saving data releveant to training/evaluation runs\n",
    "        experiment_name: str,\n",
    "        # The `TrainConfig` for your task\n",
    "        train_config: TrainConfig,\n",
    "        # Where the project's data is stored\n",
    "        data_path: str = \"data\",\n",
    "        # Where exported Learners and other models should stored\n",
    "        model_output_path: str = \"models\",\n",
    "        # Where any logged data should be stored\n",
    "        log_output_path: str = \"logs\",\n",
    "        # Whether predictions should be logged\n",
    "        log_preds: bool = False,\n",
    "        # The number of predictions that should be logged. It is left to each subclass to define what that means\n",
    "        log_n_preds: int = None,\n",
    "        # Whether or not to log experiments and sweeps to W&B\n",
    "        use_wandb: bool = False,\n",
    "        # Whether or not you want to have printed out everything during a training/evaulation run\n",
    "        verbose: bool = False,\n",
    "        # Any other kwargs you want to use in your ModelTrainer\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.task = task\n",
    "        self.experiment_name = experiment_name\n",
    "        self.train_config = train_config\n",
    "\n",
    "        self.data_path = Path(data_path)\n",
    "\n",
    "        self.model_output_path = Path(model_output_path)\n",
    "        self.model_output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        self.log_output_path = Path(log_output_path)\n",
    "        self.log_output_path.mkdir(parents=True, exist_ok=True)\n",
    "        self.log_preds = log_preds\n",
    "        self.log_n_preds = log_n_preds\n",
    "\n",
    "        self.use_wandb = use_wandb\n",
    "        if self.use_wandb:\n",
    "            wandb.login()\n",
    "\n",
    "        self.verbose = verbose\n",
    "\n",
    "    # --- training ---\n",
    "    @abc.abstractmethod\n",
    "    def get_training_data(self, on_the_fly=False, split_type=\"cross_validation\"):\n",
    "        pass\n",
    "\n",
    "    def train(self, sweep_config: dict = None):\n",
    "        if self.use_wandb and sweep_config is None:\n",
    "            wandb.finish(quiet=not self.verbose)\n",
    "\n",
    "    # --- inference ---\n",
    "    def load_learner_or_model(self, model_learner_fpath: str | Path = None, device=\"cpu\", mode=\"eval\"):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def get_preds(self, model_or_learner, data, **kwargs):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    # --- wandb ---\n",
    "    def init_wandb_run(self, is_sweep: bool = False):\n",
    "        run = wandb.init(\n",
    "            project=f\"{os.environ['WANDB_PROJECT_NAME']}-{self.task}\",\n",
    "            entity=os.environ[\"WANDB_TEAM\"],\n",
    "            group=f\"{self.experiment_name}_sweep\" if is_sweep else self.experiment_name,\n",
    "            config=get_train_config_props(self.train_config),\n",
    "            dir=self.log_output_path,\n",
    "            reinit=True,\n",
    "        )\n",
    "\n",
    "        return run\n",
    "\n",
    "    def configure_sweep(self, sweep_config: dict = None):\n",
    "        sweep_id = wandb.sweep(\n",
    "            sweep=sweep_config,\n",
    "            project=f\"{os.environ['WANDB_PROJECT_NAME']}-{self.task}\",\n",
    "            entity=os.environ[\"WANDB_TEAM\"],\n",
    "        )\n",
    "        return sweep_id\n",
    "\n",
    "    def update_train_config_from_sweep_params(self, params_d: dict):\n",
    "        pass\n",
    "        for k, v in params_d.items():\n",
    "            if hasattr(self.train_config, k):\n",
    "                setattr(self.train_config, k, wandb.config[k])\n",
    "\n",
    "    # --- utility ---\n",
    "    def get_train_config_props(self):\n",
    "        return get_train_config_props(self.train_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('fsdl_2022_course_project')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
