{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/team_007/mambaforge/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "from pathlib import Path\n",
    "\n",
    "from fastai.vision.all import *\n",
    "import torch\n",
    "\n",
    "from course_copilot import transcription, topic_segmentation, summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_id = \"Jsz4E2iNXUA\"\n",
    "device = \"cuda\"\n",
    "\n",
    "audio_files_fpath = Path(\"../../transcription/audio_files\")\n",
    "transcription_fpath = Path(\"../../transcription/transcriptions\")\n",
    "whisper_models_fpath = Path(\"../../transcription/models\")\n",
    "\n",
    "whisper_model = \"base\"\n",
    "topic_segmentation_learner_fpath = \"../../models/topic_segmentation_deberta_v3_small.pkl\"\n",
    "headline_summarization_learner_fpath = \"../../models/headline_summarization.pkl\"\n",
    "content_summarization_learner_fpath = \"../../models/content_summarization.pkl\"\n",
    "\n",
    "# smaller = more fine grained topics (more topics predicted) while larger values = less fine grained (less topics predicted)\n",
    "topic_segmentation_get_preds_kwargs = {\"threshold_std_coeff\": 1.9}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>elapsed_seconds</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>00:00:00.000</td>\n",
       "      <td>Let me make sure everything is as it should be.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.56</td>\n",
       "      <td>00:00:03.560</td>\n",
       "      <td>I'm always fascinated by the fact that people are waiting.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.72</td>\n",
       "      <td>00:00:06.720</td>\n",
       "      <td>It's like it's it's so surprising that people are like on here</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.70</td>\n",
       "      <td>00:00:12.700</td>\n",
       "      <td>sometimes early for you.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.12</td>\n",
       "      <td>00:00:14.120</td>\n",
       "      <td>It makes sense for my session.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   elapsed_seconds     timestamp  \\\n",
       "0             0.00  00:00:00.000   \n",
       "1             3.56  00:00:03.560   \n",
       "2             6.72  00:00:06.720   \n",
       "3            12.70  00:00:12.700   \n",
       "4            14.12  00:00:14.120   \n",
       "\n",
       "                                                       transcript  \n",
       "0                 Let me make sure everything is as it should be.  \n",
       "1      I'm always fascinated by the fact that people are waiting.  \n",
       "2  It's like it's it's so surprising that people are like on here  \n",
       "3                                        sometimes early for you.  \n",
       "4                                  It makes sense for my session.  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_fpath = transcription.fetch_youtube_audio(youtube_id, audio_files_fpath=audio_files_fpath)\n",
    "\n",
    "transcription_fpath = transcription.fetch_transcription(\n",
    "    audio_fpath=audio_fpath,\n",
    "    transcription_fpath=transcription_fpath,\n",
    "    model_fpath=whisper_models_fpath,\n",
    "    model_checkptoint=whisper_model,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "transcription_df = transcription.transcription_to_df(transcription_fpath)\n",
    "transcription_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(633, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcription_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# predicted topics:  41\n",
      "[0, 44, 133, 139, 151, 156, 161, 166, 169, 177]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>elapsed_seconds</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>transcript</th>\n",
       "      <th>depth_score</th>\n",
       "      <th>threshold</th>\n",
       "      <th>pred_start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>00:00:00.000</td>\n",
       "      <td>Let me make sure everything is as it should be.</td>\n",
       "      <td>0.006972</td>\n",
       "      <td>0.022045</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.56</td>\n",
       "      <td>00:00:03.560</td>\n",
       "      <td>I'm always fascinated by the fact that people are waiting.</td>\n",
       "      <td>0.004309</td>\n",
       "      <td>0.022045</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.72</td>\n",
       "      <td>00:00:06.720</td>\n",
       "      <td>It's like it's it's so surprising that people are like on here</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022045</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.70</td>\n",
       "      <td>00:00:12.700</td>\n",
       "      <td>sometimes early for you.</td>\n",
       "      <td>0.003844</td>\n",
       "      <td>0.022045</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.12</td>\n",
       "      <td>00:00:14.120</td>\n",
       "      <td>It makes sense for my session.</td>\n",
       "      <td>0.005018</td>\n",
       "      <td>0.022045</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   elapsed_seconds     timestamp  \\\n",
       "0             0.00  00:00:00.000   \n",
       "1             3.56  00:00:03.560   \n",
       "2             6.72  00:00:06.720   \n",
       "3            12.70  00:00:12.700   \n",
       "4            14.12  00:00:14.120   \n",
       "\n",
       "                                                       transcript  \\\n",
       "0                 Let me make sure everything is as it should be.   \n",
       "1      I'm always fascinated by the fact that people are waiting.   \n",
       "2  It's like it's it's so surprising that people are like on here   \n",
       "3                                        sometimes early for you.   \n",
       "4                                  It makes sense for my session.   \n",
       "\n",
       "   depth_score  threshold  pred_start  \n",
       "0     0.006972   0.022045        True  \n",
       "1     0.004309   0.022045       False  \n",
       "2     0.000000   0.022045       False  \n",
       "3     0.003844   0.022045       False  \n",
       "4     0.005018   0.022045       False  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_segmentation_trainer = topic_segmentation.TopicSegmentationModelTrainer(\n",
    "    experiment_name=\"deberta_v3_small\", train_config=topic_segmentation.TopicSegmentationConfig\n",
    ")\n",
    "# results_df, train_df, val_idxs = trainer.train()\n",
    "inf_learn = topic_segmentation_trainer.load_learner_or_model(\n",
    "    model_learner_fpath=topic_segmentation_learner_fpath, device=device\n",
    ")\n",
    "\n",
    "topic_seg_preds_df, pred_topic_idxs = topic_segmentation_trainer.get_preds(\n",
    "    inf_learn, transcription_df.copy(), **topic_segmentation_get_preds_kwargs\n",
    ")\n",
    "\n",
    "# cleanup resources\n",
    "del inf_learn\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "# shows final results\n",
    "print(\"# predicted topics: \", len(pred_topic_idxs))\n",
    "print(pred_topic_idxs[:10])\n",
    "topic_seg_preds_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_num</th>\n",
       "      <th>elapsed_seconds</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 3.56, 6.72, 12.7, 14.12, 15.24, 22.72, 23.2, 25.08, 25.68, 26.96, 27.8, 28.8, 30.28, 32.04, 36.6, 39.12, 42.4, 44.96, 47.44, 51.92, 54.68, 60.64, 63.28, 66.76, 70.56, 71.24, 72.8, 73.56, 74.0, 75.16, 78.2, 80.16, 85.56, 93.75999999999999, 94.75999999999999, 106.16, 128.04, 129.24, 133.0, 140.68, 141.68, 149.88, 152.84]</td>\n",
       "      <td>00:00:00.000</td>\n",
       "      <td>Let me make sure everything is as it should be. I'm always fascinated by the fact that people are waiting. It's like it's it's so surprising that people are like on here sometimes early for you. It makes sense for my session. I'm like why are people joining? Awesome. I believe we live. Welcome back. Everyone wait is back. He wasn't well. Last week. Now he's in awesome health. So that's I was happy to hear that. And I hope you are as well because he'll be teaching us how to translate stuff and how to summarize models. If I can learn this from him, I'll take his model and deploy it on my pod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[153.92000000000002, 155.52, 162.44, 163.88, 169.44, 175.52, 176.6, 181.56, 184.76, 189.92, 192.4, 193.84, 196.68, 200.56, 206.68, 208.56, 211.76, 214.28, 220.44, 221.88, 224.92000000000002, 225.88, 229.52, 231.8, 235.28, 239.04, 242.64, 246.0, 249.12, 253.32, 255.96, 257.72, 259.56, 264.6, 270.12, 273.84000000000003, 279.08, 285.32, 287.0, 292.64, 293.08, 294.88, 295.88, 299.28, 301.52, 312.64, 314.68, 316.08, 318.0, 320.4, 324.4, 330.36, 333.68, 336.92, 337.76, 341.72, 345.92, 346.56, 350.76, 352.72, 355.88, 358.56, 359.48, 364.36, 364.88, 366.04, 366.52, 367.04, 368.44, 369.92, 373.48, ...</td>\n",
       "      <td>00:02:33.920</td>\n",
       "      <td>In the meantime, I can talk about tricks. I've been trying to learn different tricks shared across NLP, computer vision world. I found out the augmentee library by the space group. Let's see if I can find that up. Here it is. So let's see link to it. I found that to be quite interesting. And a few things I've been trying to learn in the meantime is NLP augmentations. As you can see, I learned a cool trick called pack translation. I'm sure everyone knows of it. But when you're trying to perform augmentation, you can translate your original text to foreign language, translate it back. And ju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[430.4, 434.04, 438.68, 442.0, 444.52, 447.88]</td>\n",
       "      <td>00:07:10.400</td>\n",
       "      <td>And there's minor differences between building a summarization versus a translation model, especially in terms of the metrics that you're going to want to use. So we're going to kind of go through our seven steps that we've used for looking at question answering task, and also looking at the token classification task.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[454.2, 457.08, 462.92, 467.6, 471.68, 475.24, 476.48, 479.64, 480.8, 484.44, 486.96, 489.08]</td>\n",
       "      <td>00:07:34.200</td>\n",
       "      <td>And along the way, we'll talk about a little bit deeper into model selection and also metrics selection. So as you know, when you're actually building a model, the loss is kind of the models way, the models metric, that it understands in terms of improving the quality of your weights. But from a human perspective, what we really care about is metrics. And so regardless of what you're doing, and in particular, when we look at summarization and translation, the metrics that we're going to want to use are going to be different for these tasks.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[492.88, 495.56, 498.68, 502.6, 506.68]</td>\n",
       "      <td>00:08:12.880</td>\n",
       "      <td>And we want to make sure that we're using metrics that are in line with whatever our objectives are, and also with the data set that we're using. So we'll take a look at that in a little bit more detail. And also, I have a note here on this particular slide</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic_num  \\\n",
       "0          0   \n",
       "1          1   \n",
       "2          2   \n",
       "3          3   \n",
       "4          4   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           elapsed_seconds  \\\n",
       "0                                                                                                                                                                                                                                                                                   [0.0, 3.56, 6.72, 12.7, 14.12, 15.24, 22.72, 23.2, 25.08, 25.68, 26.96, 27.8, 28.8, 30.28, 32.04, 36.6, 39.12, 42.4, 44.96, 47.44, 51.92, 54.68, 60.64, 63.28, 66.76, 70.56, 71.24, 72.8, 73.56, 74.0, 75.16, 78.2, 80.16, 85.56, 93.75999999999999, 94.75999999999999, 106.16, 128.04, 129.24, 133.0, 140.68, 141.68, 149.88, 152.84]   \n",
       "1  [153.92000000000002, 155.52, 162.44, 163.88, 169.44, 175.52, 176.6, 181.56, 184.76, 189.92, 192.4, 193.84, 196.68, 200.56, 206.68, 208.56, 211.76, 214.28, 220.44, 221.88, 224.92000000000002, 225.88, 229.52, 231.8, 235.28, 239.04, 242.64, 246.0, 249.12, 253.32, 255.96, 257.72, 259.56, 264.6, 270.12, 273.84000000000003, 279.08, 285.32, 287.0, 292.64, 293.08, 294.88, 295.88, 299.28, 301.52, 312.64, 314.68, 316.08, 318.0, 320.4, 324.4, 330.36, 333.68, 336.92, 337.76, 341.72, 345.92, 346.56, 350.76, 352.72, 355.88, 358.56, 359.48, 364.36, 364.88, 366.04, 366.52, 367.04, 368.44, 369.92, 373.48, ...   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           [430.4, 434.04, 438.68, 442.0, 444.52, 447.88]   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            [454.2, 457.08, 462.92, 467.6, 471.68, 475.24, 476.48, 479.64, 480.8, 484.44, 486.96, 489.08]   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  [492.88, 495.56, 498.68, 502.6, 506.68]   \n",
       "\n",
       "      timestamp  \\\n",
       "0  00:00:00.000   \n",
       "1  00:02:33.920   \n",
       "2  00:07:10.400   \n",
       "3  00:07:34.200   \n",
       "4  00:08:12.880   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                transcript  \n",
       "0  Let me make sure everything is as it should be. I'm always fascinated by the fact that people are waiting. It's like it's it's so surprising that people are like on here sometimes early for you. It makes sense for my session. I'm like why are people joining? Awesome. I believe we live. Welcome back. Everyone wait is back. He wasn't well. Last week. Now he's in awesome health. So that's I was happy to hear that. And I hope you are as well because he'll be teaching us how to translate stuff and how to summarize models. If I can learn this from him, I'll take his model and deploy it on my pod...  \n",
       "1  In the meantime, I can talk about tricks. I've been trying to learn different tricks shared across NLP, computer vision world. I found out the augmentee library by the space group. Let's see if I can find that up. Here it is. So let's see link to it. I found that to be quite interesting. And a few things I've been trying to learn in the meantime is NLP augmentations. As you can see, I learned a cool trick called pack translation. I'm sure everyone knows of it. But when you're trying to perform augmentation, you can translate your original text to foreign language, translate it back. And ju...  \n",
       "2                                                                                                                                                                                                                                                                                          And there's minor differences between building a summarization versus a translation model, especially in terms of the metrics that you're going to want to use. So we're going to kind of go through our seven steps that we've used for looking at question answering task, and also looking at the token classification task.  \n",
       "3                                                       And along the way, we'll talk about a little bit deeper into model selection and also metrics selection. So as you know, when you're actually building a model, the loss is kind of the models way, the models metric, that it understands in terms of improving the quality of your weights. But from a human perspective, what we really care about is metrics. And so regardless of what you're doing, and in particular, when we look at summarization and translation, the metrics that we're going to want to use are going to be different for these tasks.  \n",
       "4                                                                                                                                                                                                                                                                                                                                                        And we want to make sure that we're using metrics that are in line with whatever our objectives are, and also with the data set that we're using. So we'll take a look at that in a little bit more detail. And also, I have a note here on this particular slide  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarization_inf_df = topic_seg_preds_df.copy()\n",
    "\n",
    "summarization_inf_df[\"topic_num\"] = -1\n",
    "n_topics = len(pred_topic_idxs)\n",
    "\n",
    "for i, seg_idx in enumerate(pred_topic_idxs):\n",
    "    end_idx = pred_topic_idxs[i + 1] if i + 1 <= (n_topics - 1) else None\n",
    "    summarization_inf_df.loc[seg_idx:end_idx, \"topic_num\"] = i\n",
    "\n",
    "summarization_inf_df = summarization_inf_df.groupby(by=\"topic_num\").agg(list).reset_index()\n",
    "summarization_inf_df[\"transcript\"] = summarization_inf_df[\"transcript\"].apply(\n",
    "    lambda v: \" \".join([str(seq) for seq in v])\n",
    ")\n",
    "summarization_inf_df.timestamp = summarization_inf_df.timestamp.apply(lambda v: v[0])\n",
    "summarization_inf_df.drop(columns=[\"depth_score\", \"threshold\", \"pred_start\"], inplace=True)\n",
    "\n",
    "summarization_inf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarization_inf_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Kurian to add his magic here after he adds his models to /models ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30min 4s, sys: 4min 43s, total: 34min 47s\n",
      "Wall time: 29.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "headline_trainer = summarization.SummarizationModelTrainer(\n",
    "    task=\"inference\", experiment_name=\"headline_summarization\", train_config=summarization.HeadlineSummarizationConfig\n",
    ")\n",
    "inf_learn = headline_trainer.load_learner_or_model(headline_summarization_learner_fpath, device=\"cpu\")\n",
    "headling_preds_df = headline_trainer.get_preds(inf_learn, summarization_inf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_num</th>\n",
       "      <th>elapsed_seconds</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>transcript</th>\n",
       "      <th>topic_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 3.56, 6.72, 12.7, 14.12, 15.24, 22.72, 23.2, 25.08, 25.68, 26.96, 27.8, 28.8, 30.28, 32.04, 36.6, 39.12, 42.4, 44.96, 47.44, 51.92, 54.68, 60.64, 63.28, 66.76, 70.56, 71.24, 72.8, 73.56, 74.0, 75.16, 78.2, 80.16, 85.56, 93.75999999999999, 94.75999999999999, 106.16, 128.04, 129.24, 133.0, 140.68, 141.68, 149.88, 152.84]</td>\n",
       "      <td>00:00:00.000</td>\n",
       "      <td>Let me make sure everything is as it should be. I'm always fascinated by the fact that people are waiting. It's like it's it's so surprising that people are like on here sometimes early for you. It makes sense for my session. I'm like why are people joining? Awesome. I believe we live. Welcome back. Everyone wait is back. He wasn't well. Last week. Now he's in awesome health. So that's I was happy to hear that. And I hope you are as well because he'll be teaching us how to translate stuff and how to summarize models. If I can learn this from him, I'll take his model and deploy it on my pod...</td>\n",
       "      <td>This week'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[153.92000000000002, 155.52, 162.44, 163.88, 169.44, 175.52, 176.6, 181.56, 184.76, 189.92, 192.4, 193.84, 196.68, 200.56, 206.68, 208.56, 211.76, 214.28, 220.44, 221.88, 224.92000000000002, 225.88, 229.52, 231.8, 235.28, 239.04, 242.64, 246.0, 249.12, 253.32, 255.96, 257.72, 259.56, 264.6, 270.12, 273.84000000000003, 279.08, 285.32, 287.0, 292.64, 293.08, 294.88, 295.88, 299.28, 301.52, 312.64, 314.68, 316.08, 318.0, 320.4, 324.4, 330.36, 333.68, 336.92, 337.76, 341.72, 345.92, 346.56, 350.76, 352.72, 355.88, 358.56, 359.48, 364.36, 364.88, 366.04, 366.52, 367.04, 368.44, 369.92, 373.48, ...</td>\n",
       "      <td>00:02:33.920</td>\n",
       "      <td>In the meantime, I can talk about tricks. I've been trying to learn different tricks shared across NLP, computer vision world. I found out the augmentee library by the space group. Let's see if I can find that up. Here it is. So let's see link to it. I found that to be quite interesting. And a few things I've been trying to learn in the meantime is NLP augmentations. As you can see, I learned a cool trick called pack translation. I'm sure everyone knows of it. But when you're trying to perform augmentation, you can translate your original text to foreign language, translate it back. And ju...</td>\n",
       "      <td>This is the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[430.4, 434.04, 438.68, 442.0, 444.52, 447.88]</td>\n",
       "      <td>00:07:10.400</td>\n",
       "      <td>And there's minor differences between building a summarization versus a translation model, especially in terms of the metrics that you're going to want to use. So we're going to kind of go through our seven steps that we've used for looking at question answering task, and also looking at the token classification task.</td>\n",
       "      <td>We've</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[454.2, 457.08, 462.92, 467.6, 471.68, 475.24, 476.48, 479.64, 480.8, 484.44, 486.96, 489.08]</td>\n",
       "      <td>00:07:34.200</td>\n",
       "      <td>And along the way, we'll talk about a little bit deeper into model selection and also metrics selection. So as you know, when you're actually building a model, the loss is kind of the models way, the models metric, that it understands in terms of improving the quality of your weights. But from a human perspective, what we really care about is metrics. And so regardless of what you're doing, and in particular, when we look at summarization and translation, the metrics that we're going to want to use are going to be different for these tasks.</td>\n",
       "      <td>Models and metrics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[492.88, 495.56, 498.68, 502.6, 506.68]</td>\n",
       "      <td>00:08:12.880</td>\n",
       "      <td>And we want to make sure that we're using metrics that are in line with whatever our objectives are, and also with the data set that we're using. So we'll take a look at that in a little bit more detail. And also, I have a note here on this particular slide</td>\n",
       "      <td>metrics in line</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic_num  \\\n",
       "0          0   \n",
       "1          1   \n",
       "2          2   \n",
       "3          3   \n",
       "4          4   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           elapsed_seconds  \\\n",
       "0                                                                                                                                                                                                                                                                                   [0.0, 3.56, 6.72, 12.7, 14.12, 15.24, 22.72, 23.2, 25.08, 25.68, 26.96, 27.8, 28.8, 30.28, 32.04, 36.6, 39.12, 42.4, 44.96, 47.44, 51.92, 54.68, 60.64, 63.28, 66.76, 70.56, 71.24, 72.8, 73.56, 74.0, 75.16, 78.2, 80.16, 85.56, 93.75999999999999, 94.75999999999999, 106.16, 128.04, 129.24, 133.0, 140.68, 141.68, 149.88, 152.84]   \n",
       "1  [153.92000000000002, 155.52, 162.44, 163.88, 169.44, 175.52, 176.6, 181.56, 184.76, 189.92, 192.4, 193.84, 196.68, 200.56, 206.68, 208.56, 211.76, 214.28, 220.44, 221.88, 224.92000000000002, 225.88, 229.52, 231.8, 235.28, 239.04, 242.64, 246.0, 249.12, 253.32, 255.96, 257.72, 259.56, 264.6, 270.12, 273.84000000000003, 279.08, 285.32, 287.0, 292.64, 293.08, 294.88, 295.88, 299.28, 301.52, 312.64, 314.68, 316.08, 318.0, 320.4, 324.4, 330.36, 333.68, 336.92, 337.76, 341.72, 345.92, 346.56, 350.76, 352.72, 355.88, 358.56, 359.48, 364.36, 364.88, 366.04, 366.52, 367.04, 368.44, 369.92, 373.48, ...   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           [430.4, 434.04, 438.68, 442.0, 444.52, 447.88]   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            [454.2, 457.08, 462.92, 467.6, 471.68, 475.24, 476.48, 479.64, 480.8, 484.44, 486.96, 489.08]   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  [492.88, 495.56, 498.68, 502.6, 506.68]   \n",
       "\n",
       "      timestamp  \\\n",
       "0  00:00:00.000   \n",
       "1  00:02:33.920   \n",
       "2  00:07:10.400   \n",
       "3  00:07:34.200   \n",
       "4  00:08:12.880   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                transcript  \\\n",
       "0  Let me make sure everything is as it should be. I'm always fascinated by the fact that people are waiting. It's like it's it's so surprising that people are like on here sometimes early for you. It makes sense for my session. I'm like why are people joining? Awesome. I believe we live. Welcome back. Everyone wait is back. He wasn't well. Last week. Now he's in awesome health. So that's I was happy to hear that. And I hope you are as well because he'll be teaching us how to translate stuff and how to summarize models. If I can learn this from him, I'll take his model and deploy it on my pod...   \n",
       "1  In the meantime, I can talk about tricks. I've been trying to learn different tricks shared across NLP, computer vision world. I found out the augmentee library by the space group. Let's see if I can find that up. Here it is. So let's see link to it. I found that to be quite interesting. And a few things I've been trying to learn in the meantime is NLP augmentations. As you can see, I learned a cool trick called pack translation. I'm sure everyone knows of it. But when you're trying to perform augmentation, you can translate your original text to foreign language, translate it back. And ju...   \n",
       "2                                                                                                                                                                                                                                                                                          And there's minor differences between building a summarization versus a translation model, especially in terms of the metrics that you're going to want to use. So we're going to kind of go through our seven steps that we've used for looking at question answering task, and also looking at the token classification task.   \n",
       "3                                                       And along the way, we'll talk about a little bit deeper into model selection and also metrics selection. So as you know, when you're actually building a model, the loss is kind of the models way, the models metric, that it understands in terms of improving the quality of your weights. But from a human perspective, what we really care about is metrics. And so regardless of what you're doing, and in particular, when we look at summarization and translation, the metrics that we're going to want to use are going to be different for these tasks.   \n",
       "4                                                                                                                                                                                                                                                                                                                                                        And we want to make sure that we're using metrics that are in line with whatever our objectives are, and also with the data set that we're using. So we'll take a look at that in a little bit more detail. And also, I have a note here on this particular slide   \n",
       "\n",
       "     topic_prediction  \n",
       "0          This week'  \n",
       "1         This is the  \n",
       "2               We've  \n",
       "3  Models and metrics  \n",
       "4     metrics in line  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headling_preds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 57min, sys: 7min 20s, total: 2h 4min 20s\n",
      "Wall time: 1min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "content_trainer = summarization.SummarizationModelTrainer(\n",
    "    task=\"inference\", experiment_name=\"content_summarization\", train_config=summarization.ContentSummarizationConfig\n",
    ")\n",
    "inf_learn = content_trainer.load_learner_or_model(content_summarization_learner_fpath, device=\"cpu\")\n",
    "content_preds_df = content_trainer.get_preds(inf_learn, headling_preds_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_num</th>\n",
       "      <th>elapsed_seconds</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>transcript</th>\n",
       "      <th>topic_prediction</th>\n",
       "      <th>content_highlights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 3.56, 6.72, 12.7, 14.12, 15.24, 22.72, 23.2, 25.08, 25.68, 26.96, 27.8, 28.8, 30.28, 32.04, 36.6, 39.12, 42.4, 44.96, 47.44, 51.92, 54.68, 60.64, 63.28, 66.76, 70.56, 71.24, 72.8, 73.56, 74.0, 75.16, 78.2, 80.16, 85.56, 93.75999999999999, 94.75999999999999, 106.16, 128.04, 129.24, 133.0, 140.68, 141.68, 149.88, 152.84]</td>\n",
       "      <td>00:00:00.000</td>\n",
       "      <td>Let me make sure everything is as it should be. I'm always fascinated by the fact that people are waiting. It's like it's it's so surprising that people are like on here sometimes early for you. It makes sense for my session. I'm like why are people joining? Awesome. I believe we live. Welcome back. Everyone wait is back. He wasn't well. Last week. Now he's in awesome health. So that's I was happy to hear that. And I hope you are as well because he'll be teaching us how to translate stuff and how to summarize models. If I can learn this from him, I'll take his model and deploy it on my pod...</td>\n",
       "      <td>This week'</td>\n",
       "      <td>This week's show is the second day of the show . I'm excited to learn how to translate stuff and summarize models . I'll take his model and deploy it on my podcast .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[153.92000000000002, 155.52, 162.44, 163.88, 169.44, 175.52, 176.6, 181.56, 184.76, 189.92, 192.4, 193.84, 196.68, 200.56, 206.68, 208.56, 211.76, 214.28, 220.44, 221.88, 224.92000000000002, 225.88, 229.52, 231.8, 235.28, 239.04, 242.64, 246.0, 249.12, 253.32, 255.96, 257.72, 259.56, 264.6, 270.12, 273.84000000000003, 279.08, 285.32, 287.0, 292.64, 293.08, 294.88, 295.88, 299.28, 301.52, 312.64, 314.68, 316.08, 318.0, 320.4, 324.4, 330.36, 333.68, 336.92, 337.76, 341.72, 345.92, 346.56, 350.76, 352.72, 355.88, 358.56, 359.48, 364.36, 364.88, 366.04, 366.52, 367.04, 368.44, 369.92, 373.48, ...</td>\n",
       "      <td>00:02:33.920</td>\n",
       "      <td>In the meantime, I can talk about tricks. I've been trying to learn different tricks shared across NLP, computer vision world. I found out the augmentee library by the space group. Let's see if I can find that up. Here it is. So let's see link to it. I found that to be quite interesting. And a few things I've been trying to learn in the meantime is NLP augmentations. As you can see, I learned a cool trick called pack translation. I'm sure everyone knows of it. But when you're trying to perform augmentation, you can translate your original text to foreign language, translate it back. And ju...</td>\n",
       "      <td>This is the</td>\n",
       "      <td>This is the fifth session of our walkthrough of the Part 2, the Hugging Faced Course . This is the fifth session of our walkthrough of the Part 2, the Hugging Faced Course .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[430.4, 434.04, 438.68, 442.0, 444.52, 447.88]</td>\n",
       "      <td>00:07:10.400</td>\n",
       "      <td>And there's minor differences between building a summarization versus a translation model, especially in terms of the metrics that you're going to want to use. So we're going to kind of go through our seven steps that we've used for looking at question answering task, and also looking at the token classification task.</td>\n",
       "      <td>We've</td>\n",
       "      <td>We're going to kind of go through the seven steps that we've used to look at question answering task, and also the token classification task .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[454.2, 457.08, 462.92, 467.6, 471.68, 475.24, 476.48, 479.64, 480.8, 484.44, 486.96, 489.08]</td>\n",
       "      <td>00:07:34.200</td>\n",
       "      <td>And along the way, we'll talk about a little bit deeper into model selection and also metrics selection. So as you know, when you're actually building a model, the loss is kind of the models way, the models metric, that it understands in terms of improving the quality of your weights. But from a human perspective, what we really care about is metrics. And so regardless of what you're doing, and in particular, when we look at summarization and translation, the metrics that we're going to want to use are going to be different for these tasks.</td>\n",
       "      <td>Models and metrics</td>\n",
       "      <td>The loss is kind of the models way, the models metric, that it understands in terms of improving the quality of your weights . When we look at summarization and translation, the metrics that we're going to want to use are going to be different for these tasks .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[492.88, 495.56, 498.68, 502.6, 506.68]</td>\n",
       "      <td>00:08:12.880</td>\n",
       "      <td>And we want to make sure that we're using metrics that are in line with whatever our objectives are, and also with the data set that we're using. So we'll take a look at that in a little bit more detail. And also, I have a note here on this particular slide</td>\n",
       "      <td>metrics in line</td>\n",
       "      <td>We want to make sure that we're using metrics that are in line with whatever our objectives are, and also with the data set that we're using .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic_num  \\\n",
       "0          0   \n",
       "1          1   \n",
       "2          2   \n",
       "3          3   \n",
       "4          4   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           elapsed_seconds  \\\n",
       "0                                                                                                                                                                                                                                                                                   [0.0, 3.56, 6.72, 12.7, 14.12, 15.24, 22.72, 23.2, 25.08, 25.68, 26.96, 27.8, 28.8, 30.28, 32.04, 36.6, 39.12, 42.4, 44.96, 47.44, 51.92, 54.68, 60.64, 63.28, 66.76, 70.56, 71.24, 72.8, 73.56, 74.0, 75.16, 78.2, 80.16, 85.56, 93.75999999999999, 94.75999999999999, 106.16, 128.04, 129.24, 133.0, 140.68, 141.68, 149.88, 152.84]   \n",
       "1  [153.92000000000002, 155.52, 162.44, 163.88, 169.44, 175.52, 176.6, 181.56, 184.76, 189.92, 192.4, 193.84, 196.68, 200.56, 206.68, 208.56, 211.76, 214.28, 220.44, 221.88, 224.92000000000002, 225.88, 229.52, 231.8, 235.28, 239.04, 242.64, 246.0, 249.12, 253.32, 255.96, 257.72, 259.56, 264.6, 270.12, 273.84000000000003, 279.08, 285.32, 287.0, 292.64, 293.08, 294.88, 295.88, 299.28, 301.52, 312.64, 314.68, 316.08, 318.0, 320.4, 324.4, 330.36, 333.68, 336.92, 337.76, 341.72, 345.92, 346.56, 350.76, 352.72, 355.88, 358.56, 359.48, 364.36, 364.88, 366.04, 366.52, 367.04, 368.44, 369.92, 373.48, ...   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           [430.4, 434.04, 438.68, 442.0, 444.52, 447.88]   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            [454.2, 457.08, 462.92, 467.6, 471.68, 475.24, 476.48, 479.64, 480.8, 484.44, 486.96, 489.08]   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  [492.88, 495.56, 498.68, 502.6, 506.68]   \n",
       "\n",
       "      timestamp  \\\n",
       "0  00:00:00.000   \n",
       "1  00:02:33.920   \n",
       "2  00:07:10.400   \n",
       "3  00:07:34.200   \n",
       "4  00:08:12.880   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                transcript  \\\n",
       "0  Let me make sure everything is as it should be. I'm always fascinated by the fact that people are waiting. It's like it's it's so surprising that people are like on here sometimes early for you. It makes sense for my session. I'm like why are people joining? Awesome. I believe we live. Welcome back. Everyone wait is back. He wasn't well. Last week. Now he's in awesome health. So that's I was happy to hear that. And I hope you are as well because he'll be teaching us how to translate stuff and how to summarize models. If I can learn this from him, I'll take his model and deploy it on my pod...   \n",
       "1  In the meantime, I can talk about tricks. I've been trying to learn different tricks shared across NLP, computer vision world. I found out the augmentee library by the space group. Let's see if I can find that up. Here it is. So let's see link to it. I found that to be quite interesting. And a few things I've been trying to learn in the meantime is NLP augmentations. As you can see, I learned a cool trick called pack translation. I'm sure everyone knows of it. But when you're trying to perform augmentation, you can translate your original text to foreign language, translate it back. And ju...   \n",
       "2                                                                                                                                                                                                                                                                                          And there's minor differences between building a summarization versus a translation model, especially in terms of the metrics that you're going to want to use. So we're going to kind of go through our seven steps that we've used for looking at question answering task, and also looking at the token classification task.   \n",
       "3                                                       And along the way, we'll talk about a little bit deeper into model selection and also metrics selection. So as you know, when you're actually building a model, the loss is kind of the models way, the models metric, that it understands in terms of improving the quality of your weights. But from a human perspective, what we really care about is metrics. And so regardless of what you're doing, and in particular, when we look at summarization and translation, the metrics that we're going to want to use are going to be different for these tasks.   \n",
       "4                                                                                                                                                                                                                                                                                                                                                        And we want to make sure that we're using metrics that are in line with whatever our objectives are, and also with the data set that we're using. So we'll take a look at that in a little bit more detail. And also, I have a note here on this particular slide   \n",
       "\n",
       "     topic_prediction  \\\n",
       "0          This week'   \n",
       "1         This is the   \n",
       "2               We've   \n",
       "3  Models and metrics   \n",
       "4     metrics in line   \n",
       "\n",
       "                                                                                                                                                                                                                                                      content_highlights  \n",
       "0                                                                                                  This week's show is the second day of the show . I'm excited to learn how to translate stuff and summarize models . I'll take his model and deploy it on my podcast .  \n",
       "1                                                                                          This is the fifth session of our walkthrough of the Part 2, the Hugging Faced Course . This is the fifth session of our walkthrough of the Part 2, the Hugging Faced Course .  \n",
       "2                                                                                                                         We're going to kind of go through the seven steps that we've used to look at question answering task, and also the token classification task .  \n",
       "3  The loss is kind of the models way, the models metric, that it understands in terms of improving the quality of your weights . When we look at summarization and translation, the metrics that we're going to want to use are going to be different for these tasks .  \n",
       "4                                                                                                                         We want to make sure that we're using metrics that are in line with whatever our objectives are, and also with the data set that we're using .  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_preds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "4c27d0eb0116998fc328b5a00abe6956c11e30aa3cb3ca27ff0ca511f067786d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
