{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "\n",
    "from course_copilot import transcription, topic_segmentation, summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_id = \"Jsz4E2iNXUA\"\n",
    "device = \"cuda\"\n",
    "\n",
    "audio_files_fpath = Path(\"../../transcription/audio_files\")\n",
    "transcription_fpath = Path(\"../../transcription/transcriptions\")\n",
    "whisper_models_fpath = Path(\"../../transcription/models\")\n",
    "\n",
    "whisper_model = \"base\"\n",
    "topic_segmentation_learner_fpath = \"../../models/topic_segmentation_deberta_v3_small.pkl\"\n",
    "headline_summarization_learner_fpath = \"../../models/{exported_learner.pkl}\"\n",
    "content_summarization_learner_fpath = \"../../models/{exported_learner.pkl}\"\n",
    "\n",
    "# smaller = more fine grained topics (more topics predicted) while larger values = less fine grained (less topics predicted)\n",
    "topic_segmentation_get_preds_kwargs = {\"threshold_std_coeff\": 1.9}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00:00:00.000</td>\n",
       "      <td>Let me make sure everything is as it should be.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00:00:03.560</td>\n",
       "      <td>I'm always fascinated by the fact that people are waiting.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00:00:06.720</td>\n",
       "      <td>It's like it's it's so surprising that people are like on here</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00:00:12.700</td>\n",
       "      <td>sometimes early for you.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00:00:14.120</td>\n",
       "      <td>It makes sense for my session.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      timestamp  \\\n",
       "0  00:00:00.000   \n",
       "1  00:00:03.560   \n",
       "2  00:00:06.720   \n",
       "3  00:00:12.700   \n",
       "4  00:00:14.120   \n",
       "\n",
       "                                                       transcript  \n",
       "0                 Let me make sure everything is as it should be.  \n",
       "1      I'm always fascinated by the fact that people are waiting.  \n",
       "2  It's like it's it's so surprising that people are like on here  \n",
       "3                                        sometimes early for you.  \n",
       "4                                  It makes sense for my session.  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_fpath = transcription.fetch_youtube_audio(youtube_id, audio_files_fpath=audio_files_fpath)\n",
    "\n",
    "transcription_fpath = transcription.fetch_transcription(\n",
    "    audio_fpath=audio_fpath,\n",
    "    transcription_fpath=transcription_fpath,\n",
    "    model_fpath=whisper_models_fpath,\n",
    "    model_checkptoint=whisper_model,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "transcription_df = transcription.transcription_to_df(transcription_fpath)\n",
    "transcription_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# predicted topics:  41\n",
      "[0, 44, 113, 129, 133, 145, 150, 155, 162, 170]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>transcript</th>\n",
       "      <th>depth_score</th>\n",
       "      <th>threshold</th>\n",
       "      <th>pred_start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00:00:00.000</td>\n",
       "      <td>Let me make sure everything is as it should be.</td>\n",
       "      <td>0.006972</td>\n",
       "      <td>0.022118</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00:00:03.560</td>\n",
       "      <td>I'm always fascinated by the fact that people are waiting.</td>\n",
       "      <td>0.004309</td>\n",
       "      <td>0.022118</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00:00:06.720</td>\n",
       "      <td>It's like it's it's so surprising that people are like on here</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022118</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00:00:12.700</td>\n",
       "      <td>sometimes early for you.</td>\n",
       "      <td>0.003844</td>\n",
       "      <td>0.022118</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00:00:14.120</td>\n",
       "      <td>It makes sense for my session.</td>\n",
       "      <td>0.005018</td>\n",
       "      <td>0.022118</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      timestamp  \\\n",
       "0  00:00:00.000   \n",
       "1  00:00:03.560   \n",
       "2  00:00:06.720   \n",
       "3  00:00:12.700   \n",
       "4  00:00:14.120   \n",
       "\n",
       "                                                       transcript  \\\n",
       "0                 Let me make sure everything is as it should be.   \n",
       "1      I'm always fascinated by the fact that people are waiting.   \n",
       "2  It's like it's it's so surprising that people are like on here   \n",
       "3                                        sometimes early for you.   \n",
       "4                                  It makes sense for my session.   \n",
       "\n",
       "   depth_score  threshold  pred_start  \n",
       "0     0.006972   0.022118        True  \n",
       "1     0.004309   0.022118       False  \n",
       "2     0.000000   0.022118       False  \n",
       "3     0.003844   0.022118       False  \n",
       "4     0.005018   0.022118       False  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_segmentation_trainer = topic_segmentation.TopicSegmentationModelTrainer(\n",
    "    experiment_name=\"deberta_v3_small\", train_config=topic_segmentation.TopicSegmentationConfig\n",
    ")\n",
    "# results_df, train_df, val_idxs = trainer.train()\n",
    "inf_learn = topic_segmentation_trainer.load_learner_or_model(\n",
    "    model_learner_fpath=topic_segmentation_learner_fpath, device=device\n",
    ")\n",
    "\n",
    "topic_seg_preds_df, pred_topic_idxs = topic_segmentation_trainer.get_preds(\n",
    "    inf_learn, transcription_df.copy(), **topic_segmentation_get_preds_kwargs\n",
    ")\n",
    "\n",
    "# cleanup resources\n",
    "del inf_learn\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "# shows final results\n",
    "print(\"# predicted topics: \", len(pred_topic_idxs))\n",
    "print(pred_topic_idxs[:10])\n",
    "topic_seg_preds_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_num</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>00:00:00.000</td>\n",
       "      <td>Let me make sure everything is as it should be. I'm always fascinated by the fact that people are waiting. It's like it's it's so surprising that people are like on here sometimes early for you. It makes sense for my session. I'm like why are people joining? Awesome. I believe we live. Welcome back. Everyone wait is back. He wasn't well. Last week. Now he's in awesome health. So that's I was happy to hear that. And I hope you are as well because he'll be teaching us how to translate stuff and how to summarize models. If I can learn this from him, I'll take his model and deploy it on my pod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>00:02:34.040</td>\n",
       "      <td>In the meantime, I can talk about tricks. I've been trying to learn different tricks shared across NLP, computer vision world. I found out the augmentee library by the Spacey group. Let's see if I can find that up. Here it is. So let's see link to it. I found that to be quite interesting. And a few things I've been trying to learn in the meantime is NLP augmentations. As you can see, I learned a cool trick called back translation. I'm sure everyone knows of it. But when you're trying to perform augmentation, you can translate your original text to foreign language, translate it back. And j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>00:06:30.360</td>\n",
       "      <td>but we're now looking at some of the major NLP tasks that you can build with using transformers. And then in particular, we're looking at how we can use FASTI to develop these models, train them, deploy them for inference. And their models that are supported in a library built called Blur. So we'll be looking today kind of really diving into the summarization and translation bits. And I combined them because, as you'll see, they're actually very similar. There's little intricacies with building these type of models. And there's minor differences between building a summarization versus a tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>00:07:22.040</td>\n",
       "      <td>So we're going to kind of go through our seven steps that we've used for looking at question answering task and also looking at the token classification task. And along the way, we'll talk about,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>00:07:35.840</td>\n",
       "      <td>get a little bit deeper into model selection and also metrics selection. So as you know, when you're actually building a model, the loss is kind of the models way, the models metric, that it understands in terms of improving the quality of your weights. But from a human perspective, what we really care about is metrics. And so regardless of what you're doing, and in particular, when we look at summarization and translation, the metrics that we're going to want to use are going to be different for these tasks.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic_num     timestamp  \\\n",
       "0          0  00:00:00.000   \n",
       "1          1  00:02:34.040   \n",
       "2          2  00:06:30.360   \n",
       "3          3  00:07:22.040   \n",
       "4          4  00:07:35.840   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                transcript  \n",
       "0  Let me make sure everything is as it should be. I'm always fascinated by the fact that people are waiting. It's like it's it's so surprising that people are like on here sometimes early for you. It makes sense for my session. I'm like why are people joining? Awesome. I believe we live. Welcome back. Everyone wait is back. He wasn't well. Last week. Now he's in awesome health. So that's I was happy to hear that. And I hope you are as well because he'll be teaching us how to translate stuff and how to summarize models. If I can learn this from him, I'll take his model and deploy it on my pod...  \n",
       "1  In the meantime, I can talk about tricks. I've been trying to learn different tricks shared across NLP, computer vision world. I found out the augmentee library by the Spacey group. Let's see if I can find that up. Here it is. So let's see link to it. I found that to be quite interesting. And a few things I've been trying to learn in the meantime is NLP augmentations. As you can see, I learned a cool trick called back translation. I'm sure everyone knows of it. But when you're trying to perform augmentation, you can translate your original text to foreign language, translate it back. And j...  \n",
       "2  but we're now looking at some of the major NLP tasks that you can build with using transformers. And then in particular, we're looking at how we can use FASTI to develop these models, train them, deploy them for inference. And their models that are supported in a library built called Blur. So we'll be looking today kind of really diving into the summarization and translation bits. And I combined them because, as you'll see, they're actually very similar. There's little intricacies with building these type of models. And there's minor differences between building a summarization versus a tr...  \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                      So we're going to kind of go through our seven steps that we've used for looking at question answering task and also looking at the token classification task. And along the way, we'll talk about,  \n",
       "4                                                                                       get a little bit deeper into model selection and also metrics selection. So as you know, when you're actually building a model, the loss is kind of the models way, the models metric, that it understands in terms of improving the quality of your weights. But from a human perspective, what we really care about is metrics. And so regardless of what you're doing, and in particular, when we look at summarization and translation, the metrics that we're going to want to use are going to be different for these tasks.  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarization_inf_df = topic_seg_preds_df.copy()\n",
    "\n",
    "summarization_inf_df[\"topic_num\"] = -1\n",
    "n_topics = len(pred_topic_idxs)\n",
    "\n",
    "for i, seg_idx in enumerate(pred_topic_idxs):\n",
    "    end_idx = pred_topic_idxs[i + 1] if i + 1 <= (n_topics - 1) else None\n",
    "    summarization_inf_df.loc[seg_idx:end_idx, \"topic_num\"] = i\n",
    "\n",
    "summarization_inf_df = summarization_inf_df.groupby(by=\"topic_num\").agg(list).reset_index()\n",
    "summarization_inf_df[\"transcript\"] = summarization_inf_df[\"transcript\"].apply(\n",
    "    lambda v: \" \".join([str(seq) for seq in v])\n",
    ")\n",
    "summarization_inf_df.timestamp = summarization_inf_df.timestamp.apply(lambda v: v[0])\n",
    "summarization_inf_df.drop(columns=[\"depth_score\", \"threshold\", \"pred_start\"], inplace=True)\n",
    "\n",
    "summarization_inf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Kurian to add his magic here after he adds his models to /models ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('fsdl_2022_course_project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4c27d0eb0116998fc328b5a00abe6956c11e30aa3cb3ca27ff0ca511f067786d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
