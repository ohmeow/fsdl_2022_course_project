{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/team_007/mambaforge/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import inspect\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import torch\n",
    "\n",
    "from blurr.text.data.seq2seq.core import Seq2SeqBatchTokenizeTransform, Seq2SeqTextBlock, default_text_gen_kwargs\n",
    "from blurr.text.modeling.core import BaseModelCallback, BaseModelWrapper\n",
    "from blurr.text.modeling.seq2seq.core import Seq2SeqMetricsCallback, blurr_seq2seq_splitter\n",
    "from blurr.text.utils import get_hf_objects\n",
    "from blurr.utils import PreCalculatedCrossEntropyLoss\n",
    "from fastai.data.block import DataBlock, ColReader, ItemGetter, ColSplitter, RandomSplitter\n",
    "from fastai.callback.wandb import WandbCallback\n",
    "from fastai.imports import *\n",
    "from fastai.learner import *\n",
    "from fastai.losses import CrossEntropyLossFlat\n",
    "from fastai.optimizer import Adam, ranger\n",
    "from fastai.torch_core import *\n",
    "from fastai.torch_imports import *\n",
    "from fastcore.all import *\n",
    "from transformers import PegasusForConditionalGeneration, BartForConditionalGeneration, T5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, PreTrainedModel\n",
    "from transformers.utils import logging as hf_logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/team_007/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# silence all the HF warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grab our topics and transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheets_d = pd.read_excel(\n",
    "    \"../../data/raw/fsdl_2022_project_transcripts.xlsx\",\n",
    "    sheet_name=[\"lesson_topics\", \"lesson_transcripts\"],\n",
    "    engine=\"openpyxl\",\n",
    ")\n",
    "topics_df, transcripts_df = [v for k, v in sheets_d.items()]\n",
    "\n",
    "topics_df.drop(columns=\"video_url\", inplace=True)\n",
    "transcripts_df.drop(columns=\"video_url\", inplace=True)\n",
    "\n",
    "topics_df[\"timestamp\"] = topics_df[\"timestamp\"].astype(str)\n",
    "transcripts_df[\"timestamp\"] = transcripts_df[\"timestamp\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25283\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>course_title</th>\n",
       "      <th>lesson_num</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fast.ai 2022 - Part 1</td>\n",
       "      <td>2</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>Hi everybody. Welcome to lesson two. Thanks for coming back… slight change of environment here,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fast.ai 2022 - Part 1</td>\n",
       "      <td>2</td>\n",
       "      <td>00:00:08</td>\n",
       "      <td>we had a bit of an “administrative issue” at our university — somebody booked our room — so I'm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fast.ai 2022 - Part 1</td>\n",
       "      <td>2</td>\n",
       "      <td>00:00:14</td>\n",
       "      <td>doing this from the study at home. so sorry about the lack of decorations behind me.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fast.ai 2022 - Part 1</td>\n",
       "      <td>2</td>\n",
       "      <td>00:00:25</td>\n",
       "      <td>I'm actually really really pumped about this lesson. It feels like going back to what things</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fast.ai 2022 - Part 1</td>\n",
       "      <td>2</td>\n",
       "      <td>00:00:32</td>\n",
       "      <td>were like in the very early days, because we're doing some really new, really cool stuff, which…</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            course_title lesson_num timestamp  \\\n",
       "0  fast.ai 2022 - Part 1          2  00:00:00   \n",
       "1  fast.ai 2022 - Part 1          2  00:00:08   \n",
       "2  fast.ai 2022 - Part 1          2  00:00:14   \n",
       "3  fast.ai 2022 - Part 1          2  00:00:25   \n",
       "4  fast.ai 2022 - Part 1          2  00:00:32   \n",
       "\n",
       "                                                                                         transcript  \n",
       "0   Hi everybody. Welcome to lesson two. Thanks for coming back… slight change of environment here,  \n",
       "1   we had a bit of an “administrative issue” at our university — somebody booked our room — so I'm  \n",
       "2              doing this from the study at home. so sorry about the lack of decorations behind me.  \n",
       "3      I'm actually really really pumped about this lesson. It feels like going back to what things  \n",
       "4  were like in the very early days, because we're doing some really new, really cool stuff, which…  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(transcripts_df))\n",
    "\n",
    "transcripts_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a utility function for converting durations to total_seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_duration_to_seconds(v):\n",
    "    hrs, mins, secs = v.split(\":\")\n",
    "    return (60 * 60 * int(hrs)) + (60 * int(mins)) + int(secs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the start/end boundaries (in seconds) for each topic in each lesson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_df[\"start_seconds\"] = topics_df[\"timestamp\"].apply(convert_duration_to_seconds)\n",
    "topics_df[\"end_seconds\"] = topics_df.groupby(by=[\"course_title\", \"lesson_num\"])[\"start_seconds\"].shift(\n",
    "    -1, fill_value=100000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the total number of elapsed seconds at each timestamp in the transcripts dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcripts_df[\"elapsed_seconds\"] = transcripts_df[\"timestamp\"].apply(convert_duration_to_seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build our training data.  \n",
    "\n",
    "This should be usable for both segmentation and summarization tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "467129"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = topics_df[[\"course_title\", \"lesson_num\", \"topic\", \"start_seconds\", \"end_seconds\"]].merge(\n",
    "    transcripts_df, on=[\"course_title\", \"lesson_num\"]\n",
    ")\n",
    "len(merged_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep only the merged records where the transcript lies inbetween the start/end of the topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df[\n",
    "    (merged_df.elapsed_seconds >= merged_df.start_seconds) & (merged_df.elapsed_seconds < merged_df.end_seconds)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For both segmentation and summarization tasks, we'll need to group the transcripts by course + lesson + topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = (\n",
    "    merged_df[[\"course_title\", \"lesson_num\", \"topic\", \"transcript\", \"start_seconds\"]]\n",
    "    .groupby(by=[\"course_title\", \"lesson_num\", \"start_seconds\", \"topic\"])\n",
    "    .agg(list)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "train_df.sort_values(by=[\"course_title\", \"lesson_num\", \"start_seconds\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>course_title</th>\n",
       "      <th>lesson_num</th>\n",
       "      <th>start_seconds</th>\n",
       "      <th>topic</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C-Squared Podcast</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Intro</td>\n",
       "      <td>[[Music] welcome everybody to episode one of a, chess themed podcast with myself christian kirilla and i'm fighting on caruana so what's up, christian well not so much fabi uh it's first of all great um to finally start a, podcast the chess podcast i know that um there's a lot of podcasts out there but, i wanted to bring our own tune to the mix and i think uh yeah i'm, excited about that so that's uh the first thing how about yourself fabian well i'm back in the states after it's, been a while at your home it's good to be here it's my first time in uh visiting here and uh, yeah it's been a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C-Squared Podcast</td>\n",
       "      <td>1</td>\n",
       "      <td>137</td>\n",
       "      <td>Candidates 2018</td>\n",
       "      <td>[camps look like in general yeah well you mentioned the 2018 cycle uh where we worked together we started with the, training before the candidates and for me it's interesting because i've i've played a lot of these, candidates tournaments and i'm always doing it a bit differently trying different things trying to improve it but sometimes it goes, less or more successfully you never know what will work out i think what we did in 2018 not just for the candidates but, also for the world championship because i qualified for that i think what we did then was extremely successful, um we we arran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C-Squared Podcast</td>\n",
       "      <td>1</td>\n",
       "      <td>464</td>\n",
       "      <td>Candidates training</td>\n",
       "      <td>[going in the candidates like how was the experience yeah i think the preparation was pretty serious it, included a bunch of uh camps and preparation devoted to players as i assume i think everyone has the same, sort of general approach which is to think about their openings their strategy look at the opponents try to, get in shape make sure that you're not you know rusty or blundering things or hallucinating, variations uh but there's a lot of nerves and i i felt a lot of nerves before the tournament and i think possibly i, you know overworked over trained a bit because it was yeah it was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C-Squared Podcast</td>\n",
       "      <td>1</td>\n",
       "      <td>610</td>\n",
       "      <td>Playing for 2nd place</td>\n",
       "      <td>[were you just like focused on grabbing first well i was only focused on first, but of course there were always these thoughts that well maybe second is enough but you can't play for second, like let's say once i had achieved plus three in the tournament and john was plus four and i tried to go and go into like full, like risk reverse mode which is still difficult to do but let's say i had gone that mode and, and achieved it and like finished second with like plus three and john got plus five uh, and then like magnus says well i'm going to play right then you also feel kind of stupid you k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C-Squared Podcast</td>\n",
       "      <td>1</td>\n",
       "      <td>916</td>\n",
       "      <td>Magnus' WC decision</td>\n",
       "      <td>[know you can't uh you can't tell him you have to do something i i guess let me rephrase that, fair to let you guys play the tournament first and then tell you the decision, well i think he said it in a strange way which was that i'll play against alireza, which to me is strange because if you don't want to play world championship match i fully understand you know but did he say that did he actually name him, yeah that's kind of what he said um yeah he more he like he didn't say definitively like i won't play against, anyone but he was like i probably won't play unless it's frozen right an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        course_title lesson_num  start_seconds                  topic  \\\n",
       "0  C-Squared Podcast          1              0                  Intro   \n",
       "1  C-Squared Podcast          1            137        Candidates 2018   \n",
       "2  C-Squared Podcast          1            464    Candidates training   \n",
       "3  C-Squared Podcast          1            610  Playing for 2nd place   \n",
       "4  C-Squared Podcast          1            916    Magnus' WC decision   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                transcript  \n",
       "0  [[Music] welcome everybody to episode one of a, chess themed podcast with myself christian kirilla and i'm fighting on caruana so what's up, christian well not so much fabi uh it's first of all great um to finally start a, podcast the chess podcast i know that um there's a lot of podcasts out there but, i wanted to bring our own tune to the mix and i think uh yeah i'm, excited about that so that's uh the first thing how about yourself fabian well i'm back in the states after it's, been a while at your home it's good to be here it's my first time in uh visiting here and uh, yeah it's been a...  \n",
       "1  [camps look like in general yeah well you mentioned the 2018 cycle uh where we worked together we started with the, training before the candidates and for me it's interesting because i've i've played a lot of these, candidates tournaments and i'm always doing it a bit differently trying different things trying to improve it but sometimes it goes, less or more successfully you never know what will work out i think what we did in 2018 not just for the candidates but, also for the world championship because i qualified for that i think what we did then was extremely successful, um we we arran...  \n",
       "2  [going in the candidates like how was the experience yeah i think the preparation was pretty serious it, included a bunch of uh camps and preparation devoted to players as i assume i think everyone has the same, sort of general approach which is to think about their openings their strategy look at the opponents try to, get in shape make sure that you're not you know rusty or blundering things or hallucinating, variations uh but there's a lot of nerves and i i felt a lot of nerves before the tournament and i think possibly i, you know overworked over trained a bit because it was yeah it was...  \n",
       "3  [were you just like focused on grabbing first well i was only focused on first, but of course there were always these thoughts that well maybe second is enough but you can't play for second, like let's say once i had achieved plus three in the tournament and john was plus four and i tried to go and go into like full, like risk reverse mode which is still difficult to do but let's say i had gone that mode and, and achieved it and like finished second with like plus three and john got plus five uh, and then like magnus says well i'm going to play right then you also feel kind of stupid you k...  \n",
       "4  [know you can't uh you can't tell him you have to do something i i guess let me rephrase that, fair to let you guys play the tournament first and then tell you the decision, well i think he said it in a strange way which was that i'll play against alireza, which to me is strange because if you don't want to play world championship match i fully understand you know but did he say that did he actually name him, yeah that's kind of what he said um yeah he more he like he didn't say definitively like i won't play against, anyone but he was like i probably won't play unless it's frozen right an...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build summarization training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarization_train_df = train_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarization_train_df[\"transcript\"] = summarization_train_df[\"transcript\"].apply(\n",
    "    lambda v: \" \".join([str(seq) for seq in v])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blurr learner for training summarization model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using pegasus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('pegasus',\n",
       " transformers.models.pegasus.configuration_pegasus.PegasusConfig,\n",
       " transformers.models.pegasus.tokenization_pegasus_fast.PegasusTokenizerFast,\n",
       " transformers.models.pegasus.modeling_pegasus.PegasusForConditionalGeneration)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_model_name = \"sshleifer/distill-pegasus-cnn-16-4\"\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(\n",
    "    pretrained_model_name, model_cls=PegasusForConditionalGeneration\n",
    ")\n",
    "\n",
    "hf_arch, type(hf_config), type(hf_tokenizer), type(hf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PegasusConfig {\n",
       "  \"_name_or_path\": \"sshleifer/distill-pegasus-cnn-16-4\",\n",
       "  \"activation_dropout\": 0.1,\n",
       "  \"activation_function\": \"relu\",\n",
       "  \"add_bias_logits\": false,\n",
       "  \"add_final_layer_norm\": true,\n",
       "  \"architectures\": [\n",
       "    \"PegasusForConditionalGeneration\"\n",
       "  ],\n",
       "  \"attention_dropout\": 0.1,\n",
       "  \"bos_token_id\": 0,\n",
       "  \"classif_dropout\": 0.0,\n",
       "  \"classifier_dropout\": 0.0,\n",
       "  \"d_model\": 1024,\n",
       "  \"decoder_attention_heads\": 16,\n",
       "  \"decoder_ffn_dim\": 4096,\n",
       "  \"decoder_layerdrop\": 0.0,\n",
       "  \"decoder_layers\": 4,\n",
       "  \"decoder_start_token_id\": 0,\n",
       "  \"dropout\": 0.1,\n",
       "  \"encoder_attention_heads\": 16,\n",
       "  \"encoder_ffn_dim\": 4096,\n",
       "  \"encoder_layerdrop\": 0.0,\n",
       "  \"encoder_layers\": 16,\n",
       "  \"eos_token_id\": 1,\n",
       "  \"extra_pos_embeddings\": 1,\n",
       "  \"force_bos_token_to_be_generated\": false,\n",
       "  \"forced_eos_token_id\": 1,\n",
       "  \"id2label\": {\n",
       "    \"0\": \"LABEL_0\",\n",
       "    \"1\": \"LABEL_1\",\n",
       "    \"2\": \"LABEL_2\"\n",
       "  },\n",
       "  \"init_std\": 0.02,\n",
       "  \"is_encoder_decoder\": true,\n",
       "  \"label2id\": {\n",
       "    \"LABEL_0\": 0,\n",
       "    \"LABEL_1\": 1,\n",
       "    \"LABEL_2\": 2\n",
       "  },\n",
       "  \"length_penalty\": 0.8,\n",
       "  \"max_length\": 128,\n",
       "  \"max_position_embeddings\": 1024,\n",
       "  \"model_type\": \"pegasus\",\n",
       "  \"normalize_before\": true,\n",
       "  \"normalize_embedding\": false,\n",
       "  \"num_beams\": 8,\n",
       "  \"num_hidden_layers\": 16,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"save_step\": 15,\n",
       "  \"scale_embedding\": true,\n",
       "  \"static_position_embeddings\": true,\n",
       "  \"transformers_version\": \"4.22.1\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 96103\n",
       "}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({}, {})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_gen_kwargs = {}\n",
    "if hf_arch in [\"bart\", \"t5\"]:\n",
    "    text_gen_kwargs = {\n",
    "        **hf_config.task_specific_params[\"summarization\"],\n",
    "        **{\"max_length\": 60, \"min_length\": 30, \"num_beams\": 4},\n",
    "    }\n",
    "\n",
    "\n",
    "generate_func_args = list(inspect.signature(hf_model.generate).parameters.keys())\n",
    "for k in text_gen_kwargs.copy():\n",
    "    if k not in generate_func_args:\n",
    "        del text_gen_kwargs[k]\n",
    "\n",
    "\n",
    "tok_kwargs = {}\n",
    "if hf_arch == \"mbart\":\n",
    "    tok_kwargs[\"src_lang\"], tok_kwargs[\"tgt_lang\"] = \"en_XX\", \"en_XX\"\n",
    "text_gen_kwargs, tok_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_tokenize_tfm = Seq2SeqBatchTokenizeTransform(\n",
    "    hf_arch,\n",
    "    hf_config,\n",
    "    hf_tokenizer,\n",
    "    hf_model,\n",
    "    max_length=1024,\n",
    "    max_target_length=128,\n",
    "    tok_kwargs=tok_kwargs,\n",
    "    text_gen_kwargs=text_gen_kwargs,\n",
    ")\n",
    "\n",
    "blocks = (Seq2SeqTextBlock(batch_tokenize_tfm=batch_tokenize_tfm), noop)\n",
    "\n",
    "dblock = DataBlock(blocks=blocks, get_x=ColReader(\"transcript\"), get_y=ColReader(\"topic\"), splitter=RandomSplitter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, torch.Size([1, 1024]), torch.Size([1, 8]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls = dblock.dataloaders(summarization_train_df, bs=1)\n",
    "b = dls.one_batch()\n",
    "len(b), b[0][\"input_ids\"].shape, b[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>little bit bigger you know obviously a super famous artwork and and this is not that he wasn't the first person to illustrate perspective or he wasn't the first person to illustrate this particular biblical scene but he was amongst the first to use perspective to draw it and or to paint it and so previous to this we had medieval painting right which was very kind of stilted and and the space was kind of weirdly ill-defined it looked a lot like children's drawings but just like really really refined children's drawings where everything is a little bit awkward so what is kind of special about this and why it's Malay Nardo's Last Supper is important is that this was painted let me see if we there's a well it was painted in a room and kind of high up in a room on a wall and if you stood all the way back at the far end of the room it created the illusion that this whole scene was happening on that far wall like the the walls and the ceiling and the room that you were physically standing in appeared to continue into the painting and then off into the distance so it was this optical illusion you know you you you would look at it and say well I know that's a flat wall but it seems to kind of go further the painting appears to make the wall look like it's a window into another space right so Leonardo using perspective created this depth so it looks like there's a whole room in behind all of these figures sitting at this table okay so I'm not going to go into too too deep into the history of perspective there's lots of videos and stuff about that that already exists but this is a particularly important painting wasn't the first one but it it you know there was some people using perspective fifty years before this but it definitely is amongst the most famous early examples okay so I'm gonna go back to my handout here so just to kind of continue that there are lots of different kinds of perspective now the first type of perspective we're going to talk about and I'm just gonna talk about those briefly in my in my classes I talked about a little bit longer and we're gonna do we would do an exercise with it but it's gonna be a little challenging for us to do over the web so I'm gonna kind of just breeze through it so this is isometric projection and you've probably seen this many times if you've ever assembled IKEA furniture IKEA furniture is drawn in isometric projection so let's say if I look at this drawing it's image on the bottom right here I'm scum so I'm zoomed in on this here if I was to show you this drawing and say this is the plan for the bathroom I'm going to this is I'm gonna renovate my bathroom and this is what its gonna look like I think you might look at it and say okay I what okay oh this is the sink okay um and what is this here what are these things is this oh is that a shower okay so what is this a so it's not clear right it's a cuz it's drawn from one angle and so we can't really see any dimension in this drawing whereas if we use isometric projection we now see that same I'm able to zoom back out a little bit more here this same image reproduced here but from like a 3/4 review so we're kind of taking this front view and then rotating it so that we can now see the top right if you imagine this being a box like let me see like this box right so we've started from this point of view straight on and then we're kind of now looking at it from this angle so you could see the top and the front side and this side right and you can even kind of imagine what the back side is a little bit right so this allows us to see multiple points of view all at once and if you've it's probably not that many people watching this who have any experience with drafting but this is I took drafting when I was in high school and we spent a lot in before computers and your drawing all this on paper and using rulers in a super analytical and like a very left brain activity right so break like a lot of mathematics and you're always using the calculator and to try to get all this right but so you like an exercise in in a drafting class and exam would be something like this where they would give you the front view of this object the side view and then the top view and they would say illustrate it in an isometric projection from a 3/4 angle right so you this image here would not be visible you'd have to create that from only these three so it's a little bit tricky but all of a sudden this image is a lot clearer to most people than just looking at these three other views right so in when I'm teaching this class in in person what I do is I pass out a little sheet like this and I get people to kind of fill it out right so here's one and then you're just&lt;/s&gt;</td>\n",
       "      <td>Shading a Cylinder 4 Different Ways</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(dataloaders=dls, max_n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq_metrics = {\n",
    "    \"rouge\": {\n",
    "        \"compute_kwargs\": {\"rouge_types\": [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"], \"use_stemmer\": True},\n",
    "        \"returns\": [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"],\n",
    "    },\n",
    "    \"bertscore\": {\"compute_kwargs\": {\"lang\": \"en\"}, \"returns\": [\"precision\", \"recall\", \"f1\"]},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BaseModelWrapper(hf_model)\n",
    "learn_cbs = [BaseModelCallback]\n",
    "fit_cbs = [Seq2SeqMetricsCallback(custom_metrics=seq2seq_metrics)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(\n",
    "    dls,\n",
    "    model,\n",
    "    opt_func=partial(Adam),\n",
    "    loss_func=CrossEntropyLossFlat(),\n",
    "    cbs=learn_cbs,\n",
    "    splitter=partial(blurr_seq2seq_splitter, arch=hf_arch),\n",
    ")\n",
    "\n",
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "BaseModelWrapper (Input shape: 1 x 1024)\n",
       "============================================================================\n",
       "Layer (type)         Output Shape         Param #    Trainable \n",
       "============================================================================\n",
       "                     1 x 8 x 1024        \n",
       "Embedding                                 98409472   False     \n",
       "Embedding                                 98409472   False     \n",
       "____________________________________________________________________________\n",
       "                     1 x 1024            \n",
       "PegasusSinusoidalPositionalEmbedding                      1048576    False     \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "LayerNorm                                 2048       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     1 x 1024 x 4096     \n",
       "Linear                                    4198400    False     \n",
       "____________________________________________________________________________\n",
       "                     1 x 1024 x 1024     \n",
       "Linear                                    4195328    False     \n",
       "LayerNorm                                 2048       True      \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "LayerNorm                                 2048       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     1 x 1024 x 4096     \n",
       "Linear                                    4198400    False     \n",
       "____________________________________________________________________________\n",
       "                     1 x 1024 x 1024     \n",
       "Linear                                    4195328    False     \n",
       "LayerNorm                                 2048       True      \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "LayerNorm                                 2048       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     1 x 1024 x 4096     \n",
       "Linear                                    4198400    False     \n",
       "____________________________________________________________________________\n",
       "                     1 x 1024 x 1024     \n",
       "Linear                                    4195328    False     \n",
       "LayerNorm                                 2048       True      \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "LayerNorm                                 2048       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     1 x 1024 x 4096     \n",
       "Linear                                    4198400    False     \n",
       "____________________________________________________________________________\n",
       "                     1 x 1024 x 1024     \n",
       "Linear                                    4195328    False     \n",
       "LayerNorm                                 2048       True      \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "LayerNorm                                 2048       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     1 x 1024 x 4096     \n",
       "Linear                                    4198400    False     \n",
       "____________________________________________________________________________\n",
       "                     1 x 1024 x 1024     \n",
       "Linear                                    4195328    False     \n",
       "LayerNorm                                 2048       True      \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "LayerNorm                                 2048       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     1 x 1024 x 4096     \n",
       "Linear                                    4198400    False     \n",
       "____________________________________________________________________________\n",
       "                     1 x 1024 x 1024     \n",
       "Linear                                    4195328    False     \n",
       "LayerNorm                                 2048       True      \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "LayerNorm                                 2048       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     1 x 1024 x 4096     \n",
       "Linear                                    4198400    False     \n",
       "____________________________________________________________________________\n",
       "                     1 x 1024 x 1024     \n",
       "Linear                                    4195328    False     \n",
       "LayerNorm                                 2048       True      \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "LayerNorm                                 2048       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     1 x 1024 x 4096     \n",
       "Linear                                    4198400    False     \n",
       "____________________________________________________________________________\n",
       "                     1 x 1024 x 1024     \n",
       "Linear                                    4195328    False     \n",
       "LayerNorm                                 2048       True      \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "LayerNorm                                 2048       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     1 x 1024 x 4096     \n",
       "Linear                                    4198400    False     \n",
       "____________________________________________________________________________\n",
       "                     1 x 1024 x 1024     \n",
       "Linear                                    4195328    False     \n",
       "LayerNorm                                 2048       True      \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "LayerNorm                                 2048       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     1 x 1024 x 4096     \n",
       "Linear                                    4198400    False     \n",
       "____________________________________________________________________________\n",
       "                     1 x 1024 x 1024     \n",
       "Linear                                    4195328    False     \n",
       "LayerNorm                                 2048       True      \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "LayerNorm                                 2048       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     1 x 1024 x 4096     \n",
       "Linear                                    4198400    False     \n",
       "____________________________________________________________________________\n",
       "                     1 x 1024 x 1024     \n",
       "Linear                                    4195328    False     \n",
       "LayerNorm                                 2048       True      \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "LayerNorm                                 2048       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     1 x 1024 x 4096     \n",
       "Linear                                    4198400    False     \n",
       "____________________________________________________________________________\n",
       "                     1 x 1024 x 1024     \n",
       "Linear                                    4195328    False     \n",
       "LayerNorm                                 2048       True      \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "LayerNorm                                 2048       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     1 x 1024 x 4096     \n",
       "Linear                                    4198400    False     \n",
       "____________________________________________________________________________\n",
       "                     1 x 1024 x 1024     \n",
       "Linear                                    4195328    False     \n",
       "LayerNorm                                 2048       True      \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "LayerNorm                                 2048       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     1 x 1024 x 4096     \n",
       "Linear                                    4198400    False     \n",
       "____________________________________________________________________________\n",
       "                     1 x 1024 x 1024     \n",
       "Linear                                    4195328    False     \n",
       "LayerNorm                                 2048       True      \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "LayerNorm                                 2048       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     1 x 1024 x 4096     \n",
       "Linear                                    4198400    False     \n",
       "____________________________________________________________________________\n",
       "                     1 x 1024 x 1024     \n",
       "Linear                                    4195328    False     \n",
       "LayerNorm                                 2048       True      \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "LayerNorm                                 2048       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     1 x 1024 x 4096     \n",
       "Linear                                    4198400    False     \n",
       "____________________________________________________________________________\n",
       "                     1 x 1024 x 1024     \n",
       "Linear                                    4195328    False     \n",
       "LayerNorm                                 2048       True      \n",
       "LayerNorm                                 2048       True      \n",
       "____________________________________________________________________________\n",
       "                     1 x 8 x 1024        \n",
       "Embedding                                 98409472   False     \n",
       "____________________________________________________________________________\n",
       "                     1 x 1024            \n",
       "PegasusSinusoidalPositionalEmbedding                      1048576    False     \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "ReLU                                                           \n",
       "LayerNorm                                 2048       True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "LayerNorm                                 2048       True      \n",
       "____________________________________________________________________________\n",
       "                     1 x 8 x 4096        \n",
       "Linear                                    4198400    True      \n",
       "____________________________________________________________________________\n",
       "                     1 x 8 x 1024        \n",
       "Linear                                    4195328    True      \n",
       "LayerNorm                                 2048       True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "ReLU                                                           \n",
       "LayerNorm                                 2048       True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "LayerNorm                                 2048       True      \n",
       "____________________________________________________________________________\n",
       "                     1 x 8 x 4096        \n",
       "Linear                                    4198400    True      \n",
       "____________________________________________________________________________\n",
       "                     1 x 8 x 1024        \n",
       "Linear                                    4195328    True      \n",
       "LayerNorm                                 2048       True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "ReLU                                                           \n",
       "LayerNorm                                 2048       True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "LayerNorm                                 2048       True      \n",
       "____________________________________________________________________________\n",
       "                     1 x 8 x 4096        \n",
       "Linear                                    4198400    True      \n",
       "____________________________________________________________________________\n",
       "                     1 x 8 x 1024        \n",
       "Linear                                    4195328    True      \n",
       "LayerNorm                                 2048       True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "ReLU                                                           \n",
       "LayerNorm                                 2048       True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "LayerNorm                                 2048       True      \n",
       "____________________________________________________________________________\n",
       "                     1 x 8 x 4096        \n",
       "Linear                                    4198400    True      \n",
       "____________________________________________________________________________\n",
       "                     1 x 8 x 1024        \n",
       "Linear                                    4195328    True      \n",
       "LayerNorm                                 2048       True      \n",
       "LayerNorm                                 2048       True      \n",
       "____________________________________________________________________________\n",
       "                     1 x 8 x 96103       \n",
       "Linear                                    98409472   False     \n",
       "____________________________________________________________________________\n",
       "\n",
       "Total params: 664,465,408\n",
       "Total trainable params: 67,256,320\n",
       "Total non-trainable params: 597,209,088\n",
       "\n",
       "Optimizer used: functools.partial(<function Adam at 0x7f5254243d90>)\n",
       "Loss function: FlattenedLoss of CrossEntropyLoss()\n",
       "\n",
       "Model frozen up to parameter group #2\n",
       "\n",
       "Callbacks:\n",
       "  - TrainEvalCallback\n",
       "  - BaseModelCallback\n",
       "  - CastToTensor\n",
       "  - Recorder\n",
       "  - ProgressCallback"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "      <th>bertscore_precision</th>\n",
       "      <th>bertscore_recall</th>\n",
       "      <th>bertscore_f1</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.998927</td>\n",
       "      <td>3.955342</td>\n",
       "      <td>0.233282</td>\n",
       "      <td>0.089950</td>\n",
       "      <td>0.231544</td>\n",
       "      <td>0.230825</td>\n",
       "      <td>0.890668</td>\n",
       "      <td>0.875131</td>\n",
       "      <td>0.882466</td>\n",
       "      <td>01:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.571942</td>\n",
       "      <td>3.849483</td>\n",
       "      <td>0.261678</td>\n",
       "      <td>0.113552</td>\n",
       "      <td>0.258470</td>\n",
       "      <td>0.259180</td>\n",
       "      <td>0.895343</td>\n",
       "      <td>0.881118</td>\n",
       "      <td>0.887834</td>\n",
       "      <td>01:21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(2, lr_max=1e-4, cbs=fit_cbs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions and taking look at results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>so next we're going to talk about how to prioritize machine learning projects and so what this is going to boil down to is finding problems that are potentially high impact to work on and then trying to assess what the cost of those projects might be so to double click on that a little bit this is you know a general framework that you can think about for how to prioritize projects like nothing machine learning specific here but one way to think about project prioritization is that you want to look for things that are high impact or potentially high impact and are also relatively feasible right so those are the two axes that you might measure potential projects along and you know you might plot your projects on on this kind of two by two and then the ones that are in the upper right corner there's the ones to go and trap right so it's not necessarily an exercise you actually need to do but one way to think about picking projects is looking at what makes projects potentially high impact and what makes them feasible so i think there's no kind of silver bullet answer to finding high impact machine learning projects it depends on your use case and it's just generally hard but i do want to give you a few mental models for how to think about what types of machine learning projects might be high impact and so the four i want to talk about are where can you take advantage of cheap prediction where can you automate complicated where's their friction in your product that you might be able to automate away where can you automate complicated manual processes and then you know the the easiest one maybe is like what are other people doing so one lens to look at this problem with is through economics so there's this book called prediction machines that lays out the case that at a high level what ai enables you to do is it reduces the cost of prediction right so you know where a certain type of prediction might have required like an expert to spend their time to make this prediction you know machine learning allows you to like basically automate that expert into a system that you can run very cheaply and so prediction is essential for decision making and that means that if you have really cheap prediction then predictions give me a lot more places even for problems where it's too expensive before right like most people couldn't like hire a private driver before and so the implication of this if you like take this lens to project selection is to look for projects where cheap prediction could have a huge business impact right so it's a mental rule that you can think that you can think about when you're looking for high priority projects another lens i think is worth looking at is thinking about it from the lens of like what does your product actually need and so this is from an article by spotify which i think of this kind of being like one of the best machine learning driven products and i'll i'll link to this article in a few slides but the thesis that they lay out is that you should really be thinking about machine learning projects from a product perspective and you should be looking for parts of your product experience that are high friction and automating those points of high friction are exactly like where there's a lot of impact for machine learning to to make your business better a third heuristic that you might use is you know in addition to thinking about like the abstract economics of what ai enables and like what could make your product better maybe we should just think about like what is machine learning actually good at like where you know what what are the nails that this that this hammer can actually hit and so for this i like this this software 2.0 blog post by andre kurpathi and you know i think he sums it up nicely in a tweet which is uh gradient descent can write better code than you it's very nice to apologize for for insulting my code like that but to dive into this a little bit more the case that andre lays on this blog post is that what he frames as software 1.0 is kind of what most of us would think of as software right so traditional programs that have explicit instructions that are in most cases written by a human software 2.0 is a different programming paradigm where humans instead of writing code specify goals and then an algorithm that searches for a program that solves those goals and instead of working with code software 2.0 you know programmers instead work with data sets and those data sets get compiled into programs via optimization and you might ask like why do this right and and the answer at least according to andre is that it just works better you know gradient descent can write better code than you but in addition to that it's it's also more general in some sense because we can teach computers to do things that we can't easily articulate as rules ourselves and there are also computational advantages so if if instead of having like all these complicated control flows in our programs they're all just matrix multiplications that we can design better hardware to to suit those types of computations better and so you know putting on our project selection hat here the the implication of this mental model is that you should look for places in your product where or you know the whatever you're working on where there'</td>\n",
       "      <td>Prioritizing Projects (Assessing the feasibility and impact of the projects)</td>\n",
       "      <td>How to prioritize machine learning projects</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_article = \"\"\"hey everybody welcome back this week we're going to talk about something a little bit different than we do most weeks most weeks we talk about specific\n",
    "technical aspects of building machine learning powered products but this week we're going to focus on some of the\n",
    "organizational things that you need to do in order to work together on ml-powered products as part of an\n",
    "interdisciplinary team so the the reality of building ml Power Products is that building any product well is really\n",
    "difficult you have to figure out how to hire grade people you need to be able to manage those people and get the best out\n",
    "of them you need to make sure that your team is all working together towards a shared goal you need to make good\n",
    "long-term technical choices manage technical debt over time you need to make sure that you're managing\n",
    "expectations not just of your own team but also of leadership of your organization and you need to be able to make sure\n",
    "that you're working well within the confines of the requirements of the rest of the org that you're understanding\n",
    "those requirements well and communicating back to your progress to the rest of the organization against those requirements\n",
    "but machine learning adds even more additional complexity to this machine learning Talent tends to be very scarce\n",
    "and expensive to attract machine learning teams are not just a\n",
    "single role but today they tend to be pretty interdisciplinary which makes managing them an even bigger challenge\n",
    "machine learning projects often have unclear timelines and there's a high\n",
    "degree of uncertainty to those timelines machine learning itself is moving super fast and machine learning as we've\n",
    "covered before you can think of as like the high interest credit card of technical debt so keeping up with making\n",
    "good long-term decisions and not incurring too much technical debt is especially difficult in ml unlike\n",
    "traditional software ml is so new that in most organizations leadership tends not to be that well educated in it they\n",
    "might not understand some of the core differences between ML and other technology that you're working with machine learning products tend to fail\n",
    "in ways that are really hard for Lay people to understand and so that makes it very difficult to help the rest of\n",
    "the stakeholders in your organization understand what they could really expect from the technology that you're building\n",
    "and what is realistic for us to achieve so throughout the rest rest of this lecture we're going to kind of touch on\n",
    "some of these themes and cover different aspects of this problem of working together to build ml Power Products as\n",
    "an organization so here are the pieces that we're going to cover we're going to talk about different roles that are involved in building ml products we're\n",
    "going to talk about some of the unique aspects involved in hiring ml Talent\n",
    "we're going to talk about organization of teams and how the ml team tends to fit into the rest of the org and some of\n",
    "the pros and cons of different ways of setting that up we'll talk about managing ml teams and\n",
    "ml product management and then lastly we'll talk about some of the design considerations for how to design a\n",
    "product that is well suited to having a good ml model that backs it so let's dive in and talk about rules the most\n",
    "common ml rules that you might hear of are things like ml product manager ml\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_texts': ['Introduction',\n",
       "   'Work together on ml-powered products',\n",
       "   'Work together on ml-powered products as part of an interdisciplinary team']}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_generate(test_article, num_return_sequences=3, key=\"summary_texts\", max_length=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_texts': ['Introduction', 'Introduction', 'Introduction']}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_generate(\n",
    "    test_article,\n",
    "    do_sample=True,\n",
    "    max_length=20,\n",
    "    top_k=50,\n",
    "    top_p=0.95,\n",
    "    num_return_sequences=3,\n",
    "    key=\"summary_texts\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using BART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('bart',\n",
       " transformers.models.bart.configuration_bart.BartConfig,\n",
       " transformers.models.bart.tokenization_bart_fast.BartTokenizerFast,\n",
       " transformers.models.bart.modeling_bart.BartForConditionalGeneration)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_model_name = \"sshleifer/distilbart-cnn-12-6\"\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(\n",
    "    pretrained_model_name, model_cls=BartForConditionalGeneration\n",
    ")\n",
    "\n",
    "hf_arch, type(hf_config), type(hf_tokenizer), type(hf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_tokenize_tfm = Seq2SeqBatchTokenizeTransform(\n",
    "    hf_arch,\n",
    "    hf_config,\n",
    "    hf_tokenizer,\n",
    "    hf_model,\n",
    "    max_length=1024,\n",
    "    max_target_length=128,\n",
    "    tok_kwargs=tok_kwargs,\n",
    "    text_gen_kwargs=text_gen_kwargs,\n",
    ")\n",
    "\n",
    "blocks = (Seq2SeqTextBlock(batch_tokenize_tfm=batch_tokenize_tfm), noop)\n",
    "\n",
    "dblock = DataBlock(blocks=blocks, get_x=ColReader(\"transcript\"), get_y=ColReader(\"topic\"), splitter=RandomSplitter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;s&gt; little bit bigger you know obviously a super famous artwork and and this is not that he wasn't the first person to illustrate perspective or he wasn't the first person to illustrate this particular biblical scene but he was amongst the first to use perspective to draw it and or to paint it and so previous to this we had medieval painting right which was very kind of stilted and and the space was kind of weirdly ill-defined it looked a lot like children's drawings but just like really really refined children's drawings where everything is a little bit awkward so what is kind of special about this and why it's Malay Nardo's Last Supper is important is that this was painted let me see if we there's a well it was painted in a room and kind of high up in a room on a wall and if you stood all the way back at the far end of the room it created the illusion that this whole scene was happening on that far wall like the the walls and the ceiling and the room that you were physically standing in appeared to continue into the painting and then off into the distance so it was this optical illusion you know you you you would look at it and say well I know that's a flat wall but it seems to kind of go further the painting appears to make the wall look like it's a window into another space right so Leonardo using perspective created this depth so it looks like there's a whole room in behind all of these figures sitting at this table okay so I'm not going to go into too too deep into the history of perspective there's lots of videos and stuff about that that already exists but this is a particularly important painting wasn't the first one but it it you know there was some people using perspective fifty years before this but it definitely is amongst the most famous early examples okay so I'm gonna go back to my handout here so just to kind of continue that there are lots of different kinds of perspective now the first type of perspective we're going to talk about and I'm just gonna talk about those briefly in my in my classes I talked about a little bit longer and we're gonna do we would do an exercise with it but it's gonna be a little challenging for us to do over the web so I'm gonna kind of just breeze through it so this is isometric projection and you've probably seen this many times if you've ever assembled IKEA furniture IKEA furniture is drawn in isometric projection so let's say if I look at this drawing it's image on the bottom right here I'm scum so I'm zoomed in on this here if I was to show you this drawing and say this is the plan for the bathroom I'm going to this is I'm gonna renovate my bathroom and this is what its gonna look like I think you might look at it and say okay I what okay oh this is the sink okay um and what is this here what are these things is this oh is that a shower okay so what is this a so it's not clear right it's a cuz it's drawn from one angle and so we can't really see any dimension in this drawing whereas if we use isometric projection we now see that same I'm able to zoom back out a little bit more here this same image reproduced here but from like a 3/4 review so we're kind of taking this front view and then rotating it so that we can now see the top right if you imagine this being a box like let me see like this box right so we've started from this point of view straight on and then we're kind of now looking at it from this angle so you could see the top and the front side and this side right and you can even kind of imagine what the back side is a little bit right so this allows us to see multiple points of view all at once and if you've it's probably not that many people watching this who have any experience with drafting but this is I took drafting when I was in high school and we spent a lot in before computers and your drawing all this on paper and using rulers in a super analytical and like a very left brain activity right so break like a lot of mathematics and you're always using the calculator and to try to get all this right but so you like an exercise in in a drafting class and exam would be something like this where they would give you the front view of this object the side view and then the top view and they would say illustrate it in an isometric projection from a 3/4 angle right so you this image here would not be visible you'd have to create that from only these three so it's a little bit tricky but all of a sudden this image is a lot clearer to most people than just looking at these three other views right so in when I'm teaching this class in in person what I do is I pass out a little sheet like this and I get people to kind of fill it out right so here's one and then you're just trying to copy it below alright so we kind of made these relatively simple and straightforward just so people can&lt;/s&gt;</td>\n",
       "      <td>Shading a Cylinder 4 Different Ways</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;s&gt; depending on your subject it can be easy or difficult to get the expression you desire to tell the story or to capture the true essence of that person all right let's jump into lightroom now and i'm going to share some photos showing how i've used these compositional rules and techniques all right so this first image of our daughter is not a strong image when it comes to some of the composition techniques we've talked about but the expression is the main compositional technique used by capturing her mood at this point in time during the photo shoot later on in the photo shoot about 20 minutes later she was having enough and she was done so expressions are a great way to tell a story based on the subjects that you're photographing this next image i captured with a mamiya rgb67 about 18 or 19 years ago and although i do have the rule of thirds being applied in here with the couple in the center it's not a very strong composition based on the rule of thirds by itself instead these leading lines on this wall bring us into the image and direct us directly to the couple so i believe the leading lines in this image are the strongest composition technique used in this particular image our next image again not a strong composition really not using the rule of thirds instead we have another great expression telling us the story of this young man's day and i've included enough elements in the image to help tell the story and if you know exactly what he's doing at this time let me know in the comments below this next image is not a very good image it's actually pretty poor it's out of focus and that's because i captured this image at night as you can see at a very slow shutter speed of under one second so i was hand holding this and it created camera shake but i include this image because i want to talk about the composition of this image and how it relates to where you may be going on your vacations or images that you capture in general so as you can see we have a railing in the front we have some leading lines directing us throughout the image as well as these leading lines from inside the top and bottom of the rails here they're kind of curving so if your eye comes down here maybe it picks up one of these curves and it comes back in through the image at different points so it's allowing you to travel across the image from one side to the other top and down behind it you can see there's a lot of lights going on it's kind of hard to see what it is but this is niagara falls now in your lifetime you've probably seen thousands of images from niagara falls and they all pretty much look the same don't they but this image is different from anything else you've ever seen i decided to shoot through the railing and use the railing as a frame and to use the leading lines to direct us throughout the image and i wanted to include the niagara falls as a secondary element to what's going on in the foreground but we still know it's the niagara falls at least now that i've told you or if you've been here before you know this is niagara falls now this is on the canadian side not the american side so my point is you've seen millions of photos of this location and probably other locations too like a lot of locations at yosemite park the grand canyon the eiffel tower etc so all of these locations that are hot spots for tourists are receiving millions of photos taken every year at these locations and they all look the same so my point is try and find something different to stand out from the crowd think of a new different type of composition technique that you can apply to your images to capture that location but to show it in a different light try a different angle different perspective that way your images don't look like everybody else's all right next image here we have the couple on the right side of the rural thirds and we have some leading lines on this bridge that take us throughout the image and back again towards the couple this next image i'm using rule of thirds again her feet are in this quadrant right down here on this point and there's another compositional technique being used as well which is contrast so her dress here and the sand are contrasting from the skin of her feet and the color of her toenails so our eyes tend to come towards her feet because they're different from the large areas of contrast from the dress and the sand now the whiteness of the dress itself is grabbing our eyes attention as well so we come up here and we look around up here but because of the contrast we come back down to this area over here rule of thirds again we have the couple in the left quadrant and the corvette is taking up two thirds of that quadrant now this image could be better the background should have been blurred out even more it looks like i shot at f4 at 28 millimeters so i should have used a larger f-stop like 2.8 or even 1.4 with a 50 millimeter lens i just didn't have an option to shoot at this angle with a larger focal length because i couldn't&lt;/s&gt;</td>\n",
       "      <td>50+ Composition Examples</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;s&gt; here look at all these beautiful photos and drawings paintings cool knitting and I think these are drawings that you want to get you've tagged me in here just if you in the future to tag just add a little visit the apt symbol and in BA in front that way because I I just didn't immediately come up but anyway it's your drawing let's week if we can make that a little bit bigger it gets a little silly when you get too big hmm okay I guess I just can't go to bei I'll have to keep it that size so I could see the whole drawing very cool Heidi um I like this kind of wood texture that you've created here of its it looks like a a tree trunk with almost like a heart shaped like knot in there and then all of those kind of squiggles and patterns in the background I like it Oh a tree with a heart okay that's the title I fit her to read the tale I think the the texture you put on the tree looks fantastic which camera that one there the texture on the tree is fantastic that turned out really really well and the texture around that the heart on the tree is also super effective like and there's a little shadow underneath it that helps that really pop off and the way that you've kind of rounded the pieces so that's really effective I think that there's the tree looks great as it is I think your background looks looks more doodle esque you know it's much more simplified and I would it would be I mean there's some it's something to be said about a contrast between kind of a more refined style and a looser style kind of on the same page together but I in this case I do it makes me do feel like the the doodlee part is it's a little bit detracting from the the the tree trunk like the tree trunk I think is fantastic so I kind of feel like I want to see the background elevated a little bit and you put more attention into the background or and and that could be just adding a little bit more detail into it or darkening it dramatically and I'm not sure you know like there's you but like a question mark and exclamation mark and some other punctuation all of those in you know I'm not sure if they are necessarily complimenting the tree and the heart as much and then the squiggles on the left side that just kind of feels like you're filling in that space I mean I so I if you've you've done such a beautiful job on the tree trunk I kind of wanted to see you'd also apply some of your ability into the other space rather than just filling it up with stuff overall really great drawing I just think it can be better there's whenever I look at my own drawings I always think they can be much better Wow fantastic look at this face doodles so that's wild so this is great it looks like you've you've like taken just this abstract amoeba-like outline and then started filling it in with facial features and then you started doing this shading that we've been talking about today to give it that volume and to make it look three-dimensional and I don't have a lot to add to it I think it's really fantastic it was really great to see your imagination in here and to see like the stitching around lips there the caller how you've done the caller I think is really effective I think if anything areas that could be improved as maybe the I don't know if it's like some tassels or worms or rope or whatever it is it's kind of depend of holding that mask that appears to be I think those look like they could use a little more attention in the hair looks like it could use a little more attention and what I would do especially for the hair is think instead one big block of hair is going in and trying to kind of articulate more hairs in there so as you're shading it you're not just kind of randomly doing this but thinking about like going in and emphasizing that form at the hair that looks great I don't think there's you know especially if this is your what you're doing is a doodle it's really cool what I think is even really neat is there's I guess I the these are supposed to be eyelids right these those look like the intent is for these to be eyelids and eyelashes obviously in my mind however I see this as like a cavity like a what ocular cavity cavity and then the ibis being an eyeball right here and almost like one eyeball shared by both eyes and then this is like the inside of the skull here that's kind of what how and I actually think that looks really cool maybe it's not what you intended if you wanted to make this look more like the eyelid instead of these I would maybe have lines that kind of curve this way around on either side and then maybe de-emphasize this quite hard line in here and this might have been done much softer because this with this really hard outline here it looks more like this is not just a fold in in the eye&lt;/s&gt;</td>\n",
       "      <td>Feedback on Viewer Art</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;s&gt; and the next thing that you're going to do is you're going to go and implement that model and debug your implementation all right so the steps we're going to cover here are first you need to get your model to run it all which sounds easy but it's not always as easy as it sounds then you're going to over fit a single batch of data and once you can overfit a single batch of data then we're going to compare the results of your model to some known result all right so to just give you a quick preview of some of the stuff that we're going to cover here i think in my experience these are five of the most common bugs that tend to come up when you're implementing a deep learning model so one really common one is you have the wrong shapes for your tensors so you know you you're trying to add something that's like three by four together with something that's like three by five usually you're you're like usually this will fail loudly which makes it relatively easy to debug but it's also possible for it to fail silently particularly in tensorflow where you'll have kind of accidental broadcasting when you have shapes that are undefined and so this can be a silent source of bugs it can be very very painful to to find pre-processing inputs incorrectly so forgetting to normalize your inputs or over normalizing your inputs is pretty common source of bugs one other thing that's like really easy to do by accident is to have the wrong input to your loss function so a lot of times the loss function will have we'll expect the just the raw logits of like from your model but you'll take the softmax because that's you know logically what you want the input to be and then you'll get bugs because of that forgetting to set up train mode for the net correctly this again often comes up in batch norm and then various different sources of numerical instability which you know if you're implementing new types of models you'll inevitably spend a lot of time debugging before we go into specific strategies there's a few pieces of sort of general advice that i have when you're implementing a new machine learning model so the first is to start with as lightweight and implementation as you can so adding the minimum possible new lines of code for for version one and so intuitively like the way to think about this is that every line of code that you write is like could possibly have some bugs in it and so if you have fewer lines of code your debugging process is going to be easier because there's going to be fewer places to look for the error and as a rule of thumb i think trying to get your implementation to something less than 200 lines for the first version is is generally a good goal and oftentimes like i would really try to get things to be less than 100 lines but it's not always possible to do that and one other note here this doesn't count like tested infrastructure components so if you have like some infrastructure that you've been using for a lot of different models in your code base then those are fine like don't count those toward your 200 lines another piece of advice is generally try to use off-the-shelf components when you can so for example keras is great for implementing a first version of your model same with pi torch lightning which we're using in the labs using the definitions of layers that are built into your library instead of writing out the math yourself which you know can be tempting to do because you're trying to make a simple lightweight implementation but the the implementations of layers and things like that in these libraries have a lot of the kind of numerical gotchas already taken care of especially in the loss functions and then lastly and this is maybe actually the most important thing is you know a lot of times we're working with massive data sets and so in order to deal with those massive data sets it's important to build kind of like complicated data pipelines that sort of shuttle all the data from you know wherever it's stored to your gpu in an efficient way but i would highly highly recommend starting with a version of your data set that you can load into memory when you start working on a problem and then building those complicated data pipelines later because data pipelines are almost inevitable source of bugs and and so you want to make sure that your model implementation is working well before you add these in okay now let's talk through um the steps here so the first thing that we're gonna do is we're gonna get the model to run there's a few common issues that'll come up here one is you might have a shape mismatch or you might have a casting issue so you know your your model expects floats and you're giving it hints and recommended resolution here is just step through the model creation in you know in like your python model implementation in a debugger and just like inspect the shape and types of the outputs at each step until you get to the point where something is happening that's wrong out of memory issues are another really common source of bugs at this stage and so what i like to do here is just look for all the the operations that are going to be memory intensive so you&lt;/s&gt;</td>\n",
       "      <td>Implement and Debug</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls = dblock.dataloaders(summarization_train_df, bs=4)\n",
    "b = dls.one_batch()\n",
    "dls.show_batch(dataloaders=dls, max_n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "      <th>bertscore_precision</th>\n",
       "      <th>bertscore_recall</th>\n",
       "      <th>bertscore_f1</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.546107</td>\n",
       "      <td>3.186811</td>\n",
       "      <td>0.098343</td>\n",
       "      <td>0.033006</td>\n",
       "      <td>0.088328</td>\n",
       "      <td>0.092021</td>\n",
       "      <td>0.812041</td>\n",
       "      <td>0.868961</td>\n",
       "      <td>0.839343</td>\n",
       "      <td>01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.031897</td>\n",
       "      <td>2.868734</td>\n",
       "      <td>0.099648</td>\n",
       "      <td>0.033584</td>\n",
       "      <td>0.089872</td>\n",
       "      <td>0.095200</td>\n",
       "      <td>0.808950</td>\n",
       "      <td>0.873280</td>\n",
       "      <td>0.839659</td>\n",
       "      <td>00:57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = BaseModelWrapper(hf_model)\n",
    "learn_cbs = [BaseModelCallback]\n",
    "fit_cbs = [Seq2SeqMetricsCallback(custom_metrics=seq2seq_metrics)]\n",
    "\n",
    "learn = Learner(\n",
    "    dls,\n",
    "    model,\n",
    "    opt_func=partial(Adam),\n",
    "    loss_func=CrossEntropyLossFlat(),\n",
    "    cbs=learn_cbs,\n",
    "    splitter=partial(blurr_seq2seq_splitter, arch=hf_arch),\n",
    ")\n",
    "\n",
    "learn.freeze()\n",
    "\n",
    "learn.fit_one_cycle(2, lr_max=1e-4, cbs=fit_cbs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions and taking look at results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all right so we talked about the different roles that go into machine learning organizations next thing that we're going to talk about is how machine learning teams themselves are situated in the context of the larger organization that they're part of so um i went out and had kind of a bunch of conversations with folks about this to understand where where their machine learning teams are situated in their org and how they kind of interact with the rest of the organization the overall lessons learned here are that there isn't really a consensus yet as to what is the right way to structure a machine learning team um different organizations have different practices and different kind of structures seem to work well for different types of organizations and so the goal of this section is really to help is really just like provide kind of a taxonomy of best practices for at different like maturity levels of organizations based on what we've seen so the metaphor that we're going to use is scaling the machine learning organization mountain so starting starting from the bottom the bottom of the mountain we have organizations that have kind of nascent machine learning or maybe they're doing machine learning in some ad hoc way so what does this look like for your organization really this means like no one's doing ml or there's a couple people in the in the organization that are doing it ml and some ad hoc basis you probably have very little machine learning expertise in-house um what kind of organizations fit this bill right now well if you look outside of like silicon valley tech companies and fortune 500 companies most companies are in this category like most kind of small to medium businesses um even ones that do have software teams in-house and especially ones in less technology forward industries tend to be doing very very little machine learning right now maybe there's a couple people in the org that are experimenting with it um you know hard to find advantages of a model like this if you're trying to do ml but one of the big advantages if you're looking to join an organization at this stage is that there's probably low hanging fruit there's probably things that you can go in and do and just have a big impact the big disadvantage of joining an organization at this stage if you want to do ml in the context of the organization is that there's often very little support for machine learning projects the organization itself might not really believe in machine learning they might not feel like there's a mandate to be doing complicated things like machine learning um and so you might be fighting an uphill battle in terms of like convincing people that what you're doing is worth the time it's taking worth the money that it's taking and um actually a good idea and then if your goal is to kind of build out a function in this organization to use machine learning to do good things in this organization it can be really difficult to hire and retain good talent because um in machine learning like in many other technical fields a lot of you know many really talented people want to work with other really talented people and so you can go and work in an organization like this and be the talent magnet but um it's it's going to be you're going to you're going to be fighting against the um the kind of natural tendency of people to want to go where other machine learning people are climbing up the machine learning organization mountain to the next stage um kind of the next stage of uh that many organizations adopt machine learning at is what i would call like ml r d archetype so what does this look like um this is kind of the stage at which the company is you know decided that it's curious about machine learning it's starting to do some research and development um around it it has some pocs and um you know it's starting to invest in it in maybe a more exploratory way to figure out okay is this does this really make sense for our business and in many of these organizations the machine learning effort is centralized into a smaller team that's maybe off somewhere in the research and development arm of the organization and in a lot of cases what this actually corresponds to in terms of the outputs of these teams are since they're not really closely embedded with product teams they're really operating more like researchers they're kind of getting data sets from other parts of the organization they're running experiments on them and they're producing internal reports or maybe external papers that are essentially you know proof of concept that maybe one of these models could be useful in the company so i've seen this a lot in some of the larger industries that are slower tech adopters so oil and gas companies manufacturing companies telecom companies that maybe have an ml research group somewhere but are not actually doing ml at scale yet there's a couple advantages to this model one is that you can often hire pretty experienced researchers into an organization like this because since the the mandate of this like mlr d team is to do research and not to necessarily build actual products that tends to appeal to researchers who want to keep doing the kind of thing that they've been doing and the other big advantage of this i think is pretty underrated is that you can you you know since these teams are not really being held accountable for near-term output let's say they often have the mandate to work</td>\n",
       "      <td>ML Organizations</td>\n",
       "      <td>[ What Is The Right Way To Structure A Machine Learning Team? (ML, ml, ml r d, ML, ml d, etc., etc. etc. Pathways Pathways, and Scaling The ML Mountitioning The ML Mountain (Figuring out the pros and pros and cons,  Comparing Probability of Recidivism vs. Certain Race (without Protected Class Attributes such as race, age, number of years in jail, etc. etc. and number of crimes in the past (without protected class attributes like race) Case Study #1 (Comparing),  Pandas Data Frame Interpretation (Data Frame, Bin Bin Laden, bin Laden, cabin, numpy, etc. etc. and pandas (R-CNN, pandas, python, pi, n-CNN/pyramid, python/p-CNN),  How To Pick a single number to optimize and then baselines to see if your performance on that number is good or not so the main things that we'll cover in choosing a metric in the real world and the process of optimizing a machine learning project (without baselines)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_article = \"\"\"hey everybody welcome back this week we're going to talk about something a little bit different than we do most weeks most weeks we talk about specific\n",
    "technical aspects of building machine learning powered products but this week we're going to focus on some of the\n",
    "organizational things that you need to do in order to work together on ml-powered products as part of an\n",
    "interdisciplinary team so the the reality of building ml Power Products is that building any product well is really\n",
    "difficult you have to figure out how to hire grade people you need to be able to manage those people and get the best out\n",
    "of them you need to make sure that your team is all working together towards a shared goal you need to make good\n",
    "long-term technical choices manage technical debt over time you need to make sure that you're managing\n",
    "expectations not just of your own team but also of leadership of your organization and you need to be able to make sure\n",
    "that you're working well within the confines of the requirements of the rest of the org that you're understanding\n",
    "those requirements well and communicating back to your progress to the rest of the organization against those requirements\n",
    "but machine learning adds even more additional complexity to this machine learning Talent tends to be very scarce\n",
    "and expensive to attract machine learning teams are not just a\n",
    "single role but today they tend to be pretty interdisciplinary which makes managing them an even bigger challenge\n",
    "machine learning projects often have unclear timelines and there's a high\n",
    "degree of uncertainty to those timelines machine learning itself is moving super fast and machine learning as we've\n",
    "covered before you can think of as like the high interest credit card of technical debt so keeping up with making\n",
    "good long-term decisions and not incurring too much technical debt is especially difficult in ml unlike\n",
    "traditional software ml is so new that in most organizations leadership tends not to be that well educated in it they\n",
    "might not understand some of the core differences between ML and other technology that you're working with machine learning products tend to fail\n",
    "in ways that are really hard for Lay people to understand and so that makes it very difficult to help the rest of\n",
    "the stakeholders in your organization understand what they could really expect from the technology that you're building\n",
    "and what is realistic for us to achieve so throughout the rest rest of this lecture we're going to kind of touch on\n",
    "some of these themes and cover different aspects of this problem of working together to build ml Power Products as\n",
    "an organization so here are the pieces that we're going to cover we're going to talk about different roles that are involved in building ml products we're\n",
    "going to talk about some of the unique aspects involved in hiring ml Talent\n",
    "we're going to talk about organization of teams and how the ml team tends to fit into the rest of the org and some of\n",
    "the pros and cons of different ways of setting that up we'll talk about managing ml teams and\n",
    "ml product management and then lastly we'll talk about some of the design considerations for how to design a\n",
    "product that is well suited to having a good ml model that backs it so let's dive in and talk about rules the most\n",
    "common ml rules that you might hear of are things like ml product manager ml\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_texts': [' Building ML Products (ML, ML, etc., etc. Different Ways to Hired ML Talent, Manaching ML Teams, Managing ML Teams and Learning Teams (ML Teams, etc. Learning Talent, Making ML Projects, Managing Teams, Making Technical Debt, Making Good Technical Choices',\n",
       "   ' Building ML Products (ML, ML, etc., etc. Different Ways to Hired ML Talent, Manaching ML Teams, Managing ML Teams and Learning Teams (ML Teams, etc. Learning Talent, Making ML Projects, Managing Teams, Making Technical Debt, Making Good Technical Decisions',\n",
       "   ' Building ML Products (ML, ML, etc., etc. Different Ways to Hired ML Talent, Manaching ML Teams, Managing ML Teams and Learning Teams (ML Teams, etc. Learning Talent, Making ML Projects, Managing ML Projects and Managing ML Projects (ML)']}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_generate(test_article, num_return_sequences=3, key=\"summary_texts\", max_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_texts': [' Building ML Products (ML, ML, etc. Organizational Roles, Hiring ML Talent, Manaching ML Teams, Managing ML Teams and Designing a ML Product (without Traditional Hardware) The Common ML Talent Pathways (ML) and Learning Talent (ML Teams)',\n",
       "   ' Building ML Products (ML, ML, etc. Organizational Roles, ML Talent, Technical Debt, ML Projects, and etc. Different Ways to Hired ML Talent & Design ML Products. ML Teams. ML Talent Hiring ML Teams vs. Lay Workers',\n",
       "   ' Building ML Products (ML, ML, etc., etc. ML, ML and other ML Partnerships & Hiring ML Talent & Managing ML Partners (ML Partnerships, etc. Different Ways to Hired ML Talent, Training ML Partners, Managing ML Teams and Different Roles']}]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_generate(\n",
    "    test_article,\n",
    "    do_sample=True,\n",
    "    max_length=128,\n",
    "    top_k=50,\n",
    "    top_p=0.95,\n",
    "    num_return_sequences=3,\n",
    "    key=\"summary_texts\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T5 architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('t5',\n",
       " transformers.models.t5.configuration_t5.T5Config,\n",
       " transformers.models.t5.tokenization_t5_fast.T5TokenizerFast,\n",
       " transformers.models.t5.modeling_t5.T5ForConditionalGeneration)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_model_name = \"t5-small\"\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(pretrained_model_name, model_cls=T5ForConditionalGeneration)\n",
    "\n",
    "hf_arch, type(hf_config), type(hf_tokenizer), type(hf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_tokenize_tfm = Seq2SeqBatchTokenizeTransform(\n",
    "    hf_arch,\n",
    "    hf_config,\n",
    "    hf_tokenizer,\n",
    "    hf_model,\n",
    "    max_length=1024,\n",
    "    max_target_length=128,\n",
    "    tok_kwargs=tok_kwargs,\n",
    "    text_gen_kwargs=text_gen_kwargs,\n",
    ")\n",
    "\n",
    "blocks = (Seq2SeqTextBlock(batch_tokenize_tfm=batch_tokenize_tfm), noop)\n",
    "\n",
    "dblock = DataBlock(blocks=blocks, get_x=ColReader(\"transcript\"), get_y=ColReader(\"topic\"), splitter=RandomSplitter())\n",
    "dls = dblock.dataloaders(summarization_train_df, bs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "      <th>bertscore_precision</th>\n",
       "      <th>bertscore_recall</th>\n",
       "      <th>bertscore_f1</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.613483</td>\n",
       "      <td>3.647889</td>\n",
       "      <td>0.119634</td>\n",
       "      <td>0.033613</td>\n",
       "      <td>0.113095</td>\n",
       "      <td>0.113229</td>\n",
       "      <td>0.839792</td>\n",
       "      <td>0.850511</td>\n",
       "      <td>0.844703</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.762565</td>\n",
       "      <td>3.472579</td>\n",
       "      <td>0.131414</td>\n",
       "      <td>0.031813</td>\n",
       "      <td>0.128218</td>\n",
       "      <td>0.128023</td>\n",
       "      <td>0.852144</td>\n",
       "      <td>0.858542</td>\n",
       "      <td>0.854714</td>\n",
       "      <td>00:21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    }
   ],
   "source": [
    "model = BaseModelWrapper(hf_model)\n",
    "learn_cbs = [BaseModelCallback]\n",
    "fit_cbs = [Seq2SeqMetricsCallback(custom_metrics=seq2seq_metrics)]\n",
    "\n",
    "learn = Learner(\n",
    "    dls,\n",
    "    model,\n",
    "    opt_func=partial(Adam),\n",
    "    loss_func=CrossEntropyLossFlat(),\n",
    "    cbs=learn_cbs,\n",
    "    splitter=partial(blurr_seq2seq_splitter, arch=hf_arch),\n",
    ")\n",
    "\n",
    "learn.freeze()\n",
    "\n",
    "learn.fit_one_cycle(2, lr_max=1e-4, cbs=fit_cbs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions and taking look at results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all right next category of tests that we're going to talk about are integration tests between your training system and your prediction system so these are tests that are meant to to evaluate how good a job your training system did at producing a new model that performs well when it's placed in the context of your prediction system so really what these tests are trying to do is they're trying to make sure that the new model the train is like ready to go in production and so this is going to be the bulk of i think what is unique about testing machine learning systems how do you go about doing this we'll go into more details about some of these things but at high level you want to evaluate your model on all of the metrics all the data sets and all the slices of data that you care about and you want to compare that performance that evaluation between your old model and your baseline models and then you want to try to understand the performance envelope of your model which at a high level means you want to understand where your model is going to perform well and where it's not going to perform well what types of data might cause your model not perform well and operationally when do you want to run these tests you want to run these tests whenever you have a new candidate model like a new model that you're thinking about okay is this should i put this model into production or not so the important thing to know about evaluation tests is that this is more than just your validation score right so in particular you want to look at not only just your your kind of your loss or whatever the main metric that you're optimizing is but you want to look at all the metrics that you care about and so where might those metrics come from there could be a bunch of different metrics that are associated with your model so instead of just accuracy you might also look at precision and recall and other model metrics there's behavioral tests robustness tests privacy and fairness tests and simulation tests those are some of the other categories and i'll talk a little bit more about each of these so first what are behavioral tests the goal of behavior behavioral tests is that when you test your model in a fixed data set that tells you like okay an aggregate how well is the model doing but what it doesn't tell you is does the model have the behavior that you would expect it to have does it in particular does it treat perturbations of the data in the way that we intuitively expect that the model should treat those perturbations so there's different types of behavioral tests one is called an invariance test and so what you test in an invariance test is you assert that when you change an input that shouldn't affect the output so for example like if you're if you're doing nlp then the sentiment so the example here on the right under category b is testing sentiment and the the invariance that you're trying to test is that if you change the city or the like the location that of a tweet that's like about an airline that shouldn't change the sentiment so like someone's saying oh i had this terrible experience in chicago should have the same sentiment as someone saying i had this terrible experience in barcelona that's an invariance test there's directional tests so category c on the right and what directional tests do is they say okay when i change this input i expect it to change the output of the model and i expect it to change the output of the model in this particular way so for example if you take a really negative word and you make it really positive then you might expect that the sentiment classifier that you're using would flip its assessment of that sentiment from negative to positive [Music] and then third category is called minimum functionality tests and so what these do are they allow you to test whether certain inputs and outputs that you know what result that they should have when they're combined together actually have that result the example they use here is if you write a sentence like i negation followed by a negation like can't or didn't or won't followed by a positive verb recommend or like something like that followed by the thing then there are certain rules that you should expect those sentences to follow about whether the sentiment is positive or negative so you can generate data that follows those rules and tests whether and test whether the the model follows them or not so behavioral testing metrics this is actually a relatively new idea it's mostly used in nlp right now and it was proposed in this this paper that's linked below and so this is not something that you'll see a ton in practice but is a pretty promising idea in nlp in particular that is worth knowing that if you're working in that domain all right next talk about robustness metrics so the goal here</td>\n",
       "      <td>Evaluation Tests</td>\n",
       "      <td>[- - - - - - - - - , Using a model architecture, . . . . . . . . . , - a convolutional approach to sequence data]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_article = \"\"\"hey everybody welcome back this week we're going to talk about something a little bit different than we do most weeks most weeks we talk about specific\n",
    "technical aspects of building machine learning powered products but this week we're going to focus on some of the\n",
    "organizational things that you need to do in order to work together on ml-powered products as part of an\n",
    "interdisciplinary team so the the reality of building ml Power Products is that building any product well is really\n",
    "difficult you have to figure out how to hire grade people you need to be able to manage those people and get the best out\n",
    "of them you need to make sure that your team is all working together towards a shared goal you need to make good\n",
    "long-term technical choices manage technical debt over time you need to make sure that you're managing\n",
    "expectations not just of your own team but also of leadership of your organization and you need to be able to make sure\n",
    "that you're working well within the confines of the requirements of the rest of the org that you're understanding\n",
    "those requirements well and communicating back to your progress to the rest of the organization against those requirements\n",
    "but machine learning adds even more additional complexity to this machine learning Talent tends to be very scarce\n",
    "and expensive to attract machine learning teams are not just a\n",
    "single role but today they tend to be pretty interdisciplinary which makes managing them an even bigger challenge\n",
    "machine learning projects often have unclear timelines and there's a high\n",
    "degree of uncertainty to those timelines machine learning itself is moving super fast and machine learning as we've\n",
    "covered before you can think of as like the high interest credit card of technical debt so keeping up with making\n",
    "good long-term decisions and not incurring too much technical debt is especially difficult in ml unlike\n",
    "traditional software ml is so new that in most organizations leadership tends not to be that well educated in it they\n",
    "might not understand some of the core differences between ML and other technology that you're working with machine learning products tend to fail\n",
    "in ways that are really hard for Lay people to understand and so that makes it very difficult to help the rest of\n",
    "the stakeholders in your organization understand what they could really expect from the technology that you're building\n",
    "and what is realistic for us to achieve so throughout the rest rest of this lecture we're going to kind of touch on\n",
    "some of these themes and cover different aspects of this problem of working together to build ml Power Products as\n",
    "an organization so here are the pieces that we're going to cover we're going to talk about different roles that are involved in building ml products we're\n",
    "going to talk about some of the unique aspects involved in hiring ml Talent\n",
    "we're going to talk about organization of teams and how the ml team tends to fit into the rest of the org and some of\n",
    "the pros and cons of different ways of setting that up we'll talk about managing ml teams and\n",
    "ml product management and then lastly we'll talk about some of the design considerations for how to design a\n",
    "product that is well suited to having a good ml model that backs it so let's dive in and talk about rules the most\n",
    "common ml rules that you might hear of are things like ml product manager ml\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_texts': 'Machine learning'}]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_generate(test_article, num_return_sequences=1, key=\"summary_texts\", max_length=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_texts': ['Machine Learning',\n",
       "   'A few points in line with technology',\n",
       "   'ml Power Products']}]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_generate(\n",
    "    test_article,\n",
    "    do_sample=True,\n",
    "    max_length=100,\n",
    "    top_k=50,\n",
    "    top_p=0.95,\n",
    "    num_return_sequences=3,\n",
    "    key=\"summary_texts\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit Test code from blurr library\n",
    "\n",
    "Based on [From blurr code](https://github.com/ohmeow/blurr/blob/master/nbs/21_text-modeling-seq2seq-summarization.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_names = [\n",
    "    \"facebook/bart-base\",\n",
    "    #'facebook/blenderbot_small-90M',\n",
    "    \"allenai/led-base-16384\",\n",
    "    #     \"sshleifer/tiny-mbart\",\n",
    "    #     \"google/mt5-small\",\n",
    "    #     \"sshleifer/distill-pegasus-cnn-16-4\",\n",
    "    \"t5-small\",\n",
    "    #'microsoft/prophetnet-large-uncased',\n",
    "    #'microsoft/xprophetnet-large-wiki100-cased', # XLMProphetNet\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== facebook/bart-base ===\n",
      "\n",
      "architecture:\tbart\n",
      "tokenizer:\tBartTokenizerFast\n",
      "model:\t\tBartForConditionalGeneration\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.476376</td>\n",
       "      <td>3.071012</td>\n",
       "      <td>0.333383</td>\n",
       "      <td>0.190513</td>\n",
       "      <td>0.324846</td>\n",
       "      <td>0.326800</td>\n",
       "      <td>01:09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>learning and i think this is in many ways the the most intriguing one because up to maybe three years ago unsupervised learning was i would say a pure research thing and nobody would really be putting it into practice and then as of about two and a half years ago things started working so well that it pretty much immediately became practice so deep supervised learning the kind of more default way of doing machine learning it works uh but it requires a lot of annotated data you need data where y</td>\n",
       "      <td>Unsupervised Learning</td>\n",
       "      <td>[ Unsupervised Learning,  Viewer Perspective]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== allenai/led-base-16384 ===\n",
      "\n",
      "architecture:\tled\n",
      "tokenizer:\tLEDTokenizerFast\n",
      "model:\t\tLEDForConditionalGeneration\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.475409</td>\n",
       "      <td>3.151190</td>\n",
       "      <td>0.246533</td>\n",
       "      <td>0.093958</td>\n",
       "      <td>0.246726</td>\n",
       "      <td>0.246382</td>\n",
       "      <td>01:30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>learning and i think this is in many ways the the most intriguing one because up to maybe three years ago unsupervised learning was i would say a pure research thing and nobody would really be putting it into practice and then as of about two and a half years ago things started working so well that it pretty much immediately became practice so deep supervised learning the kind of more default way of doing machine learning it works uh but it requires a lot of annotated data you need data where yo</td>\n",
       "      <td>Unsupervised Learning</td>\n",
       "      <td>[What is deep supervised learning, Distribution]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== t5-small ===\n",
      "\n",
      "architecture:\tt5\n",
      "tokenizer:\tT5TokenizerFast\n",
      "model:\t\tT5ForConditionalGeneration\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.753005</td>\n",
       "      <td>3.298381</td>\n",
       "      <td>0.180253</td>\n",
       "      <td>0.065604</td>\n",
       "      <td>0.167540</td>\n",
       "      <td>0.167951</td>\n",
       "      <td>00:57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>so next we're going to talk about how to prioritize machine learning projects and so what this is going to boil down to is finding problems that are potentially high impact to work on and then trying to assess what the cost of those projects might be so to double click on that a little bit this is you know a general framework that you can think about for how to prioritize projects like nothing machine learning specific here but one way to think about project prioritization is that you want to lo</td>\n",
       "      <td>Prioritizing Projects (Assessing the feasibility and impact of the projects)</td>\n",
       "      <td>[Project Prioritization, I think the doodlee part]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_cls = AutoModelForSeq2SeqLM\n",
    "bsz = 2\n",
    "inp_seq_sz = 512\n",
    "trg_seq_sz = 40\n",
    "\n",
    "test_results = []\n",
    "for model_name in pretrained_model_names:\n",
    "    error = None\n",
    "\n",
    "    print(f\"=== {model_name} ===\\n\")\n",
    "\n",
    "    hf_tok_kwargs = {}\n",
    "    if model_name == \"sshleifer/tiny-mbart\":\n",
    "        hf_tok_kwargs[\"src_lang\"], hf_tok_kwargs[\"tgt_lang\"] = \"en_XX\", \"en_XX\"\n",
    "\n",
    "    hf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(\n",
    "        model_name, model_cls=model_cls, tokenizer_kwargs=hf_tok_kwargs\n",
    "    )\n",
    "\n",
    "    print(f\"architecture:\\t{hf_arch}\\ntokenizer:\\t{type(hf_tokenizer).__name__}\\nmodel:\\t\\t{type(hf_model).__name__}\\n\")\n",
    "\n",
    "    # 1. build your DataBlock\n",
    "    text_gen_kwargs = {}\n",
    "    if hf_arch in [\"bart\", \"t5\"]:\n",
    "        text_gen_kwargs = {**hf_config.task_specific_params[\"summarization\"], **{\"max_length\": 40, \"min_length\": 5}}\n",
    "\n",
    "    # not all \"summarization\" parameters are for the model.generate method ... remove them here\n",
    "    generate_func_args = list(inspect.signature(hf_model.generate).parameters.keys())\n",
    "    for k in text_gen_kwargs.copy():\n",
    "        if k not in generate_func_args:\n",
    "            del text_gen_kwargs[k]\n",
    "\n",
    "    if hf_arch == \"mbart\":\n",
    "        text_gen_kwargs[\"decoder_start_token_id\"] = hf_tokenizer.get_vocab()[\"en_XX\"]\n",
    "\n",
    "    def add_t5_prefix(inp):\n",
    "        return f\"summarize: {inp}\" if (hf_arch == \"t5\") else inp\n",
    "\n",
    "    batch_tokenize_tfm = Seq2SeqBatchTokenizeTransform(\n",
    "        hf_arch,\n",
    "        hf_config,\n",
    "        hf_tokenizer,\n",
    "        hf_model,\n",
    "        padding=\"max_length\",\n",
    "        max_length=inp_seq_sz,\n",
    "        max_target_length=trg_seq_sz,\n",
    "        text_gen_kwargs=text_gen_kwargs,\n",
    "    )\n",
    "\n",
    "    blocks = (Seq2SeqTextBlock(batch_tokenize_tfm=batch_tokenize_tfm), noop)\n",
    "    dblock = DataBlock(\n",
    "        blocks=blocks, get_x=ColReader(\"transcript\"), get_y=ColReader(\"topic\"), splitter=RandomSplitter()\n",
    "    )\n",
    "\n",
    "    dls = dblock.dataloaders(summarization_train_df, bs=bsz)\n",
    "    b = dls.one_batch()\n",
    "\n",
    "    # 2. build your Learner\n",
    "    seq2seq_metrics = {\n",
    "        \"rouge\": {\n",
    "            \"compute_kwargs\": {\"rouge_types\": [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"], \"use_stemmer\": True},\n",
    "            \"returns\": [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"],\n",
    "        }\n",
    "    }\n",
    "\n",
    "    model = BaseModelWrapper(hf_model)\n",
    "    learn_cbs = [BaseModelCallback]\n",
    "    fit_cbs = [Seq2SeqMetricsCallback(custom_metrics=seq2seq_metrics)]\n",
    "\n",
    "    learn = Learner(\n",
    "        dls,\n",
    "        model,\n",
    "        opt_func=ranger,\n",
    "        loss_func=PreCalculatedCrossEntropyLoss(),\n",
    "        cbs=learn_cbs,\n",
    "        splitter=partial(blurr_seq2seq_splitter, arch=hf_arch),\n",
    "    ).to_fp16()\n",
    "\n",
    "    learn.create_opt()\n",
    "    learn.freeze()\n",
    "\n",
    "    # 3. Run your tests\n",
    "    try:\n",
    "        print(\"*** TESTING DataLoaders ***\\n\")\n",
    "        test_eq(len(b), 2)\n",
    "        test_eq(len(b[0][\"input_ids\"]), bsz)\n",
    "        test_eq(b[0][\"input_ids\"].shape, torch.Size([bsz, inp_seq_sz]))\n",
    "        test_eq(len(b[1]), bsz)\n",
    "\n",
    "        #         print('*** TESTING One pass through the model ***')\n",
    "        #         preds = learn.model(b[0])\n",
    "        #         test_eq(preds[1].shape[0], bsz)\n",
    "        #         test_eq(preds[1].shape[2], hf_config.vocab_size)\n",
    "\n",
    "        print(\"*** TESTING Training/Results ***\")\n",
    "        learn.fit_one_cycle(1, lr_max=1e-3, cbs=fit_cbs)\n",
    "\n",
    "        test_results.append((hf_arch, type(hf_tokenizer).__name__, type(hf_model).__name__, \"PASSED\", \"\"))\n",
    "        learn.show_results(learner=learn, max_n=2, input_trunc_at=500, target_trunc_at=250)\n",
    "    except Exception as err:\n",
    "        test_results.append((hf_arch, type(hf_tokenizer).__name__, type(hf_model).__name__, \"FAILED\", err))\n",
    "    finally:\n",
    "        # cleanup\n",
    "        del learn\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "4c27d0eb0116998fc328b5a00abe6956c11e30aa3cb3ca27ff0ca511f067786d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
