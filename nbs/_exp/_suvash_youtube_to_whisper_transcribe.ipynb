{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee8cf162-c809-4418-94e9-b13a7d3bd80d",
   "metadata": {},
   "source": [
    "## Set the youtube URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f18c1a8-0d86-4f29-9a19-b930425325d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "YT_URL=\"https://www.youtube.com/watch?v=Jsz4E2iNXUA\"\n",
    "EMBED_URL=\"https://www.youtube.com/embed/Jsz4E2iNXUA\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff09c39-c0f2-42f7-b9da-570b9c5d4a91",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Download video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1d3322d-06f4-42b5-95f6-b8e854300737",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytube in /conda/envs/py310-cuda116/lib/python3.10/site-packages (12.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pytube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f83209-7728-4fbf-a973-21c6883e60d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "373eeb3c-edbf-4b09-8cdc-004b7a180f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79222bdb-3e8e-4c5c-bbcc-ccef42074098",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytube import YouTube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcd2fd81-efbd-48bb-bf8f-f2437534038d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_youtube_audio(url: str, fetch_path: Path) -> Path:\n",
    "    ext = 'mp4'\n",
    "    order = 'abr'\n",
    "    \n",
    "    yt = YouTube(url)\n",
    "    yt.check_availability()\n",
    "    \n",
    "    filename = f\"{yt.video_id}.{ext}\"\n",
    "    download_path = fetch_path/filename\n",
    "    \n",
    "    audio_streams = yt.streams.filter(only_audio=True, file_extension=ext).order_by(order).desc()\n",
    "    # download it\n",
    "    audio_streams.first().download(filename=download_path, skip_existing=True)\n",
    "    \n",
    "    return download_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9f4a34f-70ab-4e58-b94e-fadd9b5e1143",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_files_path = Path('./audio_files')\n",
    "audio_files_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2be4949e-0882-46e7-91f6-37242ad6a8f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('audio_files/Jsz4E2iNXUA.mp4')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downloaded_audio_file = fetch_youtube_audio(YT_URL, audio_files_path)\n",
    "downloaded_audio_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e714fbf-c71e-43e2-a236-aa1800e3c06c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d546520a-1716-40b5-91dc-733e252c3b53",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Transcribe with Whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "781a9da5-98f0-430e-9c55-0141334c6398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apt update && apt install git ffmpeg --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d26b58e-4911-43d3-9c63-bffb33fe3482",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/whisper.git\n",
      "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-cu6ip6ei\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-cu6ip6ei\n",
      "  Resolved https://github.com/openai/whisper.git to commit deafef05f33179b8dd865893eb4705b513f906dc\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /conda/envs/py310-cuda116/lib/python3.10/site-packages (from whisper==1.0) (1.23.1)\n",
      "Requirement already satisfied: torch in /conda/envs/py310-cuda116/lib/python3.10/site-packages (from whisper==1.0) (1.12.1+cu116)\n",
      "Requirement already satisfied: tqdm in /conda/envs/py310-cuda116/lib/python3.10/site-packages (from whisper==1.0) (4.64.0)\n",
      "Requirement already satisfied: more-itertools in /conda/envs/py310-cuda116/lib/python3.10/site-packages (from whisper==1.0) (8.14.0)\n",
      "Requirement already satisfied: transformers>=4.19.0 in /conda/envs/py310-cuda116/lib/python3.10/site-packages (from whisper==1.0) (4.21.1)\n",
      "Requirement already satisfied: ffmpeg-python==0.2.0 in /conda/envs/py310-cuda116/lib/python3.10/site-packages (from whisper==1.0) (0.2.0)\n",
      "Requirement already satisfied: future in /conda/envs/py310-cuda116/lib/python3.10/site-packages (from ffmpeg-python==0.2.0->whisper==1.0) (0.18.2)\n",
      "Requirement already satisfied: requests in /conda/envs/py310-cuda116/lib/python3.10/site-packages (from transformers>=4.19.0->whisper==1.0) (2.28.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /conda/envs/py310-cuda116/lib/python3.10/site-packages (from transformers>=4.19.0->whisper==1.0) (21.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /conda/envs/py310-cuda116/lib/python3.10/site-packages (from transformers>=4.19.0->whisper==1.0) (0.12.1)\n",
      "Requirement already satisfied: filelock in /conda/envs/py310-cuda116/lib/python3.10/site-packages (from transformers>=4.19.0->whisper==1.0) (3.8.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /conda/envs/py310-cuda116/lib/python3.10/site-packages (from transformers>=4.19.0->whisper==1.0) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /conda/envs/py310-cuda116/lib/python3.10/site-packages (from transformers>=4.19.0->whisper==1.0) (2022.7.25)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /conda/envs/py310-cuda116/lib/python3.10/site-packages (from transformers>=4.19.0->whisper==1.0) (0.8.1)\n",
      "Requirement already satisfied: typing-extensions in /conda/envs/py310-cuda116/lib/python3.10/site-packages (from torch->whisper==1.0) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /conda/envs/py310-cuda116/lib/python3.10/site-packages (from packaging>=20.0->transformers>=4.19.0->whisper==1.0) (3.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /conda/envs/py310-cuda116/lib/python3.10/site-packages (from requests->transformers>=4.19.0->whisper==1.0) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /conda/envs/py310-cuda116/lib/python3.10/site-packages (from requests->transformers>=4.19.0->whisper==1.0) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /conda/envs/py310-cuda116/lib/python3.10/site-packages (from requests->transformers>=4.19.0->whisper==1.0) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /conda/envs/py310-cuda116/lib/python3.10/site-packages (from requests->transformers>=4.19.0->whisper==1.0) (2.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/openai/whisper.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34a7e03e-92ea-44f5-b86f-9e0c55d16c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "243d7dbc-5636-4848-97e0-8738b301b35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import whisper\n",
    "from whisper.utils import write_vtt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3508effc-2a27-4ffc-859c-5b75750f07dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab6bfb9e-4525-4732-a952-ff9986ea3404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tiny.en',\n",
       " 'tiny',\n",
       " 'base.en',\n",
       " 'base',\n",
       " 'small.en',\n",
       " 'small',\n",
       " 'medium.en',\n",
       " 'medium',\n",
       " 'large']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whisper.available_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2aa72ce-feef-44dd-885d-43e7bd8bd2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "WHISPER_HOME = os.environ['WHISPER_HOME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5a4f6de-5e0a-447e-92cd-892513b72a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "WHISPER_MODEL_NAME = 'base'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0695de3d-bbdf-47e5-9c98-f249f8f5b189",
   "metadata": {},
   "outputs": [],
   "source": [
    "WHISPER_MODEL = whisper.load_model(WHISPER_MODEL_NAME, device=torch_device, download_root=WHISPER_HOME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bcafbf26-880e-490b-a78a-6299ab07f3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio_to_vtt(audio_path: Path, transcribe_path: Path, model=WHISPER_MODEL) -> Path:\n",
    "    stem = audio_path.stem\n",
    "    ext = 'vtt'\n",
    "    \n",
    "    filename = f\"{audio_path.stem}.{ext}\"\n",
    "    vtt_path = transcribe_path/filename\n",
    "\n",
    "    fields = ['start', 'end', 'text']\n",
    "    \n",
    "    result = model.transcribe(str(audio_path))\n",
    "    segments = result['segments']\n",
    "    \n",
    "    with open(vtt_path, \"w\", encoding=\"utf-8\") as vtt:\n",
    "            write_vtt(segments, file=vtt)\n",
    "\n",
    "    return vtt_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "673dd885-5d45-4163-b8a7-f4d00b47501f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription_files_path = Path('./transcription_files')\n",
    "transcription_files_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7c45548-a799-4a86-8923-cfd8a3f5b5fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('transcription_files/Jsz4E2iNXUA.vtt')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcription_file = transcribe_audio_to_vtt(downloaded_audio_file, transcription_files_path)\n",
    "transcription_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43711653-6f16-4ebd-b9d3-cf48d85d8946",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee0e6242-3c25-4bcc-88f6-6205a1c01881",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Render the transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45c8fcb1-ee98-4f2e-8a32-f826f781c97b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: webvtt-py in /conda/envs/py310-cuda116/lib/python3.10/site-packages (0.4.6)\n",
      "Requirement already satisfied: docopt in /conda/envs/py310-cuda116/lib/python3.10/site-packages (from webvtt-py) (0.6.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install webvtt-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b5819e7b-1d50-41a6-8331-80687357585d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import webvtt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b24c398-e3fb-488c-9f41-c7ad3e3d50d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "70064d07-3853-4842-be1b-d41551fc44aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"450\"\n",
       "            src=\"https://www.youtube.com/embed/Jsz4E2iNXUA\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fbf482db550>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(EMBED_URL, width=800, height=450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e83b9a6e-5708-4470-bd7f-ace473f36253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:10:23.360 00:10:27.760  There's another dataset that's presented in the course, which is interesting because\n",
      "00:10:27.760 00:10:33.800  it actually just uses Amazon reviews and it uses the title of the review as the summary\n",
      "00:10:33.800 00:10:41.120  you want to predict and the body of the review as the context.\n",
      "00:10:41.120 00:10:47.000  And definitely one thing to know is if you're actually building a summarization model, you\n",
      "00:10:47.000 00:10:52.320  really want to understand your particular dataset.\n",
      "00:10:52.320 00:10:56.240  And especially you want to look at the length of the summaries.\n",
      "00:10:56.240 00:11:01.440  So the CNN Daily Mail, like the summaries are multiple highlights.\n",
      "00:11:01.440 00:11:05.200  So like there are like one sentence highlights all concatenated together.\n",
      "00:11:05.200 00:11:12.560  But if you're working with the dataset where the summaries are just like themes or very\n",
      "00:11:12.560 00:11:18.240  succinct like short summaries, you may have to do more training if you start with something\n",
      "00:11:18.240 00:11:23.000  like the CNN, like something trained on the CNN Daily Mail dataset.\n",
      "00:11:23.000 00:11:28.200  Or you may want to look at some other datasets out there and find something that's a little\n",
      "00:11:28.200 00:11:32.920  bit more in line with that particular type of task.\n",
      "00:11:32.920 00:11:40.520  For translation, I've worked with the WMT16 datasets and there's actually a bunch of subsets\n",
      "00:11:40.520 00:11:44.760  and they include translations from one language to another.\n",
      "00:11:44.760 00:11:49.960  And so if you look at the blur documentation, you'll see that I play with the German to\n",
      "00:11:49.960 00:11:51.200  English subset.\n",
      "00:11:51.200 00:11:54.960  And what's nice is that you can just, if you want to do English to German, you just reverse\n",
      "00:11:54.960 00:11:59.760  the targets and inputs and you're good to go.\n",
      "00:11:59.760 00:12:05.280  So we'll go ahead and look at this collab here that we'll share it also at the end of\n",
      "00:12:05.280 00:12:07.400  the session.\n",
      "00:12:07.400 00:12:16.120  And I'm going to load up the kind of usual packages library.\n",
      "00:12:16.120 00:12:23.280  So datasets, transformers, the dev 2.0 latest from blur.\n",
      "00:12:23.280 00:12:28.880  And I'm also going to install some other things that we'll look at later and particularly\n",
      "00:12:28.880 00:12:33.120  are useful when calculating sequence to sequence metrics.\n",
      "00:12:33.120 00:12:36.160  And I'm going to import everything.\n",
      "00:12:36.160 00:12:42.680  And for this particular example, we're going to just for the sake of time, focus on looking\n",
      "00:12:42.680 00:12:45.440  at the summarization task.\n",
      "00:12:45.440 00:12:49.840  And like I said, we'll cover the differences between the two where they're relevant, but\n",
      "00:12:49.840 00:12:52.000  fundamentally they're the same.\n",
      "00:12:52.000 00:12:58.840  And so I like to play around with doing different ways of working with the datasets library.\n",
      "00:12:58.840 00:13:06.080  And so for experimentation, I'd like to work with a very small set of data and you may\n",
      "00:13:06.080 00:13:07.720  not get the best results.\n",
      "00:13:07.720 00:13:14.240  But it's a good way to iterate quickly and build your training and evaluation loops before\n",
      "00:13:14.240 00:13:19.840  you let something run for hours or days only to find out that it blows up and it gets\n",
      "00:13:19.840 00:13:21.720  to the evaluation stuff.\n",
      "00:13:21.720 00:13:26.200  And so this is kind of a nice little trick with datasets where you can say, I just want\n",
      "00:13:26.200 00:13:32.040  to pull 1,000 examples from the training set.\n",
      "00:13:32.040 00:13:35.080  And so that's what I'm going to do here.\n",
      "00:13:35.080 00:13:39.320  And I'm just going to work with a data frame.\n"
     ]
    }
   ],
   "source": [
    "for caption in webvtt.read(transcription_file)[160:200]:\n",
    "    print(caption.start, caption.end, caption.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0154fecf-e342-4cb1-ab47-276dd200c4e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
