{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast, os, gc, pdb, random, time\n",
    "\n",
    "from fastai.callback.all import *\n",
    "from fastai.data.block import CategoryBlock, ColReader, ColSplitter, DataBlock, IndexSplitter, RegressionBlock\n",
    "from fastai.imports import *\n",
    "from fastai.layers import SigmoidRange\n",
    "from fastai.learner import *\n",
    "from fastai.losses import CrossEntropyLossFlat, MSELossFlat, LabelSmoothingCrossEntropyFlat\n",
    "from fastai.optimizer import Adam\n",
    "from fastai.metrics import *\n",
    "from fastai.torch_core import *\n",
    "from fastai.torch_imports import *\n",
    "from fastcore.transform import Transform\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForNextSentencePrediction,\n",
    "    AutoModelForSequenceClassification,\n",
    "    DebertaV2Model,\n",
    "    logging,\n",
    ")\n",
    "from transformers.models.deberta_v2.modeling_deberta_v2 import ContextPooler\n",
    "from transformers.models.deberta_v2.modeling_deberta_v2 import StableDropout\n",
    "\n",
    "from blurr.callbacks import GradientCheckpointing\n",
    "from blurr.text.data.core import TextBlock, BatchTokenizeTransform\n",
    "from blurr.text.modeling.core import BaseModelWrapper, BaseModelCallback, blurr_splitter\n",
    "from blurr.text.utils import get_hf_objects\n",
    "from blurr.utils import PreCalculatedCrossEntropyLoss, PreCalculatedMSELoss, set_seed\n",
    "\n",
    "# silence all the HF warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "logging.set_verbosity_error()\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU #0: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "gpu_num = 0\n",
    "\n",
    "torch.cuda.set_device(gpu_num)\n",
    "print(f\"Using GPU #{torch.cuda.current_device()}: {torch.cuda.get_device_name()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 2022\n",
    "val_pct = 0.25\n",
    "bsz = 8\n",
    "data_subset_pct = 1.0\n",
    "\n",
    "# HF objects\n",
    "model_checkpoint = \"microsoft/deberta-v3-small\"\n",
    "model_cls = AutoModelForSequenceClassification\n",
    "\n",
    "# model_checkpoint = \"bert-base-uncased\"\n",
    "# model_cls = AutoModelForNextSentencePrediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25383\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>course_title</th>\n",
       "      <th>lesson_num</th>\n",
       "      <th>topic</th>\n",
       "      <th>seq</th>\n",
       "      <th>next_seq</th>\n",
       "      <th>is_topic_end</th>\n",
       "      <th>next_topic_begin_seq</th>\n",
       "      <th>other_topic_seqs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>C-Squared Podcast</td>\n",
       "      <td>1</td>\n",
       "      <td>Intro</td>\n",
       "      <td>[Music] welcome everybody to episode one of a</td>\n",
       "      <td>chess themed podcast with myself christian kirilla and i'm fighting on caruana so what's up</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[christian well not so much fabi uh it's first of all great um to finally start a, podcast the chess podcast i know that um there's a lot of podcasts out there but, i wanted to bring our own tune to the mix and i think uh yeah i'm, excited about that so that's uh the first thing how about yourself fabian well i'm back in the states after it's, been a while at your home it's good to be here it's my first time in uh visiting here and uh, yeah it's been an interesting few months played a lot of chess which is pretty cool but, also a bit difficult at times my home uh here we are not going to m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>C-Squared Podcast</td>\n",
       "      <td>1</td>\n",
       "      <td>Intro</td>\n",
       "      <td>chess themed podcast with myself christian kirilla and i'm fighting on caruana so what's up</td>\n",
       "      <td>christian well not so much fabi uh it's first of all great um to finally start a</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[Music] welcome everybody to episode one of a, podcast the chess podcast i know that um there's a lot of podcasts out there but, i wanted to bring our own tune to the mix and i think uh yeah i'm, excited about that so that's uh the first thing how about yourself fabian well i'm back in the states after it's, been a while at your home it's good to be here it's my first time in uh visiting here and uh, yeah it's been an interesting few months played a lot of chess which is pretty cool but, also a bit difficult at times my home uh here we are not going to mention the location because, those ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>C-Squared Podcast</td>\n",
       "      <td>1</td>\n",
       "      <td>Intro</td>\n",
       "      <td>christian well not so much fabi uh it's first of all great um to finally start a</td>\n",
       "      <td>podcast the chess podcast i know that um there's a lot of podcasts out there but</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[Music] welcome everybody to episode one of a, chess themed podcast with myself christian kirilla and i'm fighting on caruana so what's up, i wanted to bring our own tune to the mix and i think uh yeah i'm, excited about that so that's uh the first thing how about yourself fabian well i'm back in the states after it's, been a while at your home it's good to be here it's my first time in uh visiting here and uh, yeah it's been an interesting few months played a lot of chess which is pretty cool but, also a bit difficult at times my home uh here we are not going to mention the location beca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>C-Squared Podcast</td>\n",
       "      <td>1</td>\n",
       "      <td>Intro</td>\n",
       "      <td>podcast the chess podcast i know that um there's a lot of podcasts out there but</td>\n",
       "      <td>i wanted to bring our own tune to the mix and i think uh yeah i'm</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[Music] welcome everybody to episode one of a, chess themed podcast with myself christian kirilla and i'm fighting on caruana so what's up, christian well not so much fabi uh it's first of all great um to finally start a, excited about that so that's uh the first thing how about yourself fabian well i'm back in the states after it's, been a while at your home it's good to be here it's my first time in uh visiting here and uh, yeah it's been an interesting few months played a lot of chess which is pretty cool but, also a bit difficult at times my home uh here we are not going to mention th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>C-Squared Podcast</td>\n",
       "      <td>1</td>\n",
       "      <td>Intro</td>\n",
       "      <td>i wanted to bring our own tune to the mix and i think uh yeah i'm</td>\n",
       "      <td>excited about that so that's uh the first thing how about yourself fabian well i'm back in the states after it's</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[Music] welcome everybody to episode one of a, chess themed podcast with myself christian kirilla and i'm fighting on caruana so what's up, christian well not so much fabi uh it's first of all great um to finally start a, podcast the chess podcast i know that um there's a lot of podcasts out there but, been a while at your home it's good to be here it's my first time in uh visiting here and uh, yeah it's been an interesting few months played a lot of chess which is pretty cool but, also a bit difficult at times my home uh here we are not going to mention the location because, those uh cra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index       course_title lesson_num  topic  \\\n",
       "0      0  C-Squared Podcast          1  Intro   \n",
       "1      1  C-Squared Podcast          1  Intro   \n",
       "2      2  C-Squared Podcast          1  Intro   \n",
       "3      3  C-Squared Podcast          1  Intro   \n",
       "4      4  C-Squared Podcast          1  Intro   \n",
       "\n",
       "                                                                                           seq  \\\n",
       "0                                                [Music] welcome everybody to episode one of a   \n",
       "1  chess themed podcast with myself christian kirilla and i'm fighting on caruana so what's up   \n",
       "2             christian well not so much fabi uh it's first of all great um to finally start a   \n",
       "3             podcast the chess podcast i know that um there's a lot of podcasts out there but   \n",
       "4                            i wanted to bring our own tune to the mix and i think uh yeah i'm   \n",
       "\n",
       "                                                                                                           next_seq  \\\n",
       "0                       chess themed podcast with myself christian kirilla and i'm fighting on caruana so what's up   \n",
       "1                                  christian well not so much fabi uh it's first of all great um to finally start a   \n",
       "2                                  podcast the chess podcast i know that um there's a lot of podcasts out there but   \n",
       "3                                                 i wanted to bring our own tune to the mix and i think uh yeah i'm   \n",
       "4  excited about that so that's uh the first thing how about yourself fabian well i'm back in the states after it's   \n",
       "\n",
       "   is_topic_end next_topic_begin_seq  \\\n",
       "0         False                  NaN   \n",
       "1         False                  NaN   \n",
       "2         False                  NaN   \n",
       "3         False                  NaN   \n",
       "4         False                  NaN   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          other_topic_seqs  \n",
       "0  [christian well not so much fabi uh it's first of all great um to finally start a, podcast the chess podcast i know that um there's a lot of podcasts out there but, i wanted to bring our own tune to the mix and i think uh yeah i'm, excited about that so that's uh the first thing how about yourself fabian well i'm back in the states after it's, been a while at your home it's good to be here it's my first time in uh visiting here and uh, yeah it's been an interesting few months played a lot of chess which is pretty cool but, also a bit difficult at times my home uh here we are not going to m...  \n",
       "1  [[Music] welcome everybody to episode one of a, podcast the chess podcast i know that um there's a lot of podcasts out there but, i wanted to bring our own tune to the mix and i think uh yeah i'm, excited about that so that's uh the first thing how about yourself fabian well i'm back in the states after it's, been a while at your home it's good to be here it's my first time in uh visiting here and uh, yeah it's been an interesting few months played a lot of chess which is pretty cool but, also a bit difficult at times my home uh here we are not going to mention the location because, those ...  \n",
       "2  [[Music] welcome everybody to episode one of a, chess themed podcast with myself christian kirilla and i'm fighting on caruana so what's up, i wanted to bring our own tune to the mix and i think uh yeah i'm, excited about that so that's uh the first thing how about yourself fabian well i'm back in the states after it's, been a while at your home it's good to be here it's my first time in uh visiting here and uh, yeah it's been an interesting few months played a lot of chess which is pretty cool but, also a bit difficult at times my home uh here we are not going to mention the location beca...  \n",
       "3  [[Music] welcome everybody to episode one of a, chess themed podcast with myself christian kirilla and i'm fighting on caruana so what's up, christian well not so much fabi uh it's first of all great um to finally start a, excited about that so that's uh the first thing how about yourself fabian well i'm back in the states after it's, been a while at your home it's good to be here it's my first time in uh visiting here and uh, yeah it's been an interesting few months played a lot of chess which is pretty cool but, also a bit difficult at times my home uh here we are not going to mention th...  \n",
       "4  [[Music] welcome everybody to episode one of a, chess themed podcast with myself christian kirilla and i'm fighting on caruana so what's up, christian well not so much fabi uh it's first of all great um to finally start a, podcast the chess podcast i know that um there's a lot of podcasts out there but, been a while at your home it's good to be here it's my first time in uh visiting here and uh, yeah it's been an interesting few months played a lot of chess which is pretty cool but, also a bit difficult at times my home uh here we are not going to mention the location because, those uh cra...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_df = pd.read_csv(\"../../data/clean/segmentation_train.csv\", index_col=None)\n",
    "raw_train_df[\"other_topic_seqs\"] = raw_train_df[\"other_topic_seqs\"].apply(ast.literal_eval)\n",
    "raw_train_df.reset_index(inplace=True)\n",
    "\n",
    "print(len(raw_train_df))\n",
    "raw_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"so to start let's talk about how to address underfitting so how how do we reduce bias and here are some strategies that you\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_df[\"seq\"].sample(n=1).values[0].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Eval split\n",
    "\n",
    "For training we need to remove sequences for which there is not a \"next_seq\" (e.g., we are at end of a topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24786\n"
     ]
    }
   ],
   "source": [
    "train_df = raw_train_df[raw_train_df[\"is_topic_end\"] == False].copy()\n",
    "print(len(train_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation set should ideally ***not*** include courses in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we were just concerned with creating a validation set and nothing else\n",
    "_, val_idxs = train_test_split(range(len(train_df)), test_size=val_pct, random_state=random_seed)\n",
    "\n",
    "\n",
    "# # shuffle dataset - optional subset for faster iteration\n",
    "# train_df = train_df.sample(frac=data_subset_pct, random_state=random_seed).reset_index(drop=True)\n",
    "\n",
    "# courses = train_df[\"course_title\"].unique()\n",
    "\n",
    "# np.random.seed(random_seed)\n",
    "# np.random.shuffle(courses)\n",
    "\n",
    "# val_sz = int(len(courses) * val_pct)\n",
    "# val_courses = courses[:val_sz]\n",
    "\n",
    "# is_val = np.isin(train_df[\"course_title\"], val_courses)\n",
    "\n",
    "# idxs = np.arange(len(train_df))\n",
    "# val_idxs = idxs[is_val]\n",
    "# trn_idxs = idxs[~is_val]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HF objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if random_seed:\n",
    "    set_seed(random_seed)\n",
    "\n",
    "    # need to create configuration object separately because we may be adding new attributes (e.g., cls_dropout)\n",
    "    hf_config = AutoConfig.from_pretrained(model_checkpoint)\n",
    "    hf_config.update({})\n",
    "\n",
    "    hf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(\n",
    "        model_checkpoint,\n",
    "        model_cls=model_cls,\n",
    "        config=hf_config,\n",
    "        tokenizer_kwargs={},\n",
    "        model_kwargs={},\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseBatchTokenizeTransform(BatchTokenizeTransform):\n",
    "    def __init__(self, use_next_pos_prob=0.75, use_adjacent_neg_prob=0.5, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.use_next_pos_prob = use_next_pos_prob\n",
    "        self.use_adjacent_neg_prob = use_adjacent_neg_prob\n",
    "\n",
    "    def encodes(self, samples, return_batch_encoding=False):\n",
    "        # our positive example\n",
    "        pos_ex_idx = 0 if random.uniform(0, 1) < self.use_next_pos_prob else 1\n",
    "        updated_samples1, inputs1 = super().encodes(\n",
    "            [(s[0][pos_ex_idx] if s[0][pos_ex_idx] != \"xxNONExx\" else s[0][0], *s[2:], *s[2:]) for s in samples],\n",
    "            return_batch_encoding=True,\n",
    "        )\n",
    "\n",
    "        # our negative example (sometimes the adjacent will be \"\"; if that is the case use the other topic negative example which is at idx=1)\n",
    "        neg_ex_idx = 0 if random.uniform(0, 1) < self.use_adjacent_neg_prob and pos_ex_idx == 0 else 1\n",
    "        updated_samples2, inputs2 = super().encodes(\n",
    "            [(s[1][neg_ex_idx] if s[1][neg_ex_idx] != \"xxNONExx\" else s[1][1], *s[2:]) for s in samples],\n",
    "            return_batch_encoding=True,\n",
    "        )\n",
    "\n",
    "        # if there are no targets (e.g., when used for inference)\n",
    "        if len(samples[0]) == 2:\n",
    "            return [(inps1[0], inps2[0]) for inps1, inps2 in zip(updated_samples1, updated_samples2)]\n",
    "\n",
    "        return [(inps1[0], inps2[0], inps1[-1]) for inps1, inps2 in zip(updated_samples1, updated_samples2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pos_inputs(example, tok_sep_token=\"[SEP]\", lower_case=True):\n",
    "    seq_text = example[\"seq\"].strip().lower() if lower_case else example[\"seq\"].strip()\n",
    "    next_seq_text = example[\"next_seq\"].strip().lower() if lower_case else example[\"next_seq\"].strip()\n",
    "\n",
    "    non_adjacent_text = (\n",
    "        random.choice(example[\"other_topic_seqs\"]).strip() if len(example[\"other_topic_seqs\"]) > 0 else None\n",
    "    )\n",
    "    if lower_case and non_adjacent_text:\n",
    "        non_adjacent_text = non_adjacent_text.lower()\n",
    "\n",
    "    if example[\"is_topic_end\"] and example[\"next_topic_begin_seq\"] and non_adjacent_text:\n",
    "        # this is the last sequence in the topic so the only thing that will work here is to pair it with another non-adjacent seq in the same topic\n",
    "        # and therefore we just duplicate it here.\n",
    "        next_topic_begin_seq = (\n",
    "            example[\"next_topic_begin_seq\"].strip().lower() if lower_case else example[\"next_topic_begin_seq\"].strip()\n",
    "        )\n",
    "        inp = (f\"{seq_text}{tok_sep_token}{non_adjacent_text}\", f\"{seq_text}{tok_sep_token}{non_adjacent_text}\")\n",
    "    else:\n",
    "        # the positive pair will be a seq + the next seq -or- the seq + a non-adjacent seq in the same topic\n",
    "        inp = (\n",
    "            f\"{seq_text}{tok_sep_token}{next_seq_text}\",\n",
    "            f\"{seq_text}{tok_sep_token}{non_adjacent_text}\" if non_adjacent_text else \"xxNONExx\",\n",
    "        )\n",
    "\n",
    "    return inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_neg_inputs(example, tok_sep_token=\"[SEP]\", lower_case=True):\n",
    "    seq_text = example[\"seq\"].strip()\n",
    "\n",
    "    # if at the last sequence for a topic, set the negative pair = seq + first sequence in next topic,\n",
    "    # else get a sequence that is not adjacent but in same topic\n",
    "    if example[\"is_topic_end\"] and example[\"next_topic_begin_seq\"]:\n",
    "        neg_seq_non_adjacent_text = example[\"next_topic_begin_seq\"].strip()\n",
    "    elif len(example[\"other_topic_seqs\"]) > 0:\n",
    "        neg_seq_non_adjacent_text = random.choice(example[\"other_topic_seqs\"]).strip()\n",
    "    else:\n",
    "        neg_seq_non_adjacent_text = \"xxNONExx\"\n",
    "\n",
    "    # get a sequence that is in an entirely different topic\n",
    "    # option 1: can be in same lesson but different topic or in a different course entirely\n",
    "    # neg_seq_other_topic_text = (\n",
    "    #     train_df[\"seq\"][\n",
    "    #         (train_df[\"course_title\"] != example[\"course_title\"]) | (train_df[\"lesson_num\"] != example[\"lesson_num\"])\n",
    "    #     ]\n",
    "    #     .sample(n=1)\n",
    "    #     .values[0]\n",
    "    #     .strip()\n",
    "    # )\n",
    "\n",
    "    # option 2: sample from a different course entirely\n",
    "    neg_seq_other_topic_text = (\n",
    "        train_df[\"seq\"][(train_df[\"course_title\"] != example[\"course_title\"])].sample(n=1).values[0].strip()\n",
    "    )\n",
    "\n",
    "    if lower_case:\n",
    "        seq_text = seq_text.lower()\n",
    "        neg_seq_non_adjacent_text = neg_seq_non_adjacent_text.lower()\n",
    "        neg_seq_other_topic_text = neg_seq_other_topic_text.lower()\n",
    "\n",
    "    # our SiameseBatchTokenizeTransform will choose which one to use each time the item is fetched\n",
    "    inp = (\n",
    "        f\"{seq_text}{tok_sep_token}{neg_seq_non_adjacent_text}\",\n",
    "        f\"{seq_text}{tok_sep_token}{neg_seq_other_topic_text}\",\n",
    "    )\n",
    "\n",
    "    return inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_targets(example):\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dls(df, hf_arch, hf_config, hf_tokenizer, hf_model, val_idxs, get_x=None):\n",
    "    # define validation set\n",
    "    splitter = IndexSplitter(val_idxs)\n",
    "\n",
    "    if random_seed:\n",
    "        set_seed(random_seed)\n",
    "\n",
    "    batch_tokenize_tfm = SiameseBatchTokenizeTransform(\n",
    "        use_adjacent_neg_prob=0.75,\n",
    "        hf_arch=hf_arch,\n",
    "        hf_config=hf_config,\n",
    "        hf_tokenizer=hf_tokenizer,\n",
    "        hf_model=hf_model,\n",
    "        include_labels=False,\n",
    "        max_length=True,\n",
    "        truncation=True,\n",
    "        tok_kwargs={},\n",
    "    )\n",
    "\n",
    "    blocks = (TextBlock(batch_tokenize_tfm=batch_tokenize_tfm), noop, CategoryBlock)\n",
    "\n",
    "    get_pos_x = partial(build_pos_inputs, tok_sep_token=hf_tokenizer.sep_token, lower_case=True)\n",
    "    get_neg_x = partial(build_neg_inputs, tok_sep_token=hf_tokenizer.sep_token, lower_case=True)\n",
    "    get_y = partial(build_targets)\n",
    "\n",
    "    dblock = DataBlock(\n",
    "        blocks=blocks,\n",
    "        get_x=[get_pos_x, get_neg_x],\n",
    "        get_y=get_y,\n",
    "        splitter=splitter,\n",
    "        n_inp=2,\n",
    "    )\n",
    "\n",
    "    if random_seed:\n",
    "        set_seed(random_seed)\n",
    "\n",
    "    return dblock.dataloaders(df, bs=bsz, val_bs=bsz * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = get_dls(train_df, hf_arch, hf_config, hf_tokenizer, hf_model, val_idxs=val_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = dls.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[CLS] is... i showed my six-year-old daughter, she's like: “what are you doing dad?”, like, i'm coding, “what are you coding?” oh, you know, dog cat classifier. she checks it out and her first question is:[SEP] “can i take your keyboard for a moment”, and she goes to google, and she's like: what is a dog mixed with a cat called. like, there's no such thing as a dog mixed with a cat. anyway, she goes[SEP]\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_tokenizer.decode(b[0][\"input_ids\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[CLS] is... i showed my six-year-old daughter, she's like: “what are you doing dad?”, like, i'm coding, “what are you coding?” oh, you know, dog cat classifier. she checks it out and her first question is:[SEP] but running on our own box — classifier. so let's check: dog, so you can[SEP][PAD][PAD][PAD][PAD][PAD]\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_tokenizer.decode(b[1][\"input_ids\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorCategory([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blurr_splitter_with_head(m: Module):\n",
    "    \"\"\"Simply adds an additional layer group to the classification head\"\"\"\n",
    "    base_param_groups = blurr_splitter(m)\n",
    "\n",
    "    added_groups = L([m for m_name, m in list(m.named_children()) if m_name != \"hf_model\"])\n",
    "    added_param_groups = added_groups.map(params).filter(lambda el: len(el) > 0)\n",
    "\n",
    "    return base_param_groups + added_param_groups\n",
    "\n",
    "\n",
    "def blurr_splitter_on_backbone(m: Module):\n",
    "    \"\"\"Creates two layer groups: One for the backbone and one for the pooler/classification head\"\"\"\n",
    "    root_modules = list(m.named_children())\n",
    "    top_module_name, top_module = root_modules[0]\n",
    "\n",
    "    groups = L(top_module)\n",
    "    groups += L([m for m_name, m in root_modules[1:]])\n",
    "\n",
    "    return groups.map(params).filter(lambda el: len(el) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Review PyTorch docs (https://pytorch.org/docs/stable/generated/torch.nn.MarginRankingLoss.html); consider changing\n",
    "def MarginRankingLoss(pos_neg_scores, targs):\n",
    "    margin = 1\n",
    "    p_scores, n_scores = pos_neg_scores\n",
    "\n",
    "    scores = margin - p_scores + n_scores\n",
    "    scores = scores.clamp(min=0)\n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(inps, targs):\n",
    "    labels = []\n",
    "    all_pos_scores, all_neg_scores = inps[0], inps[1]\n",
    "\n",
    "    for i in range(len(all_pos_scores)):\n",
    "        if all_pos_scores[i] > all_neg_scores[i]:\n",
    "            labels.append(1)\n",
    "        else:\n",
    "            labels.append(0)\n",
    "\n",
    "    return sum(labels) / float(len(all_pos_scores))\n",
    "\n",
    "\n",
    "_f1_score = AvgMetric(f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TopicSegmentationModelWrapper(BaseModelWrapper):\n",
    "    def __init__(\n",
    "        self,\n",
    "        hf_config,\n",
    "        hf_model,\n",
    "        dropout_cls=nn.Dropout,\n",
    "        p=0.1,\n",
    "        hf_model_kwargs={},\n",
    "    ):\n",
    "        super().__init__(hf_model=hf_model, output_hidden_states=True, hf_model_kwargs=hf_model_kwargs)\n",
    "        store_attr()\n",
    "\n",
    "        self.coherence_prediction_dec = nn.Sequential(\n",
    "            *[\n",
    "                nn.Linear(hf_config.hidden_size, hf_config.hidden_size),\n",
    "                nn.ReLU(),\n",
    "                dropout_cls(p=p),\n",
    "                nn.Linear(hf_config.hidden_size, 2),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs1, inputs2):\n",
    "        # sequence 1 (pos examples)\n",
    "        inputs1_res = super().forward(inputs1)\n",
    "        pos_scores = inputs1_res.hidden_states[-1][:, 0, :]\n",
    "        pos_scores = self.coherence_prediction_dec(pos_scores)\n",
    "\n",
    "        # sequence 2 (neg examples)\n",
    "        inputs2_res = super().forward(inputs2)\n",
    "        neg_scores = inputs2_res.hidden_states[-1][:, 0, :]\n",
    "        neg_scores = self.coherence_prediction_dec(neg_scores)\n",
    "\n",
    "        return pos_scores[:, 0], neg_scores[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if random_seed:\n",
    "    set_seed(random_seed)\n",
    "\n",
    "learn_cbs = []\n",
    "fit_cbs = [GradientClip(max_norm=1.0)]\n",
    "\n",
    "blurr_model_wrapper = TopicSegmentationModelWrapper(hf_config=hf_config, hf_model=hf_model)\n",
    "\n",
    "learn = Learner(\n",
    "    dls,\n",
    "    blurr_model_wrapper,\n",
    "    loss_func=MarginRankingLoss,\n",
    "    metrics=[_f1_score],\n",
    "    cbs=learn_cbs,\n",
    "    splitter=blurr_splitter_on_backbone,\n",
    ")\n",
    "\n",
    "learn.create_opt()\n",
    "learn.freeze()\n",
    "learn = learn.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(len(learn.opt.param_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(minimum=0.0005248074419796466, steep=0.05754399299621582, valley=0.0008317637839354575, slide=0.0010000000474974513)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.unfreeze()\n",
    "learn.lr_find(suggest_funcs=[minimum, steep, valley, slide])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.509273</td>\n",
       "      <td>0.371147</td>\n",
       "      <td>0.849443</td>\n",
       "      <td>05:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.312491</td>\n",
       "      <td>0.306344</td>\n",
       "      <td>0.878328</td>\n",
       "      <td>05:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.377234</td>\n",
       "      <td>0.253131</td>\n",
       "      <td>0.897531</td>\n",
       "      <td>05:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.261739</td>\n",
       "      <td>0.252422</td>\n",
       "      <td>0.900274</td>\n",
       "      <td>05:51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if random_seed:\n",
    "    set_seed(random_seed)\n",
    "\n",
    "learn.fit_one_cycle(4, slice(1e-5, 1e-3), cbs=fit_cbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((#5) ['epoch','train_loss','valid_loss','f1_score','time'],\n",
       " [(#3) [0.5092725157737732,0.3711467683315277,0.8494432790059706],\n",
       "  (#3) [0.31249114871025085,0.30634400248527527,0.8783282233338713],\n",
       "  (#3) [0.37723371386528015,0.253131240606308,0.8975310634177828],\n",
       "  (#3) [0.26173877716064453,0.2524218261241913,0.9002743262869131]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = learn.recorder\n",
    "r.metric_names, r.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export(\"topic_segmentation_learner.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C-Squared Podcast',\n",
       " 'Full Stack Deep Learning - Spring 2021',\n",
       " 'ali - how to start a business',\n",
       " 'cc - how to invest in stocks',\n",
       " 'dr berg - adrenal body type',\n",
       " 'dr berg - cereal vid',\n",
       " 'dr berg - diabetes myth',\n",
       " 'dr berg - how to fast',\n",
       " 'dr berg - what happens when you fast',\n",
       " 'fast.ai 2022 - Part 1',\n",
       " 'markowskyart - begginer drawing course',\n",
       " 'parker - learn photography']"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_df.course_title.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_course_title = random.choice(train_df.iloc[val_idxs][\"course_title\"].unique().tolist())\n",
    "# val_course_title\n",
    "\n",
    "val_course_title = \"Full Stack Deep Learning - Spring 2021\"\n",
    "val_lesson_num = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "627\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>course_title</th>\n",
       "      <th>lesson_num</th>\n",
       "      <th>topic</th>\n",
       "      <th>seq</th>\n",
       "      <th>next_seq</th>\n",
       "      <th>is_topic_end</th>\n",
       "      <th>next_topic_begin_seq</th>\n",
       "      <th>other_topic_seqs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2613</td>\n",
       "      <td>2613</td>\n",
       "      <td>Full Stack Deep Learning - Spring 2021</td>\n",
       "      <td>3</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>okay so so let's dive in and talk about recurrent neural networks um and so recurrent neural networks at a</td>\n",
       "      <td>high level um this is sort of like an analog in some sense for convolutional neural networks</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[uh for sequence data um and you know that idea of being similar right that we're going to try to exploit some structure, about the data that's coming into the model um in this case the fact that the data is coming in in the sequence to build a more efficient, neural net architecture um hang on a second, all right so what we're going to cover today um first we'll talk about sequence problems and just what are some of the types of, problems you can solve with these architectures then we'll talk about recurrent neural networks which are the main family of, architectures we'll be talking abou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2614</td>\n",
       "      <td>2614</td>\n",
       "      <td>Full Stack Deep Learning - Spring 2021</td>\n",
       "      <td>3</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>high level um this is sort of like an analog in some sense for convolutional neural networks</td>\n",
       "      <td>uh for sequence data um and you know that idea of being similar right that we're going to try to exploit some structure</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[okay so so let's dive in and talk about recurrent neural networks um and so recurrent neural networks at a, about the data that's coming into the model um in this case the fact that the data is coming in in the sequence to build a more efficient, neural net architecture um hang on a second, all right so what we're going to cover today um first we'll talk about sequence problems and just what are some of the types of, problems you can solve with these architectures then we'll talk about recurrent neural networks which are the main family of, architectures we'll be talking about today and w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2615</td>\n",
       "      <td>2615</td>\n",
       "      <td>Full Stack Deep Learning - Spring 2021</td>\n",
       "      <td>3</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>uh for sequence data um and you know that idea of being similar right that we're going to try to exploit some structure</td>\n",
       "      <td>about the data that's coming into the model um in this case the fact that the data is coming in in the sequence to build a more efficient</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[okay so so let's dive in and talk about recurrent neural networks um and so recurrent neural networks at a, high level um this is sort of like an analog in some sense for convolutional neural networks, neural net architecture um hang on a second, all right so what we're going to cover today um first we'll talk about sequence problems and just what are some of the types of, problems you can solve with these architectures then we'll talk about recurrent neural networks which are the main family of, architectures we'll be talking about today and we'll talk about some of the problems with rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2616</td>\n",
       "      <td>2616</td>\n",
       "      <td>Full Stack Deep Learning - Spring 2021</td>\n",
       "      <td>3</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>about the data that's coming into the model um in this case the fact that the data is coming in in the sequence to build a more efficient</td>\n",
       "      <td>neural net architecture um hang on a second</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[okay so so let's dive in and talk about recurrent neural networks um and so recurrent neural networks at a, high level um this is sort of like an analog in some sense for convolutional neural networks, uh for sequence data um and you know that idea of being similar right that we're going to try to exploit some structure, all right so what we're going to cover today um first we'll talk about sequence problems and just what are some of the types of, problems you can solve with these architectures then we'll talk about recurrent neural networks which are the main family of, architectures we'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2617</td>\n",
       "      <td>2617</td>\n",
       "      <td>Full Stack Deep Learning - Spring 2021</td>\n",
       "      <td>3</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>neural net architecture um hang on a second</td>\n",
       "      <td>all right so what we're going to cover today um first we'll talk about sequence problems and just what are some of the types of</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[okay so so let's dive in and talk about recurrent neural networks um and so recurrent neural networks at a, high level um this is sort of like an analog in some sense for convolutional neural networks, uh for sequence data um and you know that idea of being similar right that we're going to try to exploit some structure, about the data that's coming into the model um in this case the fact that the data is coming in in the sequence to build a more efficient, problems you can solve with these architectures then we'll talk about recurrent neural networks which are the main family of, archite...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   level_0  index                            course_title lesson_num  \\\n",
       "0     2613   2613  Full Stack Deep Learning - Spring 2021          3   \n",
       "1     2614   2614  Full Stack Deep Learning - Spring 2021          3   \n",
       "2     2615   2615  Full Stack Deep Learning - Spring 2021          3   \n",
       "3     2616   2616  Full Stack Deep Learning - Spring 2021          3   \n",
       "4     2617   2617  Full Stack Deep Learning - Spring 2021          3   \n",
       "\n",
       "          topic  \\\n",
       "0  Introduction   \n",
       "1  Introduction   \n",
       "2  Introduction   \n",
       "3  Introduction   \n",
       "4  Introduction   \n",
       "\n",
       "                                                                                                                                         seq  \\\n",
       "0                                 okay so so let's dive in and talk about recurrent neural networks um and so recurrent neural networks at a   \n",
       "1                                               high level um this is sort of like an analog in some sense for convolutional neural networks   \n",
       "2                    uh for sequence data um and you know that idea of being similar right that we're going to try to exploit some structure   \n",
       "3  about the data that's coming into the model um in this case the fact that the data is coming in in the sequence to build a more efficient   \n",
       "4                                                                                                neural net architecture um hang on a second   \n",
       "\n",
       "                                                                                                                                    next_seq  \\\n",
       "0                                               high level um this is sort of like an analog in some sense for convolutional neural networks   \n",
       "1                    uh for sequence data um and you know that idea of being similar right that we're going to try to exploit some structure   \n",
       "2  about the data that's coming into the model um in this case the fact that the data is coming in in the sequence to build a more efficient   \n",
       "3                                                                                                neural net architecture um hang on a second   \n",
       "4            all right so what we're going to cover today um first we'll talk about sequence problems and just what are some of the types of   \n",
       "\n",
       "   is_topic_end next_topic_begin_seq  \\\n",
       "0         False                  NaN   \n",
       "1         False                  NaN   \n",
       "2         False                  NaN   \n",
       "3         False                  NaN   \n",
       "4         False                  NaN   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          other_topic_seqs  \n",
       "0  [uh for sequence data um and you know that idea of being similar right that we're going to try to exploit some structure, about the data that's coming into the model um in this case the fact that the data is coming in in the sequence to build a more efficient, neural net architecture um hang on a second, all right so what we're going to cover today um first we'll talk about sequence problems and just what are some of the types of, problems you can solve with these architectures then we'll talk about recurrent neural networks which are the main family of, architectures we'll be talking abou...  \n",
       "1  [okay so so let's dive in and talk about recurrent neural networks um and so recurrent neural networks at a, about the data that's coming into the model um in this case the fact that the data is coming in in the sequence to build a more efficient, neural net architecture um hang on a second, all right so what we're going to cover today um first we'll talk about sequence problems and just what are some of the types of, problems you can solve with these architectures then we'll talk about recurrent neural networks which are the main family of, architectures we'll be talking about today and w...  \n",
       "2  [okay so so let's dive in and talk about recurrent neural networks um and so recurrent neural networks at a, high level um this is sort of like an analog in some sense for convolutional neural networks, neural net architecture um hang on a second, all right so what we're going to cover today um first we'll talk about sequence problems and just what are some of the types of, problems you can solve with these architectures then we'll talk about recurrent neural networks which are the main family of, architectures we'll be talking about today and we'll talk about some of the problems with rec...  \n",
       "3  [okay so so let's dive in and talk about recurrent neural networks um and so recurrent neural networks at a, high level um this is sort of like an analog in some sense for convolutional neural networks, uh for sequence data um and you know that idea of being similar right that we're going to try to exploit some structure, all right so what we're going to cover today um first we'll talk about sequence problems and just what are some of the types of, problems you can solve with these architectures then we'll talk about recurrent neural networks which are the main family of, architectures we'...  \n",
       "4  [okay so so let's dive in and talk about recurrent neural networks um and so recurrent neural networks at a, high level um this is sort of like an analog in some sense for convolutional neural networks, uh for sequence data um and you know that idea of being similar right that we're going to try to exploit some structure, about the data that's coming into the model um in this case the fact that the data is coming in in the sequence to build a more efficient, problems you can solve with these architectures then we'll talk about recurrent neural networks which are the main family of, archite...  "
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_df = raw_train_df[\n",
    "    (raw_train_df[\"course_title\"] == val_course_title) & (raw_train_df[\"lesson_num\"] == val_lesson_num)\n",
    "].copy()\n",
    "inf_df.reset_index(inplace=True)\n",
    "\n",
    "print(len(inf_df))\n",
    "inf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inf_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_df.drop(inf_df.index[-1], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_learner = load_learner(\"topic_segmentation_learner.pkl\")\n",
    "inf_dl = inf_learner.dls.test_dl(inf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] okay so so let's dive in and talk about recurrent neural networks um and so recurrent neural networks at a[SEP] high level um this is sort of like an analog in some sense for convolutional neural networks[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
      "[CLS] okay so so let's dive in and talk about recurrent neural networks um and so recurrent neural networks at a[SEP] about the data that's coming into the model um in this case the fact that the data is coming in in the sequence to build a more efficient[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
      "---\n",
      "[CLS] high level um this is sort of like an analog in some sense for convolutional neural networks[SEP] uh for sequence data um and you know that idea of being similar right that we're going to try to exploit some structure[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
      "[CLS] high level um this is sort of like an analog in some sense for convolutional neural networks[SEP] and some of the solutions that people have come up with to address those problems then we'll do a case study on machine[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
      "---\n",
      "[CLS] uh for sequence data um and you know that idea of being similar right that we're going to try to exploit some structure[SEP] about the data that's coming into the model um in this case the fact that the data is coming in in the sequence to build a more efficient[SEP][PAD]\n",
      "[CLS] uh for sequence data um and you know that idea of being similar right that we're going to try to exploit some structure[SEP] non-recurrent models for sequences and then next week will be all about that[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
      "---\n",
      "16\n",
      "SequenceClassifierOutput(loss=None, logits=tensor([[-0.4366, -0.1417],\n",
      "        [-0.4271, -0.1475],\n",
      "        [-0.4123, -0.1624],\n",
      "        [-0.4265, -0.1510],\n",
      "        [-0.4049, -0.1701],\n",
      "        [-0.4335, -0.1413],\n",
      "        [-0.4363, -0.1375],\n",
      "        [-0.4323, -0.1407],\n",
      "        [-0.4342, -0.1440],\n",
      "        [-0.4384, -0.1436],\n",
      "        [-0.4023, -0.1776],\n",
      "        [-0.4216, -0.1437],\n",
      "        [-0.4275, -0.1583],\n",
      "        [-0.4092, -0.1675],\n",
      "        [-0.3925, -0.1741],\n",
      "        [-0.4354, -0.1445]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "[0.39254504442214966, 0.39482900500297546, 0.39835336804389954, 0.3949670195579529, 0.40013569593429565, 0.39329278469085693, 0.392618864774704, 0.39358094334602356, 0.39312970638275146, 0.3921283781528473, 0.400749534368515, 0.39613351225852966, 0.39472562074661255, 0.3991153836250305, 0.4031241834163666, 0.39284834265708923]\n"
     ]
    }
   ],
   "source": [
    "for idx, b in enumerate(inf_dl):\n",
    "    print(hf_tokenizer.decode(b[0][\"input_ids\"][0]))\n",
    "    print(hf_tokenizer.decode(b[1][\"input_ids\"][0]))\n",
    "    print(\"---\")\n",
    "    print(hf_tokenizer.decode(b[0][\"input_ids\"][1]))\n",
    "    print(hf_tokenizer.decode(b[1][\"input_ids\"][1]))\n",
    "    print(\"---\")\n",
    "    print(hf_tokenizer.decode(b[0][\"input_ids\"][2]))\n",
    "    print(hf_tokenizer.decode(b[1][\"input_ids\"][2]))\n",
    "    print(\"---\")\n",
    "    print(len(b[0][\"input_ids\"]))\n",
    "\n",
    "    scores = inf_learner.model.hf_model(b[0][\"input_ids\"], attention_mask=b[0][\"attention_mask\"])\n",
    "    print(scores)\n",
    "    print(torch.sigmoid(scores[0][:, 0]).detach().cpu().numpy().tolist())\n",
    "    if idx == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, _ = inf_learner.get_preds(dl=inf_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 626 626\n",
      "tensor([4.0073, 3.5035, 1.9720, 3.1689, 1.2264])\n",
      "tensor([-0.8434,  1.0984, -1.3691,  0.2587, -0.8578])\n"
     ]
    }
   ],
   "source": [
    "print(len(preds), len(preds[0]), len(preds[1]))\n",
    "print(preds[0][:5])\n",
    "print(preds[1][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics, segeval\n",
    "from sklearn.metrics import mean_absolute_error, f1_score, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "626\n",
      "[0.9821426272392273, 0.9707868695259094, 0.8778219819068909, 0.9596469402313232, 0.7731872200965881, 0.9886969327926636, 0.9900349974632263, 0.9908639788627625, 0.98637855052948, 0.9772564172744751]\n"
     ]
    }
   ],
   "source": [
    "scores = torch.sigmoid(preds[0]).detach().cpu().numpy().tolist()\n",
    "\n",
    "print(len(scores))\n",
    "print(scores[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8121584195036667 0.2311856467795268\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.789039854825714"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_np = np.array(scores)\n",
    "print(scores_np.mean(), scores_np.std())\n",
    "\n",
    "scores_np.mean() - (0.1 * scores_np.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "def depth_score_cal(scores):\n",
    "    output_scores = []\n",
    "    for i in range(len(scores)):\n",
    "        lflag = scores[i]\n",
    "        rflag = scores[i]\n",
    "        if i == 0:\n",
    "            hl = scores[i]\n",
    "            for r in range(i + 1, len(scores)):\n",
    "                if rflag <= scores[r]:\n",
    "                    rflag = scores[r]\n",
    "                else:\n",
    "                    break\n",
    "        elif i == len(scores):\n",
    "            hr = scores[i]\n",
    "            for l in range(i - 1, -1, -1):\n",
    "                if lflag <= scores[l]:\n",
    "                    lflag = scores[l]\n",
    "                else:\n",
    "                    break\n",
    "        else:\n",
    "            for r in range(i + 1, len(scores)):\n",
    "                if rflag <= scores[r]:\n",
    "                    rflag = scores[r]\n",
    "                else:\n",
    "                    break\n",
    "            for l in range(i - 1, -1, -1):\n",
    "                if lflag <= scores[l]:\n",
    "                    lflag = scores[l]\n",
    "                else:\n",
    "                    break\n",
    "        depth_score = 0.5 * (lflag + rflag - 2 * scores[i])\n",
    "        output_scores.append(depth_score)\n",
    "\n",
    "    return output_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "626\n",
      "[0.0, 0.0056778788566589355, 0.0930728018283844, 0.0, 0.2020682394504547, 0.0010835230350494385, 0.0004144906997680664, 0.0, 0.0022427141666412354, 0.006803780794143677]\n"
     ]
    }
   ],
   "source": [
    "depth_scores = depth_score_cal(scores)\n",
    "\n",
    "print(len(depth_scores))\n",
    "print(depth_scores[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.09908506499168972, 0.1667738593307448, 0.02781352015607105)"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depth_scores_np = np.array(depth_scores)\n",
    "depth_scores_np.mean(), depth_scores_np.std(), depth_scores_np.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08239434248236713\n"
     ]
    }
   ],
   "source": [
    "threshold = sum(depth_scores) / (len(depth_scores)) - 0.1 * statistics.stdev(depth_scores)\n",
    "print(threshold)\n",
    "\n",
    "# TODO: A higher threshold seems better in every case; explore a different calculation than the above\n",
    "# threshold = 0.755 # 0.755"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c = 0\n",
    "# pick_num = 3\n",
    "# score_wd = 0\n",
    "# score_mae = 0\n",
    "# score_f1 = 0\n",
    "# score_pk = 0\n",
    "# dp_var = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_var = [statistics.stdev(depth_scores)]\n",
    "\n",
    "boundary_indice = []\n",
    "\n",
    "seg_p_labels = [0] * (len(depth_scores))\n",
    "\n",
    "# TODO: I'm pretty sure we should start with a 1\n",
    "seg_p_labels[0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(depth_scores)):\n",
    "    if depth_scores[i] > threshold:\n",
    "        boundary_indice.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in boundary_indice:\n",
    "    seg_p_labels[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "626\n",
      "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(len(seg_p_labels))\n",
    "print(seg_p_labels[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = 0\n",
    "seg_p = []\n",
    "for idx, fake in enumerate(seg_p_labels):\n",
    "    if fake == 1 and idx != 0:\n",
    "        # tmp += 1\n",
    "        seg_p.append(tmp)\n",
    "        tmp = 1\n",
    "    else:\n",
    "        tmp += 1\n",
    "seg_p.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "[327, 209, 90]\n",
      "626\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "for el in seg_p:\n",
    "    total += el\n",
    "\n",
    "print(len(seg_p))\n",
    "print(seg_p)\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_r_labels = []\n",
    "seg_r = []\n",
    "tmp = 1\n",
    "\n",
    "for r_idx, r in inf_df.iterrows():\n",
    "    current_topic = r[\"topic\"]\n",
    "    if r_idx == 0:\n",
    "        last_seen_topic = r[\"topic\"]\n",
    "\n",
    "    if last_seen_topic != current_topic:\n",
    "        last_seen_topic = current_topic\n",
    "        seg_r_labels.append(1)\n",
    "        seg_r.append(tmp)\n",
    "        tmp = 1\n",
    "    else:\n",
    "        seg_r_labels.append(0 if r_idx != 0 else 1)\n",
    "        tmp += 1 if r_idx != 0 else 0\n",
    "\n",
    "seg_r.append(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate window_dff (WD) and PK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "[15, 48, 147, 55, 60, 119, 52, 26, 104]\n",
      "[15, 48, 147, 55, 60, 119, 52, 26, 104]\n",
      "\n",
      "626\n",
      "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(len(seg_r))\n",
    "print(seg_r[:20])\n",
    "print(seg_r[-20:])\n",
    "print(\"\")\n",
    "print(len(seg_r_labels))\n",
    "print(seg_r_labels[:20])\n",
    "print(seg_r_labels[-20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 3\n",
      "0.3604060913705583756345177665\n",
      "0.3604060913705583756345177665\n"
     ]
    }
   ],
   "source": [
    "print(len(seg_r), len(seg_p))\n",
    "\n",
    "score_wd = segeval.window_diff(seg_p, seg_r)\n",
    "print(score_wd)\n",
    "\n",
    "score_pk = segeval.pk(seg_p, seg_r)\n",
    "print(score_pk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate MAE and F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "626 626\n",
      "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(len(seg_r_labels), len(seg_p_labels))\n",
    "print(seg_r_labels[:20])\n",
    "print(seg_p_labels[:20])\n",
    "print(\"\")\n",
    "print(seg_r_labels[-20:])\n",
    "print(seg_p_labels[-20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "626 626\n",
      "10\n",
      "0.5793010752688172\n",
      "0.6602461209202782\n",
      "0.5539348100126058\n"
     ]
    }
   ],
   "source": [
    "print(len(seg_r_labels), len(seg_p_labels))\n",
    "\n",
    "score_mae = sum(list(map(abs, np.array(seg_r_labels) - np.array(seg_p_labels))))\n",
    "print(score_mae)\n",
    "\n",
    "print(f1_score(seg_r_labels, seg_p_labels, average=\"macro\"))\n",
    "print(precision_score(seg_r_labels, seg_p_labels, average=\"macro\"))\n",
    "print(recall_score(seg_r_labels, seg_p_labels, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 327, 536]"
      ]
     },
     "execution_count": 515,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg_idxs = [seg_idx for seg_idx, v in enumerate(seg_p_labels) if v == 1]\n",
    "seg_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>course_title</th>\n",
       "      <th>lesson_num</th>\n",
       "      <th>topic</th>\n",
       "      <th>seq</th>\n",
       "      <th>next_seq</th>\n",
       "      <th>is_topic_end</th>\n",
       "      <th>next_topic_begin_seq</th>\n",
       "      <th>other_topic_seqs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2613</td>\n",
       "      <td>2613</td>\n",
       "      <td>Full Stack Deep Learning - Spring 2021</td>\n",
       "      <td>3</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>okay so so let's dive in and talk about recurrent neural networks um and so recurrent neural networks at a</td>\n",
       "      <td>high level um this is sort of like an analog in some sense for convolutional neural networks</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[uh for sequence data um and you know that idea of being similar right that we're going to try to exploit some structure, about the data that's coming into the model um in this case the fact that the data is coming in in the sequence to build a more efficient, neural net architecture um hang on a second, all right so what we're going to cover today um first we'll talk about sequence problems and just what are some of the types of, problems you can solve with these architectures then we'll talk about recurrent neural networks which are the main family of, architectures we'll be talking abou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>2940</td>\n",
       "      <td>2940</td>\n",
       "      <td>Full Stack Deep Learning - Spring 2021</td>\n",
       "      <td>3</td>\n",
       "      <td>Bidirectionality and Attention from Google's Neural Machine Translation</td>\n",
       "      <td>from back in 2016. so at one point this was running in production at google um i highly doubt that it is anymore um</td>\n",
       "      <td>but it's it's worth knowing about anyway [Music] so um one one thing i want to talk about</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[about machine translation and we're gonna introduce two ideas um one is by bi-directionality, and the other is attention so these are sort of the big ideas to take away from this section and um this is all from this one paper, is just in general if you're like reading machine learning application papers, what what are the questions that you might want to ask yourself to understand what's going on these papers um so here here are some questions i, think are worth asking one is just like first of all what is the problem that they're trying to solve so what are they using the neural, network...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     level_0  index                            course_title lesson_num  \\\n",
       "0       2613   2613  Full Stack Deep Learning - Spring 2021          3   \n",
       "327     2940   2940  Full Stack Deep Learning - Spring 2021          3   \n",
       "\n",
       "                                                                       topic  \\\n",
       "0                                                               Introduction   \n",
       "327  Bidirectionality and Attention from Google's Neural Machine Translation   \n",
       "\n",
       "                                                                                                                     seq  \\\n",
       "0             okay so so let's dive in and talk about recurrent neural networks um and so recurrent neural networks at a   \n",
       "327  from back in 2016. so at one point this was running in production at google um i highly doubt that it is anymore um   \n",
       "\n",
       "                                                                                         next_seq  \\\n",
       "0    high level um this is sort of like an analog in some sense for convolutional neural networks   \n",
       "327     but it's it's worth knowing about anyway [Music] so um one one thing i want to talk about   \n",
       "\n",
       "     is_topic_end next_topic_begin_seq  \\\n",
       "0           False                  NaN   \n",
       "327         False                  NaN   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            other_topic_seqs  \n",
       "0    [uh for sequence data um and you know that idea of being similar right that we're going to try to exploit some structure, about the data that's coming into the model um in this case the fact that the data is coming in in the sequence to build a more efficient, neural net architecture um hang on a second, all right so what we're going to cover today um first we'll talk about sequence problems and just what are some of the types of, problems you can solve with these architectures then we'll talk about recurrent neural networks which are the main family of, architectures we'll be talking abou...  \n",
       "327  [about machine translation and we're gonna introduce two ideas um one is by bi-directionality, and the other is attention so these are sort of the big ideas to take away from this section and um this is all from this one paper, is just in general if you're like reading machine learning application papers, what what are the questions that you might want to ask yourself to understand what's going on these papers um so here here are some questions i, think are worth asking one is just like first of all what is the problem that they're trying to solve so what are they using the neural, network...  "
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_df.iloc[seg_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('fsdl_2022_course_project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4c27d0eb0116998fc328b5a00abe6956c11e30aa3cb3ca27ff0ca511f067786d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
