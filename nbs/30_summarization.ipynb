{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |default_exp summarization\n",
    "# |default_cls_lvl 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# summarization\n",
    "\n",
    "Training, saving, and tuning code for building summariztion model(s) that can predict both headlines and short summaries of topics given the text associated to a topic segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "from __future__ import annotations\n",
    "\n",
    "import gc\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "from blurr.text.data.seq2seq.core import Seq2SeqBatchTokenizeTransform, Seq2SeqTextBlock, default_text_gen_kwargs\n",
    "from blurr.text.modeling.core import BaseModelCallback, BaseModelWrapper\n",
    "from blurr.text.modeling.seq2seq.core import Seq2SeqMetricsCallback, blurr_seq2seq_splitter\n",
    "from blurr.text.utils import get_hf_objects\n",
    "from blurr.utils import PreCalculatedCrossEntropyLoss\n",
    "from fastcore.all import *\n",
    "from fastai.data.block import DataBlock, ColReader, ItemGetter, ColSplitter, RandomSplitter\n",
    "from fastai.callback.wandb import WandbCallback\n",
    "from fastai.imports import *\n",
    "from fastai.learner import *\n",
    "from fastai.losses import CrossEntropyLossFlat\n",
    "from fastai.optimizer import Adam, ranger\n",
    "from fastai.torch_core import *\n",
    "from fastai.torch_imports import *\n",
    "from transformers.utils import logging as hf_logging\n",
    "from transformers import PegasusForConditionalGeneration, BartForConditionalGeneration, T5ForConditionalGeneration\n",
    "\n",
    "from course_copilot import utils, training, preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Development environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "```text\n",
      "=== Software === \n",
      "python        : 3.10.6\n",
      "fastai        : 2.7.9\n",
      "fastcore      : 1.5.27\n",
      "fastprogress  : 1.0.3\n",
      "torch         : 1.12.1+cu102\n",
      "nvidia driver : 510.47\n",
      "torch cuda    : 10.2 / is available\n",
      "torch cudnn   : 7605 / is enabled\n",
      "\n",
      "=== Hardware === \n",
      "nvidia gpus   : 8\n",
      "torch devices : 2\n",
      "  - gpu0      : Tesla V100-SXM2-16GB\n",
      "  - gpu1      : Tesla V100-SXM2-16GB\n",
      "\n",
      "=== Environment === \n",
      "platform      : Linux-5.15.0-46-generic-x86_64-with-glibc2.31\n",
      "distro        : #49~20.04.1-Ubuntu SMP Thu Aug 4 19:15:44 UTC 2022\n",
      "conda env     : base\n",
      "python        : /home/team_007/mambaforge/bin/python\n",
      "sys.path      : /home/team_007/fsdl_2022_course_project/nbs\n",
      "/home/team_007/mambaforge/lib/python310.zip\n",
      "/home/team_007/mambaforge/lib/python3.10\n",
      "/home/team_007/mambaforge/lib/python3.10/lib-dynload\n",
      "\n",
      "/home/team_007/mambaforge/lib/python3.10/site-packages\n",
      "```\n",
      "\n",
      "Please make sure to include opening/closing ``` when you paste into forums/github to make the reports appear formatted as code sections.\n",
      "\n",
      "Optional package(s) to enhance the diagnostics can be installed with:\n",
      "pip install distro\n",
      "Once installed, re-run this utility to get the additional information\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "utils.print_dev_environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import pdb\n",
    "\n",
    "from fastcore.test import *\n",
    "import nbdev\n",
    "\n",
    "from blurr.utils import print_versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "# silence all the HF warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "hf_logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What we're running with at the time this documentation was generated:\n",
      "torch: 1.12.1+cu102\n",
      "fastai: 2.7.9\n",
      "transformers: 4.22.1\n"
     ]
    }
   ],
   "source": [
    "# | echo: false\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "print(\"What we're running with at the time this documentation was generated:\")\n",
    "print_versions(\"torch fastai transformers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU #1: Tesla V100-SXM2-16GB\n"
     ]
    }
   ],
   "source": [
    "# |hide\n",
    "# |cuda\n",
    "torch.cuda.set_device(1)\n",
    "print(f\"Using GPU #{torch.cuda.current_device()}: {torch.cuda.get_device_name()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "class SummarizationConfig(training.TrainConfig):\n",
    "    hf_model_cls = PegasusForConditionalGeneration\n",
    "    hf_model_checkpoint = \"sshleifer/distill-pegasus-cnn-16-4\"\n",
    "\n",
    "    # datablock/dataloaders\n",
    "    text_gen_kwargs = {}\n",
    "    tok_kwargs = {}\n",
    "\n",
    "    # learner\n",
    "    input_sequence_size = 1024\n",
    "    max_target_length = 5\n",
    "\n",
    "    batch_size = 2\n",
    "    use_fp16 = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['batch_size: 2',\n",
       " 'hf_model_checkpoint: sshleifer/distill-pegasus-cnn-16-4',\n",
       " 'hf_model_cls: PegasusForConditionalGeneration',\n",
       " 'input_sequence_size: 1024',\n",
       " 'max_target_length: 5',\n",
       " 'n_frozen_epochs: 0',\n",
       " 'n_unfrozen_epochs: 1',\n",
       " 'only_seed_splits: True',\n",
       " 'preprocess_strategy: None',\n",
       " 'random_seed: 2022',\n",
       " 'text_gen_kwargs: {}',\n",
       " 'tok_kwargs: {}',\n",
       " 'training_subset: 0.25',\n",
       " 'use_fp16: True',\n",
       " 'val_pct: 0.25']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ExampleCFG(SummarizationConfig):\n",
    "    training_subset = 0.25\n",
    "    n_frozen_epochs = 0\n",
    "    n_unfrozen_epochs = 1\n",
    "\n",
    "\n",
    "[f\"{k}: {v}\" for k, v in training.get_train_config_props(ExampleCFG).items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "def _get_training_data(\n",
    "    cfg: SummarizationConfig, data_dir=\"../data\"  # configuration for summarization  # data directory\n",
    "):\n",
    "    segmentation_df, summarization_df = preprocessing.preprocess_data(\n",
    "        ds=\"train\", data_path=data_dir, return_file=True, save_file=False\n",
    "    )\n",
    "    return summarization_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>course_title</th>\n",
       "      <th>lesson_num</th>\n",
       "      <th>start_seconds</th>\n",
       "      <th>topic</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C-Squared Podcast</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Intro</td>\n",
       "      <td>[Music] welcome everybody to episode one of a chess themed podcast with myself christian kirilla and i'm fighting on caruana so what's up christian well not so much fabi uh it's first of all great um to finally start a podcast the chess podcast i know that um there's a lot of podcasts out there but i wanted to bring our own tune to the mix and i think uh yeah i'm excited about that so that's uh the first thing how about yourself fabian well i'm back in the states after it's been a while at your home it's good to be here it's my first time in uh visiting here and uh yeah it's been an intere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C-Squared Podcast</td>\n",
       "      <td>1</td>\n",
       "      <td>137</td>\n",
       "      <td>Candidates 2018</td>\n",
       "      <td>camps look like in general yeah well you mentioned the 2018 cycle uh where we worked together we started with the training before the candidates and for me it's interesting because i've i've played a lot of these candidates tournaments and i'm always doing it a bit differently trying different things trying to improve it but sometimes it goes less or more successfully you never know what will work out i think what we did in 2018 not just for the candidates but also for the world championship because i qualified for that i think what we did then was extremely successful um we we arranged it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C-Squared Podcast</td>\n",
       "      <td>1</td>\n",
       "      <td>464</td>\n",
       "      <td>Candidates training</td>\n",
       "      <td>going in the candidates like how was the experience yeah i think the preparation was pretty serious it included a bunch of uh camps and preparation devoted to players as i assume i think everyone has the same sort of general approach which is to think about their openings their strategy look at the opponents try to get in shape make sure that you're not you know rusty or blundering things or hallucinating variations uh but there's a lot of nerves and i i felt a lot of nerves before the tournament and i think possibly i you know overworked over trained a bit because it was yeah it was like ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C-Squared Podcast</td>\n",
       "      <td>1</td>\n",
       "      <td>610</td>\n",
       "      <td>Playing for 2nd place</td>\n",
       "      <td>were you just like focused on grabbing first well i was only focused on first but of course there were always these thoughts that well maybe second is enough but you can't play for second like let's say once i had achieved plus three in the tournament and john was plus four and i tried to go and go into like full like risk reverse mode which is still difficult to do but let's say i had gone that mode and and achieved it and like finished second with like plus three and john got plus five uh and then like magnus says well i'm going to play right then you also feel kind of stupid you know li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C-Squared Podcast</td>\n",
       "      <td>1</td>\n",
       "      <td>916</td>\n",
       "      <td>Magnus' WC decision</td>\n",
       "      <td>know you can't uh you can't tell him you have to do something i i guess let me rephrase that fair to let you guys play the tournament first and then tell you the decision well i think he said it in a strange way which was that i'll play against alireza which to me is strange because if you don't want to play world championship match i fully understand you know but did he say that did he actually name him yeah that's kind of what he said um yeah he more he like he didn't say definitively like i won't play against anyone but he was like i probably won't play unless it's frozen right and yeah...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        course_title lesson_num  start_seconds                  topic  \\\n",
       "0  C-Squared Podcast          1              0                  Intro   \n",
       "1  C-Squared Podcast          1            137        Candidates 2018   \n",
       "2  C-Squared Podcast          1            464    Candidates training   \n",
       "3  C-Squared Podcast          1            610  Playing for 2nd place   \n",
       "4  C-Squared Podcast          1            916    Magnus' WC decision   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                transcript  \n",
       "0  [Music] welcome everybody to episode one of a chess themed podcast with myself christian kirilla and i'm fighting on caruana so what's up christian well not so much fabi uh it's first of all great um to finally start a podcast the chess podcast i know that um there's a lot of podcasts out there but i wanted to bring our own tune to the mix and i think uh yeah i'm excited about that so that's uh the first thing how about yourself fabian well i'm back in the states after it's been a while at your home it's good to be here it's my first time in uh visiting here and uh yeah it's been an intere...  \n",
       "1  camps look like in general yeah well you mentioned the 2018 cycle uh where we worked together we started with the training before the candidates and for me it's interesting because i've i've played a lot of these candidates tournaments and i'm always doing it a bit differently trying different things trying to improve it but sometimes it goes less or more successfully you never know what will work out i think what we did in 2018 not just for the candidates but also for the world championship because i qualified for that i think what we did then was extremely successful um we we arranged it...  \n",
       "2  going in the candidates like how was the experience yeah i think the preparation was pretty serious it included a bunch of uh camps and preparation devoted to players as i assume i think everyone has the same sort of general approach which is to think about their openings their strategy look at the opponents try to get in shape make sure that you're not you know rusty or blundering things or hallucinating variations uh but there's a lot of nerves and i i felt a lot of nerves before the tournament and i think possibly i you know overworked over trained a bit because it was yeah it was like ...  \n",
       "3  were you just like focused on grabbing first well i was only focused on first but of course there were always these thoughts that well maybe second is enough but you can't play for second like let's say once i had achieved plus three in the tournament and john was plus four and i tried to go and go into like full like risk reverse mode which is still difficult to do but let's say i had gone that mode and and achieved it and like finished second with like plus three and john got plus five uh and then like magnus says well i'm going to play right then you also feel kind of stupid you know li...  \n",
       "4  know you can't uh you can't tell him you have to do something i i guess let me rephrase that fair to let you guys play the tournament first and then tell you the decision well i think he said it in a strange way which was that i'll play against alireza which to me is strange because if you don't want to play world championship match i fully understand you know but did he say that did he actually name him yeah that's kind of what he said um yeah he more he like he didn't say definitively like i won't play against anyone but he was like i probably won't play unless it's frozen right and yeah...  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf = _get_training_data(ExampleCFG)\n",
    "sdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Huggingface objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def _get_task_hf_objects(cfg: SummarizationConfig):\n",
    "    hf_tok_kwargs = {}\n",
    "    if cfg.hf_model_checkpoint == \"sshleifer/tiny-mbart\":\n",
    "        hf_tok_kwargs[\"src_lang\"], hf_tok_kwargs[\"tgt_lang\"] = \"en_XX\", \"en_XX\"\n",
    "\n",
    "    hf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(\n",
    "        pretrained_model_name_or_path=cfg.hf_model_checkpoint,\n",
    "        model_cls=cfg.hf_model_cls,\n",
    "        tokenizer_kwargs=hf_tok_kwargs,\n",
    "    )\n",
    "    return hf_arch, hf_config, hf_tokenizer, hf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('pegasus',\n",
       " transformers.models.pegasus.configuration_pegasus.PegasusConfig,\n",
       " transformers.models.pegasus.tokenization_pegasus_fast.PegasusTokenizerFast,\n",
       " transformers.models.pegasus.modeling_pegasus.PegasusForConditionalGeneration)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_arch, hf_config, hf_tokenizer, hf_model = _get_task_hf_objects(ExampleCFG)\n",
    "hf_arch, type(hf_config), type(hf_tokenizer), type(hf_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "def _get_dls(cfg: SummarizationConfig, df, hf_arch, hf_config, hf_tokenizer, hf_model):\n",
    "    if hf_arch in [\"bart\", \"t5\"]:\n",
    "        cfg.text_gen_kwargs = {**hf_config.task_specific_params[\"summarization\"], **{\"max_length\": 40, \"min_length\": 5}}\n",
    "\n",
    "    # not all \"summarization\" parameters are for the model.generate method ... remove them here\n",
    "    generate_func_args = list(inspect.signature(hf_model.generate).parameters.keys())\n",
    "    for k in cfg.text_gen_kwargs.copy():\n",
    "        if k not in generate_func_args:\n",
    "            del text_gen_kwargs[k]\n",
    "\n",
    "    if hf_arch == \"mbart\":\n",
    "        cfg.text_gen_kwargs[\"decoder_start_token_id\"] = hf_tokenizer.get_vocab()[\"en_XX\"]\n",
    "\n",
    "    def add_t5_prefix(inp):\n",
    "        return f\"summarize: {inp}\" if (hf_arch == \"t5\") else inp\n",
    "\n",
    "    batch_tokenize_tfm = Seq2SeqBatchTokenizeTransform(\n",
    "        hf_arch,\n",
    "        hf_config,\n",
    "        hf_tokenizer,\n",
    "        hf_model,\n",
    "        padding=\"max_length\",\n",
    "        max_length=cfg.input_sequence_size,\n",
    "        max_target_length=cfg.max_target_length,\n",
    "        text_gen_kwargs=cfg.text_gen_kwargs,\n",
    "    )\n",
    "\n",
    "    blocks = (Seq2SeqTextBlock(batch_tokenize_tfm=batch_tokenize_tfm), noop)\n",
    "    dblock = DataBlock(\n",
    "        blocks=blocks, get_x=ColReader(\"transcript\"), get_y=ColReader(\"topic\"), splitter=RandomSplitter()\n",
    "    )\n",
    "\n",
    "    dls = dblock.dataloaders(df, bs=cfg.batch_size)\n",
    "    return dls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = _get_dls(ExampleCFG, sdf, hf_arch, hf_config, hf_tokenizer, hf_model)\n",
    "b = dls.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, torch.Size([2, 1024]), 2, torch.Size([2, 5]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b), len(b[0]), b[0][\"input_ids\"].shape, len(b[1]), b[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "little bit bigger you know obviously a super famous artwork and and this is not that he wasn't the first person to illustrate perspective or he wasn't the first person to illustrate this particular biblical scene but he was amongst the first to use perspective to draw it and or to paint it and so previous to this we had medieval painting right which was very kind of stilted and and the space was kind of weirdly ill-defined it looked a lot like children's drawings but just like really really refined children's drawings where everything is a little bit awkward so what is kind of special about this and why it's Malay Nardo's Last Supper is important is that this was painted let me see if we there's a well it was painted in a room and kind of high up in a room on a wall and if you stood all the way back at the far end of the room it created the illusion that this whole scene was happening on that far wall like the the walls and the ceiling and the room that you were physically standing in appeared to continue into the painting and then off into the distance so it was this optical illusion you know you you you would look at it and say well I know that's a flat wall but it seems to kind of go further the painting appears to make the wall look like it's a window into another space right so Leonardo using perspective created this depth so it looks like there's a whole room in behind all of these figures sitting at this table okay so I'm not going to go into too too deep into the history of perspective there's lots of videos and stuff about that that already exists but this is a particularly important painting wasn't the first one but it it you know there was some people using perspective fifty years before this but it definitely is amongst the most famous early examples okay so I'm gonna go back to my handout here so just to kind of continue that there are lots of different kinds of perspective now the first type of perspective we're going to talk about and I'm just gonna talk about those briefly in my in my classes I talked about a little bit longer and we're gonna do we would do an exercise with it but it's gonna be a little challenging for us to do over the web so I'm gonna kind of just breeze through it so this is isometric projection and you've probably seen this many times if you've ever assembled IKEA furniture IKEA furniture is drawn in isometric projection so let's say if I look at this drawing it's image on the bottom right here I'm scum so I'm zoomed in on this here if I was to show you this drawing and say this is the plan for the bathroom I'm going to this is I'm gonna renovate my bathroom and this is what its gonna look like I think you might look at it and say okay I what okay oh this is the sink okay um and what is this here what are these things is this oh is that a shower okay so what is this a so it's not clear right it's a cuz it's drawn from one angle and so we can't really see any dimension in this drawing whereas if we use isometric projection we now see that same I'm able to zoom back out a little bit more here this same image reproduced here but from like a 3/4 review so we're kind of taking this front view and then rotating it so that we can now see the top right if you imagine this being a box like let me see like this box right so we've started from this point of view straight on and then we're kind of now looking at it from this angle so you could see the top and the front side and this side right and you can even kind of imagine what the back side is a little bit right so this allows us to see multiple points of view all at once and if you've it's probably not that many people watching this who have any experience with drafting but this is I took drafting when I was in high school and we spent a lot in before computers and your drawing all this on paper and using rulers in a super analytical and like a very left brain activity right so break like a lot of mathematics and you're always using the calculator and to try to get all this right but so you like an exercise in in a drafting class and exam would be something like this where they would give you the front view of this object the side view and then the top view and they would say illustrate it in an isometric projection from a 3/4 angle right so you this image here would not be visible you'd have to create that from only these three so it's a little bit tricky but all of a sudden this image is a lot clearer to most people than just looking at these three other views right so in when I'm teaching this class in in person what I do is I pass out a little sheet like this and I get people to kind of fill it out right so here's one and then you're just</s>\n"
     ]
    }
   ],
   "source": [
    "print(hf_tokenizer.decode(b[0][\"input_ids\"][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_learner(cfg: SummarizationConfig, dls, hf_config, hf_model, hf_arch):\n",
    "    if cfg.random_seed and not cfg.only_seed_splits:\n",
    "        set_seed(cfg.random_seed)\n",
    "\n",
    "    model = BaseModelWrapper(hf_model)\n",
    "    learn_cbs = [BaseModelCallback]\n",
    "\n",
    "    learn = Learner(\n",
    "        dls,\n",
    "        model,\n",
    "        opt_func=ranger,\n",
    "        loss_func=PreCalculatedCrossEntropyLoss(),\n",
    "        cbs=learn_cbs,\n",
    "        splitter=partial(blurr_seq2seq_splitter, arch=hf_arch),\n",
    "    )\n",
    "\n",
    "    learn.create_opt()\n",
    "    learn.freeze()\n",
    "\n",
    "    if cfg.use_fp16:\n",
    "        learn = learn.to_fp16()\n",
    "\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = _get_learner(cfg=ExampleCFG, dls=dls, hf_config=hf_config, hf_model=hf_model, hf_arch=hf_arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.lr_find(suggest_funcs=[minimum, steep, valley, slide])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq_metrics = {\n",
    "    \"rouge\": {\n",
    "        \"compute_kwargs\": {\"rouge_types\": [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"], \"use_stemmer\": True},\n",
    "        \"returns\": [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"],\n",
    "    }\n",
    "}\n",
    "fit_cbs = [Seq2SeqMetricsCallback(custom_metrics=seq2seq_metrics)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.065241</td>\n",
       "      <td>3.908895</td>\n",
       "      <td>0.227476</td>\n",
       "      <td>0.116567</td>\n",
       "      <td>0.224963</td>\n",
       "      <td>0.225480</td>\n",
       "      <td>02:10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, lr_max=1e-3, cbs=fit_cbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del learn, dls, hf_model, hf_tokenizer, hf_config\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
