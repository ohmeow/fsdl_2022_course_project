{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |default_exp summarization\n",
    "# |default_cls_lvl 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# summarization\n",
    "\n",
    "Training, saving, and tuning code for building summariztion model(s) that can predict both headlines and short summaries of topics given the text associated to a topic segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/team_007/mambaforge/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# |export\n",
    "from __future__ import annotations\n",
    "\n",
    "import datetime\n",
    "import gc\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import wandb\n",
    "from blurr.text.data.seq2seq.core import Seq2SeqBatchTokenizeTransform, Seq2SeqTextBlock, default_text_gen_kwargs\n",
    "from blurr.text.modeling.core import BaseModelCallback, BaseModelWrapper\n",
    "from blurr.text.modeling.seq2seq.core import Seq2SeqMetricsCallback, blurr_seq2seq_splitter\n",
    "from blurr.text.utils import get_hf_objects\n",
    "from blurr.utils import PreCalculatedCrossEntropyLoss\n",
    "from fastcore.all import *\n",
    "from fastai.data.block import DataBlock, ColReader, ItemGetter, ColSplitter, RandomSplitter\n",
    "from fastai.callback.wandb import WandbCallback\n",
    "from fastai.callback.schedule import *\n",
    "from fastai.imports import *\n",
    "from fastai.learner import *\n",
    "from fastai.losses import CrossEntropyLossFlat\n",
    "from fastai.optimizer import Adam, ranger\n",
    "from fastai.torch_core import *\n",
    "from fastai.torch_imports import *\n",
    "from transformers.utils import logging as hf_logging\n",
    "from transformers import PegasusForConditionalGeneration, BartForConditionalGeneration, T5ForConditionalGeneration\n",
    "\n",
    "from course_copilot import utils, training, preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Development environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import pdb\n",
    "\n",
    "from fastcore.test import *\n",
    "import nbdev\n",
    "\n",
    "from blurr.utils import print_versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "# silence all the HF warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "hf_logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What we're running with at the time this documentation was generated:\n",
      "torch: 1.12.1+cu102\n",
      "fastai: 2.7.9\n",
      "transformers: 4.22.1\n"
     ]
    }
   ],
   "source": [
    "# | echo: false\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "print(\"What we're running with at the time this documentation was generated:\")\n",
    "print_versions(\"torch fastai transformers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU #1: Tesla V100-SXM2-16GB\n"
     ]
    }
   ],
   "source": [
    "# |hide\n",
    "# |cuda\n",
    "torch.cuda.set_device(1)\n",
    "print(f\"Using GPU #{torch.cuda.current_device()}: {torch.cuda.get_device_name()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "class SummarizationConfig(training.TrainConfig):\n",
    "    hf_model_cls = PegasusForConditionalGeneration\n",
    "    hf_model_checkpoint = \"sshleifer/distill-pegasus-cnn-16-4\"\n",
    "\n",
    "    # datablock/dataloaders\n",
    "    text_gen_kwargs = {}\n",
    "    tok_kwargs = {}\n",
    "\n",
    "    # learner\n",
    "    input_sequence_size = 512\n",
    "    max_target_length = 10\n",
    "\n",
    "    batch_size = 8\n",
    "    use_fp16 = True\n",
    "    use_wandb = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "headline_length = 5\n",
    "content_length = 80\n",
    "\n",
    "\n",
    "class ContentSummarizationConfig(SummarizationConfig):\n",
    "    max_target_length = content_length\n",
    "    text_gen_kwargs = {\"do_sample\": True, \"max_length\": 100, \"top_k\": 50, \"top_p\": 0.95}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ContentSummarizationConfig.max_target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "class HeadlineSummarizationConfig(SummarizationConfig):\n",
    "    max_target_length = headline_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['batch_size: 8',\n",
       " 'hf_model_checkpoint: sshleifer/distill-pegasus-cnn-16-4',\n",
       " 'hf_model_cls: PegasusForConditionalGeneration',\n",
       " 'input_sequence_size: 512',\n",
       " 'max_target_length: 80',\n",
       " 'n_frozen_epochs: 0',\n",
       " 'n_unfrozen_epochs: 1',\n",
       " 'only_seed_splits: True',\n",
       " 'preprocess_strategy: None',\n",
       " 'random_seed: 2022',\n",
       " \"text_gen_kwargs: {'do_sample': True, 'max_length': 100, 'top_k': 50, 'top_p': 0.95}\",\n",
       " 'tok_kwargs: {}',\n",
       " 'training_subset: 0.25',\n",
       " 'use_fp16: True',\n",
       " 'use_wandb: True',\n",
       " 'val_pct: 0.25']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class XsumCFG(ContentSummarizationConfig):\n",
    "    training_subset = 0.25\n",
    "    n_frozen_epochs = 0\n",
    "    n_unfrozen_epochs = 1\n",
    "\n",
    "\n",
    "[f\"{k}: {v}\" for k, v in training.get_train_config_props(XsumCFG).items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "def _get_training_data(cfg: SummarizationConfig, data_dir=\"data\"):  # configuration for summarization  # data directory\n",
    "    segmentation_df, summarization_df = preprocessing.preprocess_data(\n",
    "        ds=\"train\", data_path=data_dir, return_file=True, save_file=False\n",
    "    )\n",
    "    return summarization_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>course_title</th>\n",
       "      <th>lesson_num</th>\n",
       "      <th>start_seconds</th>\n",
       "      <th>topic</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C-Squared Podcast</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Intro</td>\n",
       "      <td>[Music] welcome everybody to episode one of a chess themed podcast with myself christian kirilla and i'm fighting on caruana so what's up christian well not so much fabi uh it's first of all great um to finally start a podcast the chess podcast i know that um there's a lot of podcasts out there but i wanted to bring our own tune to the mix and i think uh yeah i'm excited about that so that's uh the first thing how about yourself fabian well i'm back in the states after it's been a while at your home it's good to be here it's my first time in uh visiting here and uh yeah it's been an intere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C-Squared Podcast</td>\n",
       "      <td>1</td>\n",
       "      <td>137.0</td>\n",
       "      <td>Candidates 2018</td>\n",
       "      <td>camps look like in general yeah well you mentioned the 2018 cycle uh where we worked together we started with the training before the candidates and for me it's interesting because i've i've played a lot of these candidates tournaments and i'm always doing it a bit differently trying different things trying to improve it but sometimes it goes less or more successfully you never know what will work out i think what we did in 2018 not just for the candidates but also for the world championship because i qualified for that i think what we did then was extremely successful um we we arranged it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C-Squared Podcast</td>\n",
       "      <td>1</td>\n",
       "      <td>464.0</td>\n",
       "      <td>Candidates training</td>\n",
       "      <td>going in the candidates like how was the experience yeah i think the preparation was pretty serious it included a bunch of uh camps and preparation devoted to players as i assume i think everyone has the same sort of general approach which is to think about their openings their strategy look at the opponents try to get in shape make sure that you're not you know rusty or blundering things or hallucinating variations uh but there's a lot of nerves and i i felt a lot of nerves before the tournament and i think possibly i you know overworked over trained a bit because it was yeah it was like ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C-Squared Podcast</td>\n",
       "      <td>1</td>\n",
       "      <td>610.0</td>\n",
       "      <td>Playing for 2nd place</td>\n",
       "      <td>were you just like focused on grabbing first well i was only focused on first but of course there were always these thoughts that well maybe second is enough but you can't play for second like let's say once i had achieved plus three in the tournament and john was plus four and i tried to go and go into like full like risk reverse mode which is still difficult to do but let's say i had gone that mode and and achieved it and like finished second with like plus three and john got plus five uh and then like magnus says well i'm going to play right then you also feel kind of stupid you know li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C-Squared Podcast</td>\n",
       "      <td>1</td>\n",
       "      <td>916.0</td>\n",
       "      <td>Magnus' WC decision</td>\n",
       "      <td>know you can't uh you can't tell him you have to do something i i guess let me rephrase that fair to let you guys play the tournament first and then tell you the decision well i think he said it in a strange way which was that i'll play against alireza which to me is strange because if you don't want to play world championship match i fully understand you know but did he say that did he actually name him yeah that's kind of what he said um yeah he more he like he didn't say definitively like i won't play against anyone but he was like i probably won't play unless it's frozen right and yeah...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        course_title lesson_num  start_seconds                  topic  \\\n",
       "0  C-Squared Podcast          1            0.0                  Intro   \n",
       "1  C-Squared Podcast          1          137.0        Candidates 2018   \n",
       "2  C-Squared Podcast          1          464.0    Candidates training   \n",
       "3  C-Squared Podcast          1          610.0  Playing for 2nd place   \n",
       "4  C-Squared Podcast          1          916.0    Magnus' WC decision   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                transcript  \n",
       "0  [Music] welcome everybody to episode one of a chess themed podcast with myself christian kirilla and i'm fighting on caruana so what's up christian well not so much fabi uh it's first of all great um to finally start a podcast the chess podcast i know that um there's a lot of podcasts out there but i wanted to bring our own tune to the mix and i think uh yeah i'm excited about that so that's uh the first thing how about yourself fabian well i'm back in the states after it's been a while at your home it's good to be here it's my first time in uh visiting here and uh yeah it's been an intere...  \n",
       "1  camps look like in general yeah well you mentioned the 2018 cycle uh where we worked together we started with the training before the candidates and for me it's interesting because i've i've played a lot of these candidates tournaments and i'm always doing it a bit differently trying different things trying to improve it but sometimes it goes less or more successfully you never know what will work out i think what we did in 2018 not just for the candidates but also for the world championship because i qualified for that i think what we did then was extremely successful um we we arranged it...  \n",
       "2  going in the candidates like how was the experience yeah i think the preparation was pretty serious it included a bunch of uh camps and preparation devoted to players as i assume i think everyone has the same sort of general approach which is to think about their openings their strategy look at the opponents try to get in shape make sure that you're not you know rusty or blundering things or hallucinating variations uh but there's a lot of nerves and i i felt a lot of nerves before the tournament and i think possibly i you know overworked over trained a bit because it was yeah it was like ...  \n",
       "3  were you just like focused on grabbing first well i was only focused on first but of course there were always these thoughts that well maybe second is enough but you can't play for second like let's say once i had achieved plus three in the tournament and john was plus four and i tried to go and go into like full like risk reverse mode which is still difficult to do but let's say i had gone that mode and and achieved it and like finished second with like plus three and john got plus five uh and then like magnus says well i'm going to play right then you also feel kind of stupid you know li...  \n",
       "4  know you can't uh you can't tell him you have to do something i i guess let me rephrase that fair to let you guys play the tournament first and then tell you the decision well i think he said it in a strange way which was that i'll play against alireza which to me is strange because if you don't want to play world championship match i fully understand you know but did he say that did he actually name him yeah that's kind of what he said um yeah he more he like he didn't say definitively like i won't play against anyone but he was like i probably won't play unless it's frozen right and yeah...  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf = _get_training_data(XsumCFG, data_dir=\"../data\")\n",
    "sdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Huggingface objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def _get_task_hf_objects(cfg: SummarizationConfig):\n",
    "    hf_tok_kwargs = {}\n",
    "    if cfg.hf_model_checkpoint == \"sshleifer/tiny-mbart\":\n",
    "        hf_tok_kwargs[\"src_lang\"], hf_tok_kwargs[\"tgt_lang\"] = \"en_XX\", \"en_XX\"\n",
    "\n",
    "    hf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(\n",
    "        pretrained_model_name_or_path=cfg.hf_model_checkpoint,\n",
    "        model_cls=cfg.hf_model_cls,\n",
    "        tokenizer_kwargs=hf_tok_kwargs,\n",
    "    )\n",
    "    return hf_arch, hf_config, hf_tokenizer, hf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('pegasus',\n",
       " transformers.models.pegasus.configuration_pegasus.PegasusConfig,\n",
       " transformers.models.pegasus.tokenization_pegasus_fast.PegasusTokenizerFast,\n",
       " transformers.models.pegasus.modeling_pegasus.PegasusForConditionalGeneration)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_arch, hf_config, hf_tokenizer, hf_model = _get_task_hf_objects(XsumCFG)\n",
    "hf_arch, type(hf_config), type(hf_tokenizer), type(hf_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "def _get_dls(cfg: SummarizationConfig, df, hf_arch, hf_config, hf_tokenizer, hf_model):\n",
    "    if hf_arch in [\"bart\", \"t5\"]:\n",
    "        cfg.text_gen_kwargs = {**hf_config.task_specific_params[\"summarization\"], **{\"max_length\": 40, \"min_length\": 5}}\n",
    "\n",
    "    # TODO: add text_gen_kwargs dynamically\n",
    "    generate_func_args = list(inspect.signature(hf_model.generate).parameters.keys())\n",
    "    for k in cfg.text_gen_kwargs.copy():\n",
    "        if k not in generate_func_args:\n",
    "            del text_gen_kwargs[k]\n",
    "\n",
    "    if hf_arch == \"mbart\":\n",
    "        cfg.text_gen_kwargs[\"decoder_start_token_id\"] = hf_tokenizer.get_vocab()[\"en_XX\"]\n",
    "\n",
    "    def add_t5_prefix(inp):\n",
    "        return f\"summarize: {inp}\" if (hf_arch == \"t5\") else inp\n",
    "\n",
    "    batch_tokenize_tfm = Seq2SeqBatchTokenizeTransform(\n",
    "        hf_arch,\n",
    "        hf_config,\n",
    "        hf_tokenizer,\n",
    "        hf_model,\n",
    "        padding=\"max_length\",\n",
    "        max_length=cfg.input_sequence_size,\n",
    "        max_target_length=cfg.max_target_length,\n",
    "        text_gen_kwargs=cfg.text_gen_kwargs,\n",
    "    )\n",
    "\n",
    "    blocks = (Seq2SeqTextBlock(batch_tokenize_tfm=batch_tokenize_tfm), noop)\n",
    "    dblock = DataBlock(\n",
    "        blocks=blocks, get_x=ColReader(\"transcript\"), get_y=ColReader(\"topic\"), splitter=RandomSplitter()\n",
    "    )\n",
    "\n",
    "    dls = dblock.dataloaders(df, bs=cfg.batch_size)\n",
    "    return dls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = _get_dls(XsumCFG, sdf, hf_arch, hf_config, hf_tokenizer, hf_model)\n",
    "b = dls.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(b), len(b[0]), b[0][\"input_ids\"].shape, len(b[1]), b[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hf_tokenizer.decode(b[0][\"input_ids\"][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "def _get_learner(cfg: SummarizationConfig, dls, hf_config, hf_model, hf_arch):\n",
    "    if cfg.random_seed:\n",
    "        set_seed(cfg.random_seed)\n",
    "\n",
    "    model = BaseModelWrapper(hf_model)\n",
    "    learn_cbs = [BaseModelCallback]\n",
    "\n",
    "    learn = Learner(\n",
    "        dls,\n",
    "        model,\n",
    "        opt_func=ranger,\n",
    "        loss_func=PreCalculatedCrossEntropyLoss(),\n",
    "        cbs=learn_cbs,\n",
    "        splitter=partial(blurr_seq2seq_splitter, arch=hf_arch),\n",
    "    )\n",
    "\n",
    "    learn.create_opt()\n",
    "    learn.freeze()\n",
    "\n",
    "    if cfg.use_fp16:\n",
    "        learn = learn.to_fp16()\n",
    "\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = _get_learner(cfg=XsumCFG, dls=dls, hf_config=hf_config, hf_model=hf_model, hf_arch=hf_arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find(suggest_funcs=[minimum, steep, valley, slide])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq_metrics = {\n",
    "    \"rouge\": {\n",
    "        \"compute_kwargs\": {\"rouge_types\": [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"], \"use_stemmer\": True},\n",
    "        \"returns\": [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"],\n",
    "    }\n",
    "}\n",
    "fit_cbs = [Seq2SeqMetricsCallback(custom_metrics=seq2seq_metrics)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(1, lr_max=5e-4, cbs=fit_cbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.metrics = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_fname = \"summarize_export\"\n",
    "learn.export(fname=f\"{export_fname}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del learn, dls, hf_model, hf_tokenizer, hf_config\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = load_learner(\"summarize_export.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_texts': [\"This week we're going to talk about some of the organizational things that you need to do in order to work together on ml-powered products .\",\n",
       "   \"This week we're going to talk about some of the organizational things that you need to do in order to work together on ml-powered products .\",\n",
       "   \"This week we're going to talk about some of the organizational things that you need to do in order to work together on ml-powered products .\"]}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_article = \"\"\"hey everybody welcome back this week we're going to talk about something a little bit different than we do most weeks most weeks we talk about specific\n",
    "technical aspects of building machine learning powered products but this week we're going to focus on some of the\n",
    "organizational things that you need to do in order to work together on ml-powered products as part of an\n",
    "interdisciplinary team so the the reality of building ml Power Products is that building any product well is really\n",
    "difficult you have to figure out how to hire grade people you need to be able to manage those people and get the best out\n",
    "of them you need to make sure that your team is all working together towards a shared goal you need to make good\n",
    "long-term technical choices manage technical debt over time you need to make sure that you're managing\n",
    "expectations not just of your own team but also of leadership of your organization and you need to be able to make sure\n",
    "that you're working well within the confines of the requirements of the rest of the org that you're understanding\n",
    "those requirements well and communicating back to your progress to the rest of the organization against those requirements\n",
    "but machine learning adds even more additional complexity to this machine learning Talent tends to be very scarce\n",
    "and expensive to attract machine learning teams are not just a\n",
    "single role but today they tend to be pretty interdisciplinary which makes managing them an even bigger challenge\n",
    "machine learning projects often have unclear timelines and there's a high\n",
    "degree of uncertainty to those timelines machine learning itself is moving super fast and machine learning as we've\n",
    "covered before you can think of as like the high interest credit card of technical debt so keeping up with making\n",
    "good long-term decisions and not incurring too much technical debt is especially difficult in ml unlike\n",
    "traditional software ml is so new that in most organizations leadership tends not to be that well educated in it they\n",
    "might not understand some of the core differences between ML and other technology that you're working with machine learning products tend to fail\n",
    "in ways that are really hard for Lay people to understand and so that makes it very difficult to help the rest of\n",
    "the stakeholders in your organization understand what they could really expect from the technology that you're building\n",
    "and what is realistic for us to achieve so throughout the rest rest of this lecture we're going to kind of touch on\n",
    "some of these themes and cover different aspects of this problem of working together to build ml Power Products as\n",
    "an organization so here are the pieces that we're going to cover we're going to talk about different roles that are involved in building ml products we're\n",
    "going to talk about some of the unique aspects involved in hiring ml Talent\n",
    "we're going to talk about organization of teams and how the ml team tends to fit into the rest of the org and some of\n",
    "the pros and cons of different ways of setting that up we'll talk about managing ml teams and\n",
    "ml product management and then lastly we'll talk about some of the design considerations for how to design a\n",
    "product that is well suited to having a good ml model that backs it so let's dive in and talk about rules the most\n",
    "common ml rules that you might hear of are things like ml product manager ml\n",
    "\"\"\"\n",
    "learn.blurr_generate(\n",
    "    test_article, key=\"summary_texts\", do_sample=True, max_length=100, top_k=50, top_p=0.95, num_return_sequences=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "def _get_preds(model_or_learner, text_data: str, gen_algo, max_length):\n",
    "    if gen_algo == \"greedy\":\n",
    "        return model_or_learner.blurr_generate(text_data, key=\"summary_texts\", max_length=max_length)[0][\n",
    "            \"summary_texts\"\n",
    "        ]\n",
    "    elif gen_algo == \"topp\":\n",
    "        return model_or_learner.blurr_generate(\n",
    "            text_data,\n",
    "            key=\"summary_texts\",\n",
    "            max_length=max_length,\n",
    "            top_k=50,\n",
    "            top_p=0.95,\n",
    "        )[0][\"summary_texts\"]\n",
    "    elif gen_algo == \"topk\":\n",
    "        return model_or_learner.blurr_generate(text_data, key=\"summary_texts\", max_length=max_length, top_k=50)[0][\n",
    "            \"summary_texts\"\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = _get_preds(learn, test_article, \"greedy\", 100)\n",
    "assert isinstance(response, str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"This week we're going to talk about some of the organizational\""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_get_preds(learn, test_article, \"topp\", 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "class SummarizationModelTrainer(training.ModelTrainer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        experiment_name,\n",
    "        train_config: SummarizationConfig,\n",
    "        data_path=\"data\",\n",
    "        model_output_path=\"models\",\n",
    "        log_output_path=\"logs\",\n",
    "        log_preds=False,\n",
    "        log_n_preds=None,\n",
    "        use_wandb=False,\n",
    "        verbose=False,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            experiment_name=experiment_name,\n",
    "            train_config=train_config,\n",
    "            data_path=data_path,\n",
    "            model_output_path=model_output_path,\n",
    "            log_output_path=log_output_path,\n",
    "            log_preds=log_preds,\n",
    "            log_n_preds=log_n_preds,\n",
    "            use_wandb=use_wandb,\n",
    "            verbose=verbose,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "    def get_training_data(self):\n",
    "        return _get_training_data(cfg=self.train_config, data_dir=self.data_path)\n",
    "\n",
    "    def load_learner_or_model(self, model_learner_fpath: str | Path = None, device=\"cpu\"):\n",
    "        if model_learner_fpath is None:\n",
    "            model_learner_fpath = f\"{self.model_output_path}/{self.experiment_name}.pkl\"\n",
    "\n",
    "        learn = load_learner(model_learner_fpath, cpu=device == \"cpu\")\n",
    "        return learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "@patch\n",
    "def train(self: SummarizationModelTrainer, sweep_config: dict = None):\n",
    "    # setup\n",
    "    start = time.time()\n",
    "\n",
    "    yyyymmddHm = datetime.today().strftime(\"%Y%m%d_%H%m\")\n",
    "    seed = self.train_config.random_seed\n",
    "\n",
    "    # --- step 0: init the WANDB run if logging to wandb and update the training config from the sweep config if doing a sweep\n",
    "    is_sweep = True if sweep_config is not None else False\n",
    "\n",
    "    if self.use_wandb:\n",
    "        run = self.init_wandb_run(is_sweep)\n",
    "\n",
    "    # --- BEGIN TRAINING ---\n",
    "    if self.verbose:\n",
    "        print(f\"Experiment: {self.experiment_name}\")\n",
    "        print(f\"Training config: f{self.get_train_config_props()}\")\n",
    "\n",
    "    # --- step 1: get our TRAINING DATA ---\n",
    "    if self.verbose:\n",
    "        print(\"Preparing training data ...\")\n",
    "\n",
    "    summarization_df = self.get_training_data()\n",
    "\n",
    "    # --- step 2: get our HF OBJECTS ---\n",
    "    if self.verbose:\n",
    "        print(\"Building HF objects ...\")\n",
    "\n",
    "    hf_arch, hf_config, hf_tokenizer, hf_model = _get_task_hf_objects(self.train_config)\n",
    "\n",
    "    # --- step 3: DATALOADERS ---\n",
    "    if self.verbose:\n",
    "        print(\"Building DataLoaders ...\")\n",
    "\n",
    "    dls = _get_dls(self.train_config, summarization_df, hf_arch, hf_config, hf_tokenizer, hf_model)\n",
    "\n",
    "    # --- step 4: LEARNER ---\n",
    "    if self.verbose:\n",
    "        print(\"Building Learner ...\")\n",
    "\n",
    "    learn = _get_learner(cfg=self.train_config, dls=dls, hf_config=hf_config, hf_model=hf_model, hf_arch=hf_arch)\n",
    "\n",
    "    seq2seq_metrics = {\n",
    "        \"rouge\": {\n",
    "            \"compute_kwargs\": {\"rouge_types\": [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"], \"use_stemmer\": True},\n",
    "            \"returns\": [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"],\n",
    "        }\n",
    "    }\n",
    "    fit_cbs = [Seq2SeqMetricsCallback(custom_metrics=seq2seq_metrics)]\n",
    "\n",
    "    # add any learner callbacks req. by the `ModelTrainer`\n",
    "    if self.use_wandb and not is_sweep:\n",
    "        fit_cbs.append(WandbCallback(log_preds=False))\n",
    "\n",
    "    if self.train_config.random_seed and not self.train_config.only_seed_splits:\n",
    "        set_seed(self.train_config.random_seed)\n",
    "\n",
    "    learn.fit_one_cycle(\n",
    "        self.train_config.n_unfrozen_epochs,\n",
    "        cbs=fit_cbs,\n",
    "        lr_max=1e-4,\n",
    "    )\n",
    "\n",
    "    end = time.time()\n",
    "    if self.verbose:\n",
    "        print(f\"Time took for training is: {end - start}\")\n",
    "\n",
    "    learn.metrics = None\n",
    "\n",
    "    if self.verbose:\n",
    "        print(\"Saving model ...\")\n",
    "\n",
    "    learn.export(self.model_output_path / f\"{self.experiment_name}.pkl\")\n",
    "\n",
    "    # clean up\n",
    "    super(self.__class__, self).train()\n",
    "\n",
    "    if self.verbose:\n",
    "        print(\"End training\")\n",
    "\n",
    "    del learn, dls, hf_model, hf_tokenizer, hf_config\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `get_preds`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "@patch\n",
    "def get_preds(self: SummarizationModelTrainer, model_or_learner, df, **kwargs):\n",
    "    max_length = kwargs.get(\"max_target_length\", 10)\n",
    "    gen_algo = kwargs.get(\"gen_algo\", \"greedy\")\n",
    "\n",
    "    # To convey it's a headline summarization model\n",
    "    data = df.copy()\n",
    "\n",
    "    if self.train_config.max_target_length == headline_length:\n",
    "        headings = []\n",
    "        for i in range(len(data)):\n",
    "            headings.append(_get_preds(model_or_learner, data.iloc[i][\"transcript\"], \"greedy\", headline_length))\n",
    "        data.loc[:, \"topic_prediction\"] = headings\n",
    "\n",
    "    # To convey it's a content summarization model\n",
    "    elif self.train_config.max_target_length == content_length:\n",
    "        content_preds = []\n",
    "        for i in range(len(data)):\n",
    "            content_preds.append(_get_preds(model_or_learner, data.iloc[i][\"transcript\"], \"topp\", content_length))\n",
    "        data.loc[:, \"content_highlights\"] = content_preds\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = SummarizationModelTrainer(\n",
    "    task=\"train\",\n",
    "    experiment_name=\"content_summarization\",\n",
    "    train_config=XsumCFG,\n",
    "    data_path=\"../data\",\n",
    "    model_output_path=\"../models\",\n",
    "    log_output_path=\"../logs\",\n",
    "    log_preds=True,\n",
    "    log_n_preds=2,\n",
    "    use_wandb=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Training code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example inference code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11min 4s, sys: 21.8 s, total: 11min 26s\n",
      "Wall time: 10.4 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>course_title</th>\n",
       "      <th>lesson_num</th>\n",
       "      <th>start_seconds</th>\n",
       "      <th>topic</th>\n",
       "      <th>transcript</th>\n",
       "      <th>content_highlights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C-Squared Podcast</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Intro</td>\n",
       "      <td>[Music] welcome everybody to episode one of a chess themed podcast with myself christian kirilla and i'm fighting on caruana so what's up christian well not so much fabi uh it's first of all great um to finally start a podcast the chess podcast i know that um there's a lot of podcasts out there but i wanted to bring our own tune to the mix and i think uh yeah i'm excited about that so that's uh the first thing how about yourself fabian well i'm back in the states after it's been a while at your home it's good to be here it's my first time in uh visiting here and uh yeah it's been an intere...</td>\n",
       "      <td>I'm back in the states after it's been a few months playing a lot of chess . It's been an interesting few months playing a lot of chess which is pretty cool but also a bit difficult at times his home .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C-Squared Podcast</td>\n",
       "      <td>1</td>\n",
       "      <td>137.0</td>\n",
       "      <td>Candidates 2018</td>\n",
       "      <td>camps look like in general yeah well you mentioned the 2018 cycle uh where we worked together we started with the training before the candidates and for me it's interesting because i've i've played a lot of these candidates tournaments and i'm always doing it a bit differently trying different things trying to improve it but sometimes it goes less or more successfully you never know what will work out i think what we did in 2018 not just for the candidates but also for the world championship because i qualified for that i think what we did then was extremely successful um we we arranged it...</td>\n",
       "      <td>Maxine vachelagrav will be replaced by maxine vachelagrav .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C-Squared Podcast</td>\n",
       "      <td>1</td>\n",
       "      <td>464.0</td>\n",
       "      <td>Candidates training</td>\n",
       "      <td>going in the candidates like how was the experience yeah i think the preparation was pretty serious it included a bunch of uh camps and preparation devoted to players as i assume i think everyone has the same sort of general approach which is to think about their openings their strategy look at the opponents try to get in shape make sure that you're not you know rusty or blundering things or hallucinating variations uh but there's a lot of nerves and i i felt a lot of nerves before the tournament and i think possibly i you know overworked over trained a bit because it was yeah it was like ...</td>\n",
       "      <td>The preparation included a bunch of camps and preparation devoted to players . It was like work that pretty much led up straight to the tournament and nerfs more than you usually feel . It was like work that pretty much led up straight to the tournament and nerfs more than you usually feel .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        course_title lesson_num  start_seconds                topic  \\\n",
       "0  C-Squared Podcast          1            0.0                Intro   \n",
       "1  C-Squared Podcast          1          137.0      Candidates 2018   \n",
       "2  C-Squared Podcast          1          464.0  Candidates training   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                transcript  \\\n",
       "0  [Music] welcome everybody to episode one of a chess themed podcast with myself christian kirilla and i'm fighting on caruana so what's up christian well not so much fabi uh it's first of all great um to finally start a podcast the chess podcast i know that um there's a lot of podcasts out there but i wanted to bring our own tune to the mix and i think uh yeah i'm excited about that so that's uh the first thing how about yourself fabian well i'm back in the states after it's been a while at your home it's good to be here it's my first time in uh visiting here and uh yeah it's been an intere...   \n",
       "1  camps look like in general yeah well you mentioned the 2018 cycle uh where we worked together we started with the training before the candidates and for me it's interesting because i've i've played a lot of these candidates tournaments and i'm always doing it a bit differently trying different things trying to improve it but sometimes it goes less or more successfully you never know what will work out i think what we did in 2018 not just for the candidates but also for the world championship because i qualified for that i think what we did then was extremely successful um we we arranged it...   \n",
       "2  going in the candidates like how was the experience yeah i think the preparation was pretty serious it included a bunch of uh camps and preparation devoted to players as i assume i think everyone has the same sort of general approach which is to think about their openings their strategy look at the opponents try to get in shape make sure that you're not you know rusty or blundering things or hallucinating variations uh but there's a lot of nerves and i i felt a lot of nerves before the tournament and i think possibly i you know overworked over trained a bit because it was yeah it was like ...   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                     content_highlights  \n",
       "0                                                                                             I'm back in the states after it's been a few months playing a lot of chess . It's been an interesting few months playing a lot of chess which is pretty cool but also a bit difficult at times his home .  \n",
       "1                                                                                                                                                                                                                                           Maxine vachelagrav will be replaced by maxine vachelagrav .  \n",
       "2  The preparation included a bunch of camps and preparation devoted to players . It was like work that pretty much led up straight to the tournament and nerfs more than you usually feel . It was like work that pretty much led up straight to the tournament and nerfs more than you usually feel .  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "inf_learn = trainer.load_learner_or_model(\"../models/content_summarization.pkl\", device=\"cpu\")\n",
    "predicted_df = trainer.get_preds(inf_learn, sdf[:3])\n",
    "predicted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20803"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cleanup resources\n",
    "del inf_learn\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
