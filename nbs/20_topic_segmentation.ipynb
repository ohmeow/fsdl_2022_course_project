{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |default_exp topic_segmentation\n",
    "# |default_cls_lvl 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# topic_segmentation\n",
    "\n",
    "Training, saving, and tuning code for building topic segmentation model(s) that can predict where new topics begin given a transcript (e.g. rows of duration and text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "from __future__ import annotations\n",
    "\n",
    "import ast, os, gc, random, time\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from fastai.callback.all import *\n",
    "from fastai.callback.wandb import *\n",
    "from fastai.data.block import CategoryBlock, ColReader, ColSplitter, DataBlock, IndexSplitter, RegressionBlock\n",
    "from fastai.imports import *\n",
    "from fastai.layers import SigmoidRange\n",
    "from fastai.learner import *\n",
    "from fastai.losses import CrossEntropyLossFlat, MSELossFlat, LabelSmoothingCrossEntropyFlat\n",
    "from fastai.optimizer import Adam\n",
    "from fastai.metrics import *\n",
    "from fastai.torch_core import *\n",
    "from fastai.torch_imports import *\n",
    "from fastcore.transform import Transform\n",
    "import optuna\n",
    "from optuna.integration.fastaiv2 import FastAIPruningCallback\n",
    "from optuna.integration.wandb import WeightsAndBiasesCallback\n",
    "import segeval\n",
    "from sklearn.metrics import mean_absolute_error, f1_score, recall_score, precision_score, fbeta_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statistics\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForNextSentencePrediction,\n",
    "    AutoModelForSequenceClassification,\n",
    "    DebertaV2Model,\n",
    "    logging as hf_logging,\n",
    ")\n",
    "from transformers.models.deberta_v2.modeling_deberta_v2 import ContextPooler\n",
    "from transformers.models.deberta_v2.modeling_deberta_v2 import StableDropout\n",
    "import wandb\n",
    "\n",
    "from blurr.callbacks import GradientCheckpointing\n",
    "from blurr.text.data.core import TextBlock, BatchTokenizeTransform, first_blurr_tfm\n",
    "from blurr.text.modeling.core import BaseModelWrapper, BaseModelCallback, blurr_splitter\n",
    "from blurr.text.utils import get_hf_objects\n",
    "from blurr.utils import PreCalculatedCrossEntropyLoss, PreCalculatedMSELoss, set_seed\n",
    "\n",
    "from course_copilot import preprocessing, training, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import pdb\n",
    "\n",
    "from fastcore.test import *\n",
    "import nbdev\n",
    "\n",
    "from blurr.utils import print_versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "# silence all the HF warnings and load environment variables\n",
    "warnings.simplefilter(\"ignore\")\n",
    "hf_logging.set_verbosity_error()\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: false\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "print(\"What we're running with at the time this documentation was generated:\")\n",
    "print_versions(\"torch fastai transformers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "# |cuda\n",
    "torch.cuda.set_device(1)\n",
    "print(f\"Using GPU #{torch.cuda.current_device()}: {torch.cuda.get_device_name()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.environ[\"WANDB_PROJECT_NAME\"])\n",
    "print(os.environ[\"WANDB_TEAM\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class TopicSegmentationConfig(training.TrainConfig):\n",
    "    \"\"\"A 'training.Config' object training and tuning our segmentation models. Uses fastai and huggingface defaults by default\"\"\"\n",
    "\n",
    "    # huggingface objects\n",
    "    hf_model_cls = AutoModelForSequenceClassification\n",
    "    hf_model_checkpoint = \"microsoft/deberta-v3-small\"\n",
    "    hf_config_kwargs = {\"num_labels\": 2}\n",
    "    hf_tokenizer_kwargs = {}\n",
    "    new_special_tokens = None\n",
    "    hf_model_kwargs = {}\n",
    "\n",
    "    # datablock/dataloaders\n",
    "    use_next_pos_prob = 0.75\n",
    "    use_adjacent_neg_prob = 0.5\n",
    "    max_length = True\n",
    "    lower_case = True\n",
    "    truncation_strategy = True\n",
    "    include_labels = False\n",
    "    tok_kwargs = {}\n",
    "    batch_size = 8\n",
    "    accum = None\n",
    "\n",
    "    # learner\n",
    "    custom_model_kwargs = {\"p\": 0.1, \"dropout_cls\": nn.Dropout}\n",
    "    include_gradient_checkpointing = False\n",
    "    one_cycle_moms_start = 0.8\n",
    "    one_cycle_moms_min = 0.7\n",
    "    one_cycle_moms_end = 0.8\n",
    "    adam_beta2 = 0.99\n",
    "    adam_eps = 1e-7\n",
    "    weight_decay = 0.0\n",
    "    max_grad_norm = None\n",
    "    save_best_model = True\n",
    "    use_fp16 = True\n",
    "\n",
    "    # training\n",
    "    n_frozen_epochs = 0\n",
    "    frozen_lr = 0\n",
    "    n_unfrozen_epochs = 4\n",
    "    unfrozen_lr_min = 1e-5\n",
    "    unfrozen_lr_max = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleCFG(TopicSegmentationConfig):\n",
    "    training_subset = 0.25\n",
    "    n_frozen_epochs = 0\n",
    "    n_unfrozen_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[f\"{k}: {v}\" for k, v in training.get_train_config_props(ExampleCFG).items()][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def get_training_data(cfg: TopicSegmentationConfig, data_dir=\"data\", on_the_fly=False, split_type=\"cross_validation\"):\n",
    "    if on_the_fly:\n",
    "        raw_train_df, _ = preprocessing.preprocess_data(\n",
    "            ds=\"train\", data_path=data_dir, return_file=True, save_file=False\n",
    "        )\n",
    "    else:\n",
    "        raw_train_df = pd.read_csv(f\"{data_dir}/clean/segmentation_train.csv\", index_col=None)\n",
    "\n",
    "    raw_train_df[\"other_topic_seqs\"] = raw_train_df[\"other_topic_seqs\"].apply(ast.literal_eval)\n",
    "    raw_train_df.reset_index(inplace=True)\n",
    "\n",
    "    # for training we need to remove sequences for which there is not a \"next_seq\" (e.g., we are at end of a topic)\n",
    "    train_df = raw_train_df[raw_train_df[\"is_topic_end\"] == False].copy()\n",
    "\n",
    "    train_df = train_df.sample(frac=cfg.training_subset, random_state=cfg.random_seed).reset_index(drop=True)\n",
    "\n",
    "    if split_type == \"cross_validation\":\n",
    "        courses = train_df[\"course_title\"].unique()\n",
    "        np.random.seed(cfg.random_seed)\n",
    "        np.random.shuffle(courses)\n",
    "\n",
    "        val_sz = int(len(courses) * cfg.val_pct)\n",
    "        val_courses = courses[:val_sz]\n",
    "\n",
    "        is_val = np.isin(train_df[\"course_title\"], val_courses)\n",
    "\n",
    "        idxs = np.arange(len(train_df))\n",
    "        val_idxs = idxs[is_val]\n",
    "        trn_idxs = idxs[~is_val]\n",
    "\n",
    "        return train_df.copy(), trn_idxs, val_idxs, raw_train_df.copy()\n",
    "    else:\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, trn_idxs, val_idxs, raw_train_df = get_training_data(\n",
    "    ExampleCFG, data_dir=\"../data\", on_the_fly=False, split_type=\"cross_validation\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_df))\n",
    "print(len(trn_idxs), len(val_idxs))\n",
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hugging Face `transformers` objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def get_task_hf_objects(cfg: TopicSegmentationConfig):\n",
    "    # if 'only_seed_splits' = True, then we only care about reproducibility insofar as the training and\n",
    "    # validation sets go\n",
    "    if cfg.random_seed and not cfg.only_seed_splits:\n",
    "        set_seed(cfg.random_seed)\n",
    "\n",
    "    # need to create configuration object separately because we may be adding new attributes (e.g., cls_dropout)\n",
    "    hf_config = AutoConfig.from_pretrained(cfg.hf_model_checkpoint)\n",
    "    hf_config.update(cfg.hf_config_kwargs)\n",
    "\n",
    "    hf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(\n",
    "        cfg.hf_model_checkpoint,\n",
    "        model_cls=cfg.hf_model_cls,\n",
    "        config=hf_config,\n",
    "        tokenizer_kwargs=cfg.hf_tokenizer_kwargs,\n",
    "        model_kwargs=cfg.hf_model_kwargs,\n",
    "    )\n",
    "\n",
    "    if cfg.new_special_tokens:\n",
    "        # After adding the new tokens, we need to resize the embedding matrix in the model and initialize the weights\n",
    "        hf_tokenizer.add_special_tokens({\"additional_special_tokens\": cfg.new_special_tokens})\n",
    "        hf_model.resize_token_embeddings(len(hf_tokenizer))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            emb_size = hf_model.config.to_dict().get(\"embedding_size\", hf_model.config.hidden_size)\n",
    "            hf_model.get_input_embeddings().weight[-len(hf_tokenizer), :] = torch.zeros([emb_size])\n",
    "\n",
    "    return hf_arch, hf_config, hf_tokenizer, hf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_arch, hf_config, hf_tokenizer, hf_model = get_task_hf_objects(ExampleCFG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `DataLoaders`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def build_pos_inputs(example, cfg: TopicSegmentationConfig, hf_tokenizer_sep_token=\"[SEP]\"):\n",
    "    seq_text = example[\"seq\"].strip().lower() if cfg.lower_case else example[\"seq\"].strip()\n",
    "    next_seq_text = example[\"next_seq\"].strip().lower() if cfg.lower_case else example[\"next_seq\"].strip()\n",
    "\n",
    "    non_adjacent_text = (\n",
    "        random.choice(example[\"other_topic_seqs\"]).strip() if len(example[\"other_topic_seqs\"]) > 0 else None\n",
    "    )\n",
    "    if cfg.lower_case and non_adjacent_text:\n",
    "        non_adjacent_text = non_adjacent_text.lower()\n",
    "\n",
    "    if example[\"is_topic_end\"] and example[\"next_topic_begin_seq\"] and non_adjacent_text:\n",
    "        # this is the last sequence in the topic so the only thing that will work here is to pair it with another non-adjacent seq in the same topic\n",
    "        # and therefore we just duplicate it here.\n",
    "        next_topic_begin_seq = (\n",
    "            example[\"next_topic_begin_seq\"].strip().lower()\n",
    "            if cfg.lower_case\n",
    "            else example[\"next_topic_begin_seq\"].strip()\n",
    "        )\n",
    "        inp = (\n",
    "            f\"{seq_text}{hf_tokenizer_sep_token}{non_adjacent_text}\",\n",
    "            f\"{seq_text}{hf_tokenizer_sep_token}{non_adjacent_text}\",\n",
    "        )\n",
    "    else:\n",
    "        # the positive pair will be a seq + the next seq -or- the seq + a non-adjacent seq in the same topic\n",
    "        inp = (\n",
    "            f\"{seq_text}{hf_tokenizer_sep_token}{next_seq_text}\",\n",
    "            f\"{seq_text}{hf_tokenizer_sep_token}{non_adjacent_text}\" if non_adjacent_text else \"xxNONExx\",\n",
    "        )\n",
    "\n",
    "    return inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def build_neg_inputs(example, cfg: TopicSegmentationConfig, hf_tokenizer_sep_token=\"[SEP]\", df=None):\n",
    "    seq_text = example[\"seq\"].strip()\n",
    "\n",
    "    # if at the last sequence for a topic, set the negative pair = seq + first sequence in next topic,\n",
    "    # else get a sequence that is not adjacent but in same topic\n",
    "    if example[\"is_topic_end\"] and example[\"next_topic_begin_seq\"]:\n",
    "        neg_seq_non_adjacent_text = example[\"next_topic_begin_seq\"].strip()\n",
    "    elif len(example[\"other_topic_seqs\"]) > 0:\n",
    "        neg_seq_non_adjacent_text = random.choice(example[\"other_topic_seqs\"]).strip()\n",
    "    else:\n",
    "        neg_seq_non_adjacent_text = \"xxNONExx\"\n",
    "\n",
    "    # get a sequence that is in an entirely different topic\n",
    "    # option 1: can be in same lesson but different topic or in a different course entirely\n",
    "    # neg_seq_other_topic_text = (\n",
    "    #     df[\"seq\"][\n",
    "    #         (df[\"course_title\"] != example[\"course_title\"]) | (df[\"lesson_num\"] != example[\"lesson_num\"])\n",
    "    #     ]\n",
    "    #     .sample(n=1)\n",
    "    #     .values[0]\n",
    "    #     .strip()\n",
    "    # )\n",
    "\n",
    "    # option 2: sample from a different course entirely\n",
    "    neg_seq_other_topic_text = df[\"seq\"][(df[\"course_title\"] != example[\"course_title\"])].sample(n=1).values[0].strip()\n",
    "\n",
    "    if cfg.lower_case:\n",
    "        seq_text = seq_text.lower()\n",
    "        neg_seq_non_adjacent_text = neg_seq_non_adjacent_text.lower()\n",
    "        neg_seq_other_topic_text = neg_seq_other_topic_text.lower()\n",
    "\n",
    "    # our SiameseBatchTokenizeTransform will choose which one to use each time the item is fetched\n",
    "    inp = (\n",
    "        f\"{seq_text}{hf_tokenizer_sep_token}{neg_seq_non_adjacent_text}\",\n",
    "        f\"{seq_text}{hf_tokenizer_sep_token}{neg_seq_other_topic_text}\",\n",
    "    )\n",
    "\n",
    "    return inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def build_targets(example):\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class SiameseBatchTokenizeTransform(BatchTokenizeTransform):\n",
    "    def __init__(self, use_next_pos_prob=0.75, use_adjacent_neg_prob=0.5, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.use_next_pos_prob = use_next_pos_prob\n",
    "        self.use_adjacent_neg_prob = use_adjacent_neg_prob\n",
    "\n",
    "    def encodes(self, samples, return_batch_encoding=False):\n",
    "        # our positive example\n",
    "        pos_ex_idx = 0 if random.uniform(0, 1) < self.use_next_pos_prob else 1\n",
    "        updated_samples1, inputs1 = super().encodes(\n",
    "            [(s[0][pos_ex_idx] if s[0][pos_ex_idx] != \"xxNONExx\" else s[0][0], *s[2:], *s[2:]) for s in samples],\n",
    "            return_batch_encoding=True,\n",
    "        )\n",
    "\n",
    "        # our negative example (sometimes the adjacent will be \"\"; if that is the case use the other topic negative example which is at idx=1)\n",
    "        neg_ex_idx = 0 if random.uniform(0, 1) < self.use_adjacent_neg_prob and pos_ex_idx == 0 else 1\n",
    "        updated_samples2, inputs2 = super().encodes(\n",
    "            [(s[1][neg_ex_idx] if s[1][neg_ex_idx] != \"xxNONExx\" else s[1][1], *s[2:]) for s in samples],\n",
    "            return_batch_encoding=True,\n",
    "        )\n",
    "\n",
    "        # if there are no targets (e.g., when used for inference)\n",
    "        if len(samples[0]) == 2:\n",
    "            return [(inps1[0], inps2[0]) for inps1, inps2 in zip(updated_samples1, updated_samples2)]\n",
    "\n",
    "        return [(inps1[0], inps2[0], inps1[-1]) for inps1, inps2 in zip(updated_samples1, updated_samples2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def get_dls(cfg: TopicSegmentationConfig, df, hf_arch, hf_config, hf_tokenizer, hf_model, val_idxs_or_fold):\n",
    "    # define validation set\n",
    "    if isinstance(val_idxs_or_fold, int):\n",
    "        df[\"is_valid\"] = df[\"k_fold\"] == val_idxs_or_fold\n",
    "        splitter = ColSplitter()\n",
    "    else:\n",
    "        splitter = IndexSplitter(val_idxs_or_fold)\n",
    "\n",
    "    if cfg.random_seed:\n",
    "        set_seed(cfg.random_seed)\n",
    "\n",
    "    batch_tokenize_tfm = SiameseBatchTokenizeTransform(\n",
    "        use_next_pos_prob=cfg.use_next_pos_prob,\n",
    "        use_adjacent_neg_prob=cfg.use_adjacent_neg_prob,\n",
    "        hf_arch=hf_arch,\n",
    "        hf_config=hf_config,\n",
    "        hf_tokenizer=hf_tokenizer,\n",
    "        hf_model=hf_model,\n",
    "        include_labels=cfg.include_labels,\n",
    "        max_length=cfg.max_length,\n",
    "        truncation=cfg.truncation_strategy,\n",
    "        tok_kwargs=cfg.tok_kwargs,\n",
    "    )\n",
    "\n",
    "    blocks = (TextBlock(batch_tokenize_tfm=batch_tokenize_tfm), noop, CategoryBlock)\n",
    "\n",
    "    get_pos_x = partial(build_pos_inputs, cfg=cfg, hf_tokenizer_sep_token=hf_tokenizer.sep_token)\n",
    "    get_neg_x = partial(build_neg_inputs, cfg=cfg, hf_tokenizer_sep_token=hf_tokenizer.sep_token, df=df)\n",
    "    get_y = partial(build_targets)\n",
    "\n",
    "    dblock = DataBlock(\n",
    "        blocks=blocks,\n",
    "        get_x=[get_pos_x, get_neg_x],\n",
    "        get_y=get_y,\n",
    "        splitter=splitter,\n",
    "        n_inp=2,\n",
    "    )\n",
    "\n",
    "    if cfg.random_seed:\n",
    "        set_seed(cfg.random_seed)\n",
    "\n",
    "    bsz = cfg.batch_size if cfg.accum is None else cfg.batch_size // cfg.accum\n",
    "    return dblock.dataloaders(df, bs=bsz, val_bs=bsz * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = get_dls(ExampleCFG, train_df, hf_arch, hf_config, hf_tokenizer, hf_model, val_idxs_or_fold=val_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = dls.one_batch()\n",
    "print(len(b))\n",
    "print(\"\")\n",
    "print(hf_tokenizer.decode(b[0][\"input_ids\"][0]))\n",
    "print(\"\")\n",
    "print(hf_tokenizer.decode(b[1][\"input_ids\"][0]))\n",
    "print(\"\")\n",
    "print(b[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def blurr_splitter_with_head(m: Module):\n",
    "    \"\"\"Simply adds an additional layer group to the classification head\"\"\"\n",
    "    base_param_groups = blurr_splitter(m)\n",
    "\n",
    "    added_groups = L([m for m_name, m in list(m.named_children()) if m_name != \"hf_model\"])\n",
    "    added_param_groups = added_groups.map(params).filter(lambda el: len(el) > 0)\n",
    "\n",
    "    return base_param_groups + added_param_groups\n",
    "\n",
    "\n",
    "def blurr_splitter_on_backbone(m: Module):\n",
    "    \"\"\"Creates two layer groups: One for the backbone and one for the pooler/classification head\"\"\"\n",
    "    root_modules = list(m.named_children())\n",
    "    top_module_name, top_module = root_modules[0]\n",
    "\n",
    "    groups = L(top_module)\n",
    "    groups += L([m for m_name, m in root_modules[1:]])\n",
    "\n",
    "    return groups.map(params).filter(lambda el: len(el) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "# TODO: Review PyTorch docs (https://pytorch.org/docs/stable/generated/torch.nn.MarginRankingLoss.html); consider changing\n",
    "def MarginRankingLoss(pos_neg_scores, targs):\n",
    "    margin = 1\n",
    "    p_scores, n_scores = pos_neg_scores\n",
    "\n",
    "    scores = margin - p_scores + n_scores\n",
    "    scores = scores.clamp(min=0)\n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def topic_seg_f1_score(inps, targs):\n",
    "    labels = []\n",
    "    all_pos_scores, all_neg_scores = inps[0], inps[1]\n",
    "\n",
    "    for i in range(len(all_pos_scores)):\n",
    "        if all_pos_scores[i] > all_neg_scores[i]:\n",
    "            labels.append(1)\n",
    "        else:\n",
    "            labels.append(0)\n",
    "\n",
    "    return sum(labels) / float(len(all_pos_scores))\n",
    "\n",
    "\n",
    "_topic_seg_f1_score = AvgMetric(topic_seg_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class TopicSegmentationModelWrapper(BaseModelWrapper):\n",
    "    def __init__(\n",
    "        self,\n",
    "        hf_config,\n",
    "        hf_model,\n",
    "        dropout_cls=nn.Dropout,\n",
    "        p=0.1,\n",
    "        hf_model_kwargs={},\n",
    "    ):\n",
    "        super().__init__(hf_model=hf_model, output_hidden_states=True, hf_model_kwargs=hf_model_kwargs)\n",
    "        store_attr()\n",
    "\n",
    "        self.coherence_prediction_dec = nn.Sequential(\n",
    "            *[\n",
    "                nn.Linear(hf_config.hidden_size, hf_config.hidden_size),\n",
    "                nn.ReLU(),\n",
    "                dropout_cls(p=p),\n",
    "                nn.Linear(hf_config.hidden_size, 2),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs1, inputs2):\n",
    "        # sequence 1 (pos examples)\n",
    "        inputs1_res = super().forward(inputs1)\n",
    "        pos_scores = inputs1_res.hidden_states[-1][:, 0, :]\n",
    "        pos_scores = self.coherence_prediction_dec(pos_scores)\n",
    "\n",
    "        # sequence 2 (neg examples)\n",
    "        inputs2_res = super().forward(inputs2)\n",
    "        neg_scores = inputs2_res.hidden_states[-1][:, 0, :]\n",
    "        neg_scores = self.coherence_prediction_dec(neg_scores)\n",
    "\n",
    "        return pos_scores[:, 0], neg_scores[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Learner`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def get_learner(cfg: TopicSegmentationConfig, dls, hf_config, hf_model, learner_path=\".\"):\n",
    "\n",
    "    if cfg.random_seed and not cfg.only_seed_splits:\n",
    "        set_seed(cfg.random_seed)\n",
    "\n",
    "    learn_cbs = []\n",
    "    if cfg.accum is not None:\n",
    "        learn_cbs.append(GradientAccumulation(cfg.batch_size))\n",
    "\n",
    "    blurr_model_wrapper = TopicSegmentationModelWrapper(\n",
    "        hf_config=hf_config, hf_model=hf_model, **cfg.custom_model_kwargs\n",
    "    )\n",
    "\n",
    "    learn = Learner(\n",
    "        dls,\n",
    "        blurr_model_wrapper,\n",
    "        model_dir=learner_path,\n",
    "        opt_func=partial(Adam, sqr_mom=cfg.adam_beta2, eps=cfg.adam_eps, wd=cfg.weight_decay),\n",
    "        moms=(cfg.one_cycle_moms_start, cfg.one_cycle_moms_min, cfg.one_cycle_moms_end),\n",
    "        loss_func=PreCalculatedCrossEntropyLoss() if cfg.include_labels else MarginRankingLoss,\n",
    "        metrics=[topic_seg_f1_score],\n",
    "        cbs=learn_cbs,\n",
    "        splitter=blurr_splitter_on_backbone,\n",
    "    )\n",
    "\n",
    "    learn.create_opt()\n",
    "    learn.freeze()\n",
    "\n",
    "    if cfg.use_fp16:\n",
    "        learn = learn.to_fp16()\n",
    "\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = get_learner(cfg=ExampleCFG, dls=dls, hf_config=hf_config, hf_model=hf_model, learner_path=\"../models\")\n",
    "\n",
    "fit_cbs = []\n",
    "if ExampleCFG.max_grad_norm:\n",
    "    fit_cbs.append(GradientClip(max_norm=ExampleCFG.max_grad_norm))\n",
    "\n",
    "if ExampleCFG.include_gradient_checkpointing:\n",
    "    fit_cbs.append(GradientCheckpointing())\n",
    "\n",
    "if ExampleCFG.save_best_model:\n",
    "    fit_cbs.append(\n",
    "        SaveModelCallback(\n",
    "            monitor=\"valid_loss\",\n",
    "            comp=np.less,\n",
    "            fname=f\"temp_best_f1_topic_segmentation\",\n",
    "            reset_on_fit=False,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(learn.opt.param_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.unfreeze()\n",
    "# learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.lr_find(suggest_funcs=[minimum, steep, valley, slide])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ExampleCFG.random_seed:\n",
    "    set_seed(ExampleCFG.random_seed)\n",
    "\n",
    "learn.fit_one_cycle(1, slice(1e-5, 1e-3), cbs=fit_cbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[f\"{k}: {v}\" for k, v in training.get_train_config_props(ExampleCFG).items()][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.metric_names, learn.recorder.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export(\"../models/test_topic_segmentation.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def depth_score_cal(scores):\n",
    "    output_scores = []\n",
    "    for i in range(len(scores)):\n",
    "        lflag = scores[i]\n",
    "        rflag = scores[i]\n",
    "        if i == 0:\n",
    "            hl = scores[i]\n",
    "            for r in range(i + 1, len(scores)):\n",
    "                if rflag <= scores[r]:\n",
    "                    rflag = scores[r]\n",
    "                else:\n",
    "                    break\n",
    "        elif i == len(scores):\n",
    "            hr = scores[i]\n",
    "            for l in range(i - 1, -1, -1):\n",
    "                if lflag <= scores[l]:\n",
    "                    lflag = scores[l]\n",
    "                else:\n",
    "                    break\n",
    "        else:\n",
    "            for r in range(i + 1, len(scores)):\n",
    "                if rflag <= scores[r]:\n",
    "                    rflag = scores[r]\n",
    "                else:\n",
    "                    break\n",
    "            for l in range(i - 1, -1, -1):\n",
    "                if lflag <= scores[l]:\n",
    "                    lflag = scores[l]\n",
    "                else:\n",
    "                    break\n",
    "        depth_score = 0.5 * (lflag + rflag - 2 * scores[i])\n",
    "        output_scores.append(depth_score)\n",
    "\n",
    "    return output_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def get_validation_preds(\n",
    "    hf_model, hf_tokenizer, val_df, val_course_titles, batch_size=16, threshold_std_coeff=1.0, verbose=False\n",
    "):\n",
    "    hf_model.eval()\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Getting predictions for validatation set ...\")\n",
    "\n",
    "    val_results = []\n",
    "    for ct in val_course_titles:\n",
    "        for ln in val_df[val_df[\"course_title\"] == ct][\"lesson_num\"].unique().tolist():\n",
    "            inf_df = raw_train_df[(raw_train_df[\"course_title\"] == ct) & (raw_train_df[\"lesson_num\"] == ln)].copy()\n",
    "            inf_df.reset_index(inplace=True)\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"processing {ct}: {ln}\")\n",
    "\n",
    "            # gather sequence pairs\n",
    "            seq_pairs = L()\n",
    "            for i in range(len(inf_df) - 1):\n",
    "                seq_a = inf_df.iloc[i][\"seq\"].strip().lower()\n",
    "                seq_b = inf_df.iloc[i + 1][\"seq\"].strip().lower()\n",
    "\n",
    "                seq_pairs.append((seq_a, seq_b))\n",
    "\n",
    "            # score sequence pairs\n",
    "            scores = []\n",
    "            for i in range(0, len(seq_pairs), batch_size):\n",
    "                # print(i)\n",
    "                batch = seq_pairs[i : i + batch_size]\n",
    "                inputs = hf_tokenizer(\n",
    "                    list(batch.itemgot(0)), list(batch.itemgot(1)), padding=True, max_length=True, return_tensors=\"pt\"\n",
    "                ).to(hf_model.device)\n",
    "\n",
    "                batch_scores = hf_model(**inputs)\n",
    "                scores += batch_scores[0][:, 0].detach().cpu()[:, None]\n",
    "\n",
    "            scores = torch.sigmoid(torch.concat(scores)).numpy().tolist()\n",
    "\n",
    "            # calculate depth_scores\n",
    "            depth_scores = depth_score_cal(scores)\n",
    "            threshold = sum(depth_scores) / (len(depth_scores)) + (statistics.stdev(depth_scores) * threshold_std_coeff)\n",
    "\n",
    "            # calculate reference (target) topics and count of sequences in each\n",
    "            # seg_r_labels = reference beginning of new topic\n",
    "            # seg_r = # of sequences in each reference topic\n",
    "            seg_r_labels = []\n",
    "            seg_r = []\n",
    "            tmp = 1\n",
    "\n",
    "            for r_idx, r in inf_df.iterrows():\n",
    "                current_topic = r[\"topic\"]\n",
    "                if r_idx == 0:\n",
    "                    last_seen_topic = r[\"topic\"]\n",
    "\n",
    "                if last_seen_topic != current_topic:\n",
    "                    last_seen_topic = current_topic\n",
    "                    seg_r_labels.append(1)\n",
    "                    seg_r.append(tmp)\n",
    "                    tmp = 1\n",
    "                else:\n",
    "                    seg_r_labels.append(0)\n",
    "                    tmp += 1 if r_idx != 0 else 0\n",
    "\n",
    "            seg_r.append(tmp)\n",
    "\n",
    "            # seg_p_labels = predicted beginning of new topic\n",
    "            # seg_p = # of sequences in each predicted topic\n",
    "\n",
    "            # we add 1 in here to compensate for lopping off the last sequence (which we do cuz it has no next_seq to pair with)\n",
    "            # default everything to 0\n",
    "            seg_p_labels = [0] * (len(depth_scores) + 1)\n",
    "\n",
    "            # loop thru `depth_scores`, if any > threshold mark them as a boundary (beginning of a new topic) and then update `seg_p_labels`\n",
    "            boundary_idxs = []\n",
    "            for i in range(len(depth_scores)):\n",
    "                if depth_scores[i] > threshold:\n",
    "                    boundary_idxs.append(i)\n",
    "\n",
    "            for i in boundary_idxs:\n",
    "                seg_p_labels[i] = 1\n",
    "\n",
    "            tmp = 0\n",
    "            seg_p = []\n",
    "            for idx, is_beg_topic in enumerate(seg_p_labels):\n",
    "                if is_beg_topic == 1 and idx != 0:\n",
    "                    # tmp += 1\n",
    "                    seg_p.append(tmp)\n",
    "                    tmp = 1\n",
    "                else:\n",
    "                    tmp += 1\n",
    "\n",
    "            seg_p.append(tmp)\n",
    "\n",
    "            seg_idxs = [seg_idx for seg_idx, v in enumerate(seg_p_labels) if v == 1 or seg_idx == 0]\n",
    "            inf_df[\"depth_score\"] = depth_scores + [None]\n",
    "            inf_df[\"threshold\"] = threshold\n",
    "            inf_df[\"pred_start\"] = False\n",
    "            inf_df.loc[seg_idxs, \"pred_start\"] = True\n",
    "\n",
    "            val_results.append(inf_df)\n",
    "\n",
    "    return pd.concat(val_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_course_titles = train_df.iloc[val_idxs][\"course_title\"].unique().tolist()\n",
    "preds_df = get_validation_preds(\n",
    "    hf_model,\n",
    "    hf_tokenizer,\n",
    "    raw_train_df,\n",
    "    val_course_titles[:2],\n",
    "    batch_size=16,\n",
    "    threshold_std_coeff=1.0,\n",
    ")\n",
    "\n",
    "print(len(preds_df))\n",
    "preds_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def get_preds(data, learner_fpath, threshold_std_coeff=1.5):\n",
    "    inf_learn = load_learner(learner_fpath)\n",
    "    batch_tok_transform = first_blurr_tfm(inf_learn.dls)\n",
    "    batch_size = inf_learn.dls.bs\n",
    "\n",
    "    inf_hf_model = inf_learn.model.hf_model.eval()\n",
    "    inf_hf_tokenizer = batch_tok_transform.hf_tokenizer\n",
    "\n",
    "    # build seq + next_seq pairs\n",
    "    seq_pairs = L()\n",
    "    for i in range(len(data) - 1):\n",
    "        seq_a = data.iloc[i][\"transcript\"].strip().lower()\n",
    "        seq_b = data.iloc[i + 1][\"transcript\"].strip().lower()\n",
    "\n",
    "        seq_pairs.append((seq_a, seq_b))\n",
    "\n",
    "    # get predictions from just the HF model for the `seq_pairs` above\n",
    "    scores = []\n",
    "    for i in range(0, len(seq_pairs), batch_size):\n",
    "        # print(i)\n",
    "        batch = seq_pairs[i : i + batch_size]\n",
    "        inputs = inf_hf_tokenizer(\n",
    "            list(batch.itemgot(0)), list(batch.itemgot(1)), padding=True, max_length=True, return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        batch_scores = inf_learn.model.hf_model(**inputs)\n",
    "        scores += batch_scores[0][:, 0].detach().cpu()[:, None]\n",
    "\n",
    "    # take the sigmoid so range is between 0 and 1 for each value\n",
    "    scores = torch.sigmoid(torch.concat(scores)).numpy().tolist()\n",
    "\n",
    "    depth_scores = depth_score_cal(scores)\n",
    "\n",
    "    # `threshold_std_coeff` defines a `threshold` based on `depth_score` where any sequence pair with a score > threshold will be\n",
    "    # predicted as a start of a new topic (The paper/code does this differently but the results are abysmal. The std coefficient\n",
    "    # should be tuned to optimize for F1, F2, or whatever\n",
    "    threshold = sum(depth_scores) / (len(depth_scores)) + (statistics.stdev(depth_scores) * threshold_std_coeff)\n",
    "\n",
    "    # get predicted topic starts\n",
    "    # seg_p_labels = predicted beginning of new topic | seg_p = # of sequences in each predicted topic\n",
    "\n",
    "    # we add 1 in here to compensate for lopping off the last sequence (which we do cuz it has no next_seq to pair with)\n",
    "    # default everything to 0\n",
    "    seg_p_labels = [0] * (len(depth_scores) + 1)\n",
    "\n",
    "    # loop thru `depth_scores`, if any > threshold mark them as a boundary (beginning of a new topic) and then update `seg_p_labels`\n",
    "    boundary_idxs = []\n",
    "    for i in range(len(depth_scores)):\n",
    "        if depth_scores[i] > threshold:\n",
    "            boundary_idxs.append(i)\n",
    "\n",
    "    for i in boundary_idxs:\n",
    "        seg_p_labels[i] = 1\n",
    "\n",
    "    tmp = 0\n",
    "    seg_p = []\n",
    "    for idx, is_beg_topic in enumerate(seg_p_labels):\n",
    "        if is_beg_topic == 1 and idx != 0:\n",
    "            # tmp += 1\n",
    "            seg_p.append(tmp)\n",
    "            tmp = 1\n",
    "        else:\n",
    "            tmp += 1\n",
    "\n",
    "    seg_p.append(tmp)\n",
    "\n",
    "    # update inference dataset with depth_score for each row as well as the threshold used and whether it is start of a topic\n",
    "    seg_idxs = [seg_idx for seg_idx, v in enumerate(seg_p_labels) if v == 1 or seg_idx == 0]\n",
    "    data[\"depth_score\"] = depth_scores + [None]\n",
    "    data[\"threshold\"] = threshold\n",
    "    data[\"pred_start\"] = False\n",
    "    data.loc[seg_idxs, \"pred_start\"] = True\n",
    "\n",
    "    # clean up\n",
    "    del inf_learn, inf_hf_model, inf_hf_tokenizer\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    # return the updated inference dataset and the topic start indices\n",
    "    return data, seg_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_df = pd.read_csv(f\"../data/clean/segmentation_train.csv\", index_col=None)\n",
    "\n",
    "val_course_title = \"fast.ai 2022 - Part 1\"\n",
    "val_lesson_num = \"4\"\n",
    "\n",
    "inf_df = raw_train_df[\n",
    "    (raw_train_df[\"course_title\"] == val_course_title) & (raw_train_df[\"lesson_num\"] == val_lesson_num)\n",
    "].copy()\n",
    "inf_df[\"transcript\"] = inf_df[\"seq\"]\n",
    "inf_df.reset_index(inplace=True)\n",
    "\n",
    "print(len(inf_df))\n",
    "inf_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df, seg_idxs = get_preds(inf_df, \"../models/test_topic_segmentation.pkl\", threshold_std_coeff=1.0)\n",
    "\n",
    "print(seg_idxs[:10])\n",
    "print(len(preds_df))\n",
    "preds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del learn\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class TopicSegmentationModelTrainer(training.ModelTrainer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        experiment_name,\n",
    "        train_config: TopicSegmentationConfig,\n",
    "        data_path=\"data\",\n",
    "        model_output_path=\"models\",\n",
    "        log_output_path=\"logs\",\n",
    "        log_preds=False,\n",
    "        log_n_preds=None,\n",
    "        use_wandb=False,\n",
    "        verbose=False,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            experiment_name=experiment_name,\n",
    "            train_config=train_config,\n",
    "            data_path=data_path,\n",
    "            model_output_path=model_output_path,\n",
    "            log_output_path=log_output_path,\n",
    "            log_preds=log_preds,\n",
    "            log_n_preds=log_n_preds,\n",
    "            use_wandb=use_wandb,\n",
    "            verbose=verbose,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "    def get_training_data(self, on_the_fly=False, split_type=\"cross_validation\"):\n",
    "        return get_training_data(\n",
    "            cfg=self.train_config, data_dir=self.data_path, on_the_fly=on_the_fly, split_type=split_type\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "@patch\n",
    "def train(self: TopicSegmentationModelTrainer, trial: optuna.Trial = None):\n",
    "    # timing\n",
    "    start = time.time()\n",
    "\n",
    "    yyyymmddHm = datetime.today().strftime(\"%Y%m%d_%H%m\")\n",
    "    seed = self.train_config.random_seed\n",
    "\n",
    "    if self.verbose:\n",
    "        print(f\"Experiment: {self.experiment_name}\")\n",
    "        print(f\"Training config: f{self.get_train_config_props()}\")\n",
    "\n",
    "    # --- step 1: get our TRAINING DATA ---\n",
    "    if self.verbose:\n",
    "        print(\"Preparing training data ...\")\n",
    "\n",
    "    df, trn_idxs, val_idxs, raw_df = self.get_training_data()\n",
    "\n",
    "    # --- step 2: get our HF OBJECTS ---\n",
    "    if self.verbose:\n",
    "        print(\"Building HF objects ...\")\n",
    "\n",
    "    hf_arch, hf_config, hf_tokenizer, hf_model = get_task_hf_objects(self.train_config)\n",
    "\n",
    "    # --- step 3: DATALOADERS ---\n",
    "    if self.verbose:\n",
    "        print(\"Building DataLoaders ...\")\n",
    "\n",
    "    dls = get_dls(self.train_config, df, hf_arch, hf_config, hf_tokenizer, hf_model, val_idxs_or_fold=val_idxs)\n",
    "\n",
    "    # --- step 4: LEARNER ---\n",
    "    if self.verbose:\n",
    "        print(\"Building Learner ...\")\n",
    "\n",
    "    learn = get_learner(self.train_config, dls, hf_config, hf_model, learner_path=self.model_output_path)\n",
    "\n",
    "    # add any learner callbacks req. by the `ModelTrainer`\n",
    "    if self.use_wandb:\n",
    "        learn.add_cb(WandbCallback(log_preds=False))\n",
    "\n",
    "    if trial is not None:\n",
    "        learn.add_cb(FastAIPruningCallback(trial, monitor=\"valid_loss\"))\n",
    "\n",
    "    # add any fit callbacks req. by the `ModelTrainer`\n",
    "    fit_cbs = []\n",
    "    if self.train_config.max_grad_norm:\n",
    "        fit_cbs.append(GradientClip(max_norm=self.train_config.max_grad_norm))\n",
    "\n",
    "    if self.train_config.include_gradient_checkpointing:\n",
    "        fit_cbs.append(GradientCheckpointing())\n",
    "\n",
    "    if self.train_config.save_best_model:\n",
    "        fit_cbs.append(\n",
    "            SaveModelCallback(\n",
    "                monitor=\"valid_loss\",\n",
    "                comp=np.less,\n",
    "                fname=f\"temp_best_f1_{self.experiment_name}\",\n",
    "                reset_on_fit=False,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # --- step 4: TRAIN ---\n",
    "    if self.verbose:\n",
    "        print(\"Training ...\")\n",
    "\n",
    "    if self.train_config.n_frozen_epochs > 0:\n",
    "        if self.train_config.random_seed and not self.train_config.only_seed_splits:\n",
    "            set_seed(self.train_config.random_seed)\n",
    "\n",
    "        learn.fit_one_cycle(self.train_config.n_frozen_epochs, lr_max=self.train_config.frozen_lr, cbs=fit_cbs)\n",
    "\n",
    "    if self.train_config.n_unfrozen_epochs > 0:\n",
    "        learn.unfreeze()\n",
    "\n",
    "        if self.train_config.random_seed and not self.train_config.only_seed_splits:\n",
    "            set_seed(self.train_config.random_seed)\n",
    "\n",
    "        learn.fit_one_cycle(\n",
    "            self.train_config.n_unfrozen_epochs,\n",
    "            lr_max=slice(self.train_config.unfrozen_lr_min, self.train_config.unfrozen_lr_max),\n",
    "            cbs=fit_cbs,\n",
    "        )\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    # --- step 5: LOG RESULTS ---\n",
    "    if self.verbose:\n",
    "        print(\"Logging results ...\")\n",
    "\n",
    "    # 5a: log high level results (metrics, loss, training configuration)\n",
    "    res = learn.validate()\n",
    "\n",
    "    train_config_df = pd.DataFrame(\n",
    "        [self.get_train_config_props()], columns=[k for k in self.get_train_config_props().keys()]\n",
    "    )\n",
    "    metrics_df = pd.DataFrame([res], columns=learn.recorder.metric_names[2:-1])\n",
    "\n",
    "    results_df = pd.concat([train_config_df, metrics_df], axis=1)\n",
    "    results_df[\"time\"] = end - start\n",
    "    results_df.to_csv(f\"{self.log_output_path}/{self.experiment_name}_{yyyymmddHm}_results.csv\", index=None)\n",
    "\n",
    "    # 5b: log actual predictions for the validation set\n",
    "    if self.log_preds:\n",
    "        val_course_titles = train_df.iloc[val_idxs][\"course_title\"].unique().tolist()\n",
    "        preds_df = get_validation_preds(\n",
    "            hf_model,\n",
    "            hf_tokenizer,\n",
    "            raw_df,\n",
    "            val_course_titles[: self.log_n_preds],\n",
    "            batch_size=learn.dls[1].bs,\n",
    "            threshold_std_coeff=1.0,\n",
    "            verbose=self.verbose,\n",
    "        )\n",
    "        preds_df.to_csv(f\"{self.log_output_path}/{self.experiment_name}_{yyyymmddHm}_preds.csv\", index=None)\n",
    "\n",
    "        if self.use_wandb:\n",
    "            wandb.run.summary[\"valid_loss\"] = results_df.iloc[0][\"valid_loss\"]\n",
    "            wandb.run.summary[\"topic_seg_f1_score\"] = results_df.iloc[0][\"topic_seg_f1_score\"]\n",
    "\n",
    "            table = wandb.Table(data=preds_df)\n",
    "            wandb.log({\"Prediction_Samples\": table})\n",
    "\n",
    "            wandb.run.summary[\"state\"] = \"completed\"\n",
    "\n",
    "    # --- step 5: SAVE MODEL (except when tuning) ---\n",
    "    if trial is None:\n",
    "        if self.verbose:\n",
    "            print(\"Saving model ...\")\n",
    "\n",
    "        learn.export(self.model_output_path / f\"{self.experiment_name}.pkl\")\n",
    "\n",
    "    # clean up\n",
    "    super(self.__class__, self).train()\n",
    "\n",
    "    del learn, dls, hf_model, hf_tokenizer, hf_config\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    if self.verbose:\n",
    "        print(\"End training\")\n",
    "\n",
    "    return results_df, raw_df, df, val_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = TopicSegmentationModelTrainer(\n",
    "    experiment_name=\"topic_segmentation\",\n",
    "    train_config=ExampleCFG,\n",
    "    data_path=\"../data\",\n",
    "    model_output_path=\"../models\",\n",
    "    log_output_path=\"../logs\",\n",
    "    log_preds=True,\n",
    "    log_n_preds=2,\n",
    "    use_wandb=True,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "results_df, raw_df, train_df, train_val_idxs = trainer.train()\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `predict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "@patch\n",
    "def predict(self: TopicSegmentationModelTrainer, data, **kwargs):\n",
    "\n",
    "    learner_fpath = kwargs.get(\"learner_fpath\", f\"{self.model_output_path}/{self.experiment_name}.pkl\")\n",
    "    threshold_std_coeff = kwargs.get(\"threshold_std_coeff\", 1.0)\n",
    "\n",
    "    preds_df, pred_seg_idxs = get_preds(data, learner_fpath=learner_fpath, threshold_std_coeff=threshold_std_coeff)\n",
    "    return preds_df, pred_seg_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = TopicSegmentationModelTrainer(\n",
    "    \"test_topic_seg_learner\", ExampleCFG, \"../data\", \"../models\", \"../logs\", verbose=True\n",
    ")\n",
    "# results_df, train_df, val_idxs = trainer.train()\n",
    "preds_df, pred_topic_idxs = trainer.predict(inf_df[[\"topic\", \"transcript\"]].copy())\n",
    "\n",
    "print(pred_topic_idxs[:10])\n",
    "preds_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `tune`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `tune_threshold`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('fsdl_2022_course_project')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
