{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |default_exp topic_segmentation\n",
    "# |default_cls_lvl 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# topic_segmentation\n",
    "\n",
    "Training, saving, and tuning code for building topic segmentation model(s) that can predict where new topics begin given a transcript (e.g. rows of duration and text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "from __future__ import annotations\n",
    "\n",
    "import ast, os, gc, random, time\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from fastai.callback.all import *\n",
    "from fastai.callback.wandb import *\n",
    "from fastai.data.block import CategoryBlock, ColReader, ColSplitter, DataBlock, IndexSplitter, RegressionBlock\n",
    "from fastai.imports import *\n",
    "from fastai.layers import SigmoidRange\n",
    "from fastai.learner import *\n",
    "from fastai.losses import CrossEntropyLossFlat, MSELossFlat, LabelSmoothingCrossEntropyFlat\n",
    "from fastai.optimizer import Adam\n",
    "from fastai.metrics import *\n",
    "from fastai.torch_core import *\n",
    "from fastai.torch_imports import *\n",
    "from fastcore.transform import Transform\n",
    "import optuna\n",
    "from optuna.integration.fastaiv2 import FastAIPruningCallback\n",
    "from optuna.integration.wandb import WeightsAndBiasesCallback\n",
    "import segeval\n",
    "from sklearn.metrics import mean_absolute_error, f1_score, recall_score, precision_score, fbeta_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statistics\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForNextSentencePrediction,\n",
    "    AutoModelForSequenceClassification,\n",
    "    DebertaV2Model,\n",
    "    logging as hf_logging,\n",
    ")\n",
    "from transformers.models.deberta_v2.modeling_deberta_v2 import ContextPooler\n",
    "from transformers.models.deberta_v2.modeling_deberta_v2 import StableDropout\n",
    "import wandb\n",
    "\n",
    "from blurr.callbacks import GradientCheckpointing\n",
    "from blurr.text.data.core import TextBlock, BatchTokenizeTransform, first_blurr_tfm\n",
    "from blurr.text.modeling.core import BaseModelWrapper, BaseModelCallback, blurr_splitter\n",
    "from blurr.text.utils import get_hf_objects\n",
    "from blurr.utils import PreCalculatedCrossEntropyLoss, PreCalculatedMSELoss, set_seed\n",
    "\n",
    "from course_copilot import preprocessing, training, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import pdb\n",
    "\n",
    "from fastcore.test import *\n",
    "import nbdev\n",
    "\n",
    "from blurr.utils import print_versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# |export\n",
    "# silence all the HF warnings and load environment variables\n",
    "warnings.simplefilter(\"ignore\")\n",
    "hf_logging.set_verbosity_error()\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What we're running with at the time this documentation was generated:\n",
      "torch: 1.12.1+cu102\n",
      "fastai: 2.7.9\n",
      "transformers: 4.22.0\n"
     ]
    }
   ],
   "source": [
    "# | echo: false\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "print(\"What we're running with at the time this documentation was generated:\")\n",
    "print_versions(\"torch fastai transformers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU #1: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "# |hide\n",
    "# |cuda\n",
    "torch.cuda.set_device(1)\n",
    "print(f\"Using GPU #{torch.cuda.current_device()}: {torch.cuda.get_device_name()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "course-copilot-ml\n",
      "course-copilot\n"
     ]
    }
   ],
   "source": [
    "print(os.environ[\"WANDB_PROJECT_NAME\"])\n",
    "print(os.environ[\"WANDB_TEAM\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class TopicSegmentationConfig(training.TrainConfig):\n",
    "    \"\"\"A 'training.Config' object training and tuning our segmentation models. Uses fastai and huggingface defaults by default\"\"\"\n",
    "\n",
    "    # huggingface objects\n",
    "    hf_model_cls = AutoModelForSequenceClassification\n",
    "    hf_model_checkpoint = \"microsoft/deberta-v3-small\"\n",
    "    hf_config_kwargs = {\"num_labels\": 2}\n",
    "    hf_tokenizer_kwargs = {}\n",
    "    new_special_tokens = None\n",
    "    hf_model_kwargs = {}\n",
    "\n",
    "    # datablock/dataloaders\n",
    "    use_next_pos_prob = 0.75\n",
    "    use_adjacent_neg_prob = 0.5\n",
    "    max_length = True\n",
    "    lower_case = True\n",
    "    truncation_strategy = True\n",
    "    include_labels = False\n",
    "    tok_kwargs = {}\n",
    "    batch_size = 8\n",
    "    accum = None\n",
    "\n",
    "    # learner\n",
    "    custom_model_kwargs = {\"p\": 0.1, \"dropout_cls\": nn.Dropout}\n",
    "    include_gradient_checkpointing = False\n",
    "    one_cycle_moms_start = 0.8\n",
    "    one_cycle_moms_min = 0.7\n",
    "    one_cycle_moms_end = 0.8\n",
    "    adam_beta2 = 0.99\n",
    "    adam_eps = 1e-7\n",
    "    weight_decay = 0.0\n",
    "    max_grad_norm = None\n",
    "    save_best_model = True\n",
    "    use_fp16 = True\n",
    "\n",
    "    # training\n",
    "    n_frozen_epochs = 0\n",
    "    frozen_lr = 0\n",
    "    n_unfrozen_epochs = 4\n",
    "    unfrozen_lr_min = 1e-5\n",
    "    unfrozen_lr_max = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleCFG(TopicSegmentationConfig):\n",
    "    training_subset = 0.25\n",
    "    n_frozen_epochs = 0\n",
    "    n_unfrozen_epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accum: None',\n",
       " 'adam_beta2: 0.99',\n",
       " 'adam_eps: 1e-07',\n",
       " 'batch_size: 8',\n",
       " \"custom_model_kwargs: {'p': 0.1, 'dropout_cls': <class 'torch.nn.modules.dropout.Dropout'>}\"]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f\"{k}: {v}\" for k, v in training.get_train_config_props(ExampleCFG).items()][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def _get_training_data(cfg: TopicSegmentationConfig, data_dir=\"data\", on_the_fly=False, split_type=\"cross_validation\"):\n",
    "    if on_the_fly:\n",
    "        raw_train_df, _ = preprocessing.preprocess_data(\n",
    "            ds=\"train\", data_path=data_dir, return_file=True, save_file=False\n",
    "        )\n",
    "    else:\n",
    "        raw_train_df = pd.read_csv(f\"{data_dir}/clean/segmentation_train.csv\", index_col=None)\n",
    "\n",
    "    raw_train_df[\"other_topic_seqs\"] = raw_train_df[\"other_topic_seqs\"].apply(ast.literal_eval)\n",
    "    raw_train_df.reset_index(inplace=True)\n",
    "\n",
    "    # for training we need to remove sequences for which there is not a \"next_seq\" (e.g., we are at end of a topic)\n",
    "    train_df = raw_train_df[raw_train_df[\"is_topic_end\"] == False].copy()\n",
    "\n",
    "    train_df = train_df.sample(frac=cfg.training_subset, random_state=cfg.random_seed).reset_index(drop=True)\n",
    "\n",
    "    if split_type == \"cross_validation\":\n",
    "        courses = train_df[\"course_title\"].unique()\n",
    "        np.random.seed(cfg.random_seed)\n",
    "        np.random.shuffle(courses)\n",
    "\n",
    "        val_sz = int(len(courses) * cfg.val_pct)\n",
    "        val_courses = courses[:val_sz]\n",
    "\n",
    "        is_val = np.isin(train_df[\"course_title\"], val_courses)\n",
    "\n",
    "        idxs = np.arange(len(train_df))\n",
    "        val_idxs = idxs[is_val]\n",
    "        trn_idxs = idxs[~is_val]\n",
    "\n",
    "        return train_df.copy(), trn_idxs, val_idxs, raw_train_df.copy()\n",
    "    else:\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, trn_idxs, val_idxs, raw_train_df = _get_training_data(\n",
    "    ExampleCFG, data_dir=\"../data\", on_the_fly=False, split_type=\"cross_validation\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6196\n",
      "4981 1215\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>course_title</th>\n",
       "      <th>lesson_num</th>\n",
       "      <th>topic</th>\n",
       "      <th>seq</th>\n",
       "      <th>prev_seq</th>\n",
       "      <th>next_seq</th>\n",
       "      <th>is_topic_end</th>\n",
       "      <th>next_topic_begin_seq</th>\n",
       "      <th>other_topic_seqs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23538</td>\n",
       "      <td>parker - learn photography</td>\n",
       "      <td>1</td>\n",
       "      <td>Apertures Deep Dive</td>\n",
       "      <td>particular the detroit tigers so their wedding day was in that area</td>\n",
       "      <td>and if you recognize this letter d you know that's from detroit and in</td>\n",
       "      <td>and we were near the detroit tiger stadium if i had completely blurred out</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[you fully understand how they work and how they can alter your final image now previously i demonstrated that the, larger the aperture the more the background is blurred out when it comes to the area in focus this is referred to, as the depth of field so the depth of field is the zone within a photo that, appears sharp and in focus when focusing on your subject that is considered the point of focus beyond that, how much appears in focus corresponds to the depth of field so here are two more, images and the amount of the depth of field in one is greater than the other, the first image i ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6466</td>\n",
       "      <td>Full Stack Deep Learning - Spring 2021</td>\n",
       "      <td>9</td>\n",
       "      <td>Long Term Ethical Problems in AI</td>\n",
       "      <td>we basically need robots in order to have a functioning economy in the next few decades</td>\n",
       "      <td>brilliant person and this article which i recommend you click on talks about how</td>\n",
       "      <td>an interesting spin on this worry though is ai not necessarily replacing human labor</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[a.i so the first i think a lot of people's minds go to autonomous weapons and maybe they go into a place that, is a little easy to dismiss as maybe far-fetched not realistic we don't have to worry about it it's just a movie, but of course as the saying goes the future is already here it's just not evenly distributed so, israel apparently has autonomous robo snipers on their borders today and just, i think last weekend or something there was an article about the new york city police deploying, the boston dynamics spot robot which actually anyone can buy now i think it's only like, 60 000 o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                            course_title lesson_num  \\\n",
       "0  23538              parker - learn photography          1   \n",
       "1   6466  Full Stack Deep Learning - Spring 2021          9   \n",
       "\n",
       "                              topic  \\\n",
       "0               Apertures Deep Dive   \n",
       "1  Long Term Ethical Problems in AI   \n",
       "\n",
       "                                                                                       seq  \\\n",
       "0                      particular the detroit tigers so their wedding day was in that area   \n",
       "1  we basically need robots in order to have a functioning economy in the next few decades   \n",
       "\n",
       "                                                                           prev_seq  \\\n",
       "0            and if you recognize this letter d you know that's from detroit and in   \n",
       "1  brilliant person and this article which i recommend you click on talks about how   \n",
       "\n",
       "                                                                               next_seq  \\\n",
       "0            and we were near the detroit tiger stadium if i had completely blurred out   \n",
       "1  an interesting spin on this worry though is ai not necessarily replacing human labor   \n",
       "\n",
       "   is_topic_end next_topic_begin_seq  \\\n",
       "0         False                  NaN   \n",
       "1         False                  NaN   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          other_topic_seqs  \n",
       "0  [you fully understand how they work and how they can alter your final image now previously i demonstrated that the, larger the aperture the more the background is blurred out when it comes to the area in focus this is referred to, as the depth of field so the depth of field is the zone within a photo that, appears sharp and in focus when focusing on your subject that is considered the point of focus beyond that, how much appears in focus corresponds to the depth of field so here are two more, images and the amount of the depth of field in one is greater than the other, the first image i ca...  \n",
       "1  [a.i so the first i think a lot of people's minds go to autonomous weapons and maybe they go into a place that, is a little easy to dismiss as maybe far-fetched not realistic we don't have to worry about it it's just a movie, but of course as the saying goes the future is already here it's just not evenly distributed so, israel apparently has autonomous robo snipers on their borders today and just, i think last weekend or something there was an article about the new york city police deploying, the boston dynamics spot robot which actually anyone can buy now i think it's only like, 60 000 o...  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(train_df))\n",
    "print(len(trn_idxs), len(val_idxs))\n",
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hugging Face `transformers` objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def _get_task_hf_objects(cfg: TopicSegmentationConfig):\n",
    "    # if 'only_seed_splits' = True, then we only care about reproducibility insofar as the training and\n",
    "    # validation sets go\n",
    "    if cfg.random_seed and not cfg.only_seed_splits:\n",
    "        set_seed(cfg.random_seed)\n",
    "\n",
    "    # need to create configuration object separately because we may be adding new attributes (e.g., cls_dropout)\n",
    "    hf_config = AutoConfig.from_pretrained(cfg.hf_model_checkpoint)\n",
    "    hf_config.update(cfg.hf_config_kwargs)\n",
    "\n",
    "    hf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(\n",
    "        cfg.hf_model_checkpoint,\n",
    "        model_cls=cfg.hf_model_cls,\n",
    "        config=hf_config,\n",
    "        tokenizer_kwargs=cfg.hf_tokenizer_kwargs,\n",
    "        model_kwargs=cfg.hf_model_kwargs,\n",
    "    )\n",
    "\n",
    "    if cfg.new_special_tokens:\n",
    "        # After adding the new tokens, we need to resize the embedding matrix in the model and initialize the weights\n",
    "        hf_tokenizer.add_special_tokens({\"additional_special_tokens\": cfg.new_special_tokens})\n",
    "        hf_model.resize_token_embeddings(len(hf_tokenizer))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            emb_size = hf_model.config.to_dict().get(\"embedding_size\", hf_model.config.hidden_size)\n",
    "            hf_model.get_input_embeddings().weight[-len(hf_tokenizer), :] = torch.zeros([emb_size])\n",
    "\n",
    "    return hf_arch, hf_config, hf_tokenizer, hf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_arch, hf_config, hf_tokenizer, hf_model = _get_task_hf_objects(ExampleCFG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `DataLoaders`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def _build_pos_inputs(example, cfg: TopicSegmentationConfig, hf_tokenizer_sep_token=\"[SEP]\"):\n",
    "    seq_text = example[\"seq\"].strip().lower() if cfg.lower_case else example[\"seq\"].strip()\n",
    "    next_seq_text = example[\"next_seq\"].strip().lower() if cfg.lower_case else example[\"next_seq\"].strip()\n",
    "\n",
    "    non_adjacent_text = (\n",
    "        random.choice(example[\"other_topic_seqs\"]).strip() if len(example[\"other_topic_seqs\"]) > 0 else None\n",
    "    )\n",
    "    if cfg.lower_case and non_adjacent_text:\n",
    "        non_adjacent_text = non_adjacent_text.lower()\n",
    "\n",
    "    if example[\"is_topic_end\"] and example[\"next_topic_begin_seq\"] and non_adjacent_text:\n",
    "        # this is the last sequence in the topic so the only thing that will work here is to pair it with another non-adjacent seq in the same topic\n",
    "        # and therefore we just duplicate it here.\n",
    "        next_topic_begin_seq = (\n",
    "            example[\"next_topic_begin_seq\"].strip().lower()\n",
    "            if cfg.lower_case\n",
    "            else example[\"next_topic_begin_seq\"].strip()\n",
    "        )\n",
    "        inp = (\n",
    "            f\"{seq_text}{hf_tokenizer_sep_token}{non_adjacent_text}\",\n",
    "            f\"{seq_text}{hf_tokenizer_sep_token}{non_adjacent_text}\",\n",
    "        )\n",
    "    else:\n",
    "        # the positive pair will be a seq + the next seq -or- the seq + a non-adjacent seq in the same topic\n",
    "        inp = (\n",
    "            f\"{seq_text}{hf_tokenizer_sep_token}{next_seq_text}\",\n",
    "            f\"{seq_text}{hf_tokenizer_sep_token}{non_adjacent_text}\" if non_adjacent_text else \"xxNONExx\",\n",
    "        )\n",
    "\n",
    "    return inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def _build_neg_inputs(example, cfg: TopicSegmentationConfig, hf_tokenizer_sep_token=\"[SEP]\", df=None):\n",
    "    seq_text = example[\"seq\"].strip()\n",
    "\n",
    "    # if at the last sequence for a topic, set the negative pair = seq + first sequence in next topic,\n",
    "    # else get a sequence that is not adjacent but in same topic\n",
    "    if example[\"is_topic_end\"] and example[\"next_topic_begin_seq\"]:\n",
    "        neg_seq_non_adjacent_text = example[\"next_topic_begin_seq\"].strip()\n",
    "    elif len(example[\"other_topic_seqs\"]) > 0:\n",
    "        neg_seq_non_adjacent_text = random.choice(example[\"other_topic_seqs\"]).strip()\n",
    "    else:\n",
    "        neg_seq_non_adjacent_text = \"xxNONExx\"\n",
    "\n",
    "    # get a sequence that is in an entirely different topic\n",
    "    # option 1: can be in same lesson but different topic or in a different course entirely\n",
    "    # neg_seq_other_topic_text = (\n",
    "    #     df[\"seq\"][\n",
    "    #         (df[\"course_title\"] != example[\"course_title\"]) | (df[\"lesson_num\"] != example[\"lesson_num\"])\n",
    "    #     ]\n",
    "    #     .sample(n=1)\n",
    "    #     .values[0]\n",
    "    #     .strip()\n",
    "    # )\n",
    "\n",
    "    # option 2: sample from a different course entirely\n",
    "    neg_seq_other_topic_text = df[\"seq\"][(df[\"course_title\"] != example[\"course_title\"])].sample(n=1).values[0].strip()\n",
    "\n",
    "    if cfg.lower_case:\n",
    "        seq_text = seq_text.lower()\n",
    "        neg_seq_non_adjacent_text = neg_seq_non_adjacent_text.lower()\n",
    "        neg_seq_other_topic_text = neg_seq_other_topic_text.lower()\n",
    "\n",
    "    # our SiameseBatchTokenizeTransform will choose which one to use each time the item is fetched\n",
    "    inp = (\n",
    "        f\"{seq_text}{hf_tokenizer_sep_token}{neg_seq_non_adjacent_text}\",\n",
    "        f\"{seq_text}{hf_tokenizer_sep_token}{neg_seq_other_topic_text}\",\n",
    "    )\n",
    "\n",
    "    return inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def _build_targets(example):\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class SiameseBatchTokenizeTransform(BatchTokenizeTransform):\n",
    "    def __init__(self, use_next_pos_prob=0.75, use_adjacent_neg_prob=0.5, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.use_next_pos_prob = use_next_pos_prob\n",
    "        self.use_adjacent_neg_prob = use_adjacent_neg_prob\n",
    "\n",
    "    def encodes(self, samples, return_batch_encoding=False):\n",
    "        # our positive example\n",
    "        pos_ex_idx = 0 if random.uniform(0, 1) < self.use_next_pos_prob else 1\n",
    "        updated_samples1, inputs1 = super().encodes(\n",
    "            [(s[0][pos_ex_idx] if s[0][pos_ex_idx] != \"xxNONExx\" else s[0][0], *s[2:], *s[2:]) for s in samples],\n",
    "            return_batch_encoding=True,\n",
    "        )\n",
    "\n",
    "        # our negative example (sometimes the adjacent will be \"\"; if that is the case use the other topic negative example which is at idx=1)\n",
    "        neg_ex_idx = 0 if random.uniform(0, 1) < self.use_adjacent_neg_prob and pos_ex_idx == 0 else 1\n",
    "        updated_samples2, inputs2 = super().encodes(\n",
    "            [(s[1][neg_ex_idx] if s[1][neg_ex_idx] != \"xxNONExx\" else s[1][1], *s[2:]) for s in samples],\n",
    "            return_batch_encoding=True,\n",
    "        )\n",
    "\n",
    "        # if there are no targets (e.g., when used for inference)\n",
    "        if len(samples[0]) == 2:\n",
    "            return [(inps1[0], inps2[0]) for inps1, inps2 in zip(updated_samples1, updated_samples2)]\n",
    "\n",
    "        return [(inps1[0], inps2[0], inps1[-1]) for inps1, inps2 in zip(updated_samples1, updated_samples2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def _get_dls(cfg: TopicSegmentationConfig, df, hf_arch, hf_config, hf_tokenizer, hf_model, val_idxs_or_fold):\n",
    "    # define validation set\n",
    "    if isinstance(val_idxs_or_fold, int):\n",
    "        df[\"is_valid\"] = df[\"k_fold\"] == val_idxs_or_fold\n",
    "        splitter = ColSplitter()\n",
    "    else:\n",
    "        splitter = IndexSplitter(val_idxs_or_fold)\n",
    "\n",
    "    if cfg.random_seed:\n",
    "        set_seed(cfg.random_seed)\n",
    "\n",
    "    batch_tokenize_tfm = SiameseBatchTokenizeTransform(\n",
    "        use_next_pos_prob=cfg.use_next_pos_prob,\n",
    "        use_adjacent_neg_prob=cfg.use_adjacent_neg_prob,\n",
    "        hf_arch=hf_arch,\n",
    "        hf_config=hf_config,\n",
    "        hf_tokenizer=hf_tokenizer,\n",
    "        hf_model=hf_model,\n",
    "        include_labels=cfg.include_labels,\n",
    "        max_length=cfg.max_length,\n",
    "        truncation=cfg.truncation_strategy,\n",
    "        tok_kwargs=cfg.tok_kwargs,\n",
    "    )\n",
    "\n",
    "    blocks = (TextBlock(batch_tokenize_tfm=batch_tokenize_tfm), noop, CategoryBlock)\n",
    "\n",
    "    get_pos_x = partial(_build_pos_inputs, cfg=cfg, hf_tokenizer_sep_token=hf_tokenizer.sep_token)\n",
    "    get_neg_x = partial(_build_neg_inputs, cfg=cfg, hf_tokenizer_sep_token=hf_tokenizer.sep_token, df=df)\n",
    "    get_y = partial(_build_targets)\n",
    "\n",
    "    dblock = DataBlock(\n",
    "        blocks=blocks,\n",
    "        get_x=[get_pos_x, get_neg_x],\n",
    "        get_y=get_y,\n",
    "        splitter=splitter,\n",
    "        n_inp=2,\n",
    "    )\n",
    "\n",
    "    if cfg.random_seed:\n",
    "        set_seed(cfg.random_seed)\n",
    "\n",
    "    bsz = cfg.batch_size if cfg.accum is None else cfg.batch_size // cfg.accum\n",
    "    return dblock.dataloaders(df, bs=bsz, val_bs=bsz * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = _get_dls(ExampleCFG, train_df, hf_arch, hf_config, hf_tokenizer, hf_model, val_idxs_or_fold=val_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "\n",
      "[CLS] of three of them so, you know, you kind of... this is the idea, right?, as if somebody says to you: “i like this movie, this movie, this movie” and you're like: “oh, they like those movies too” what[SEP] other movies do you like? and they'll say: “oh, how about this?” there's a chance, good chance, that you're going to like the same thing. that's the basis of collaborative filtering, okay, it's...[SEP]\n",
      "\n",
      "[CLS] of three of them so, you know, you kind of... this is the idea, right?, as if somebody says to you: “i like this movie, this movie, this movie” and you're like: “oh, they like those movies too” what[SEP] you're going to be really hungry and[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
      "\n",
      "TensorCategory([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "b = dls.one_batch()\n",
    "print(len(b))\n",
    "print(\"\")\n",
    "print(hf_tokenizer.decode(b[0][\"input_ids\"][0]))\n",
    "print(\"\")\n",
    "print(hf_tokenizer.decode(b[1][\"input_ids\"][0]))\n",
    "print(\"\")\n",
    "print(b[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def blurr_splitter_with_head(m: Module):\n",
    "    \"\"\"Simply adds an additional layer group to the classification head\"\"\"\n",
    "    base_param_groups = blurr_splitter(m)\n",
    "\n",
    "    added_groups = L([m for m_name, m in list(m.named_children()) if m_name != \"hf_model\"])\n",
    "    added_param_groups = added_groups.map(params).filter(lambda el: len(el) > 0)\n",
    "\n",
    "    return base_param_groups + added_param_groups\n",
    "\n",
    "\n",
    "def blurr_splitter_on_backbone(m: Module):\n",
    "    \"\"\"Creates two layer groups: One for the backbone and one for the pooler/classification head\"\"\"\n",
    "    root_modules = list(m.named_children())\n",
    "    top_module_name, top_module = root_modules[0]\n",
    "\n",
    "    groups = L(top_module)\n",
    "    groups += L([m for m_name, m in root_modules[1:]])\n",
    "\n",
    "    return groups.map(params).filter(lambda el: len(el) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "# TODO: Review PyTorch docs (https://pytorch.org/docs/stable/generated/torch.nn.MarginRankingLoss.html); consider changing\n",
    "def MarginRankingLoss(pos_neg_scores, targs):\n",
    "    margin = 1\n",
    "    p_scores, n_scores = pos_neg_scores\n",
    "\n",
    "    scores = margin - p_scores + n_scores\n",
    "    scores = scores.clamp(min=0)\n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def topic_seg_f1_score(inps, targs):\n",
    "    labels = []\n",
    "    all_pos_scores, all_neg_scores = inps[0], inps[1]\n",
    "\n",
    "    for i in range(len(all_pos_scores)):\n",
    "        if all_pos_scores[i] > all_neg_scores[i]:\n",
    "            labels.append(1)\n",
    "        else:\n",
    "            labels.append(0)\n",
    "\n",
    "    return sum(labels) / float(len(all_pos_scores))\n",
    "\n",
    "\n",
    "_topic_seg_f1_score = AvgMetric(topic_seg_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class TopicSegmentationModelWrapper(BaseModelWrapper):\n",
    "    def __init__(\n",
    "        self,\n",
    "        hf_config,\n",
    "        hf_model,\n",
    "        dropout_cls=nn.Dropout,\n",
    "        p=0.1,\n",
    "        hf_model_kwargs={},\n",
    "    ):\n",
    "        super().__init__(hf_model=hf_model, output_hidden_states=True, hf_model_kwargs=hf_model_kwargs)\n",
    "        store_attr()\n",
    "\n",
    "        self.coherence_prediction_dec = nn.Sequential(\n",
    "            *[\n",
    "                nn.Linear(hf_config.hidden_size, hf_config.hidden_size),\n",
    "                nn.ReLU(),\n",
    "                dropout_cls(p=p),\n",
    "                nn.Linear(hf_config.hidden_size, 2),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs1, inputs2):\n",
    "        # sequence 1 (pos examples)\n",
    "        inputs1_res = super().forward(inputs1)\n",
    "        pos_scores = inputs1_res.hidden_states[-1][:, 0, :]\n",
    "        pos_scores = self.coherence_prediction_dec(pos_scores)\n",
    "\n",
    "        # sequence 2 (neg examples)\n",
    "        inputs2_res = super().forward(inputs2)\n",
    "        neg_scores = inputs2_res.hidden_states[-1][:, 0, :]\n",
    "        neg_scores = self.coherence_prediction_dec(neg_scores)\n",
    "\n",
    "        return pos_scores[:, 0], neg_scores[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Learner`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def _get_learner(cfg: TopicSegmentationConfig, dls, hf_config, hf_model, learner_path=\".\"):\n",
    "\n",
    "    if cfg.random_seed and not cfg.only_seed_splits:\n",
    "        set_seed(cfg.random_seed)\n",
    "\n",
    "    learn_cbs = []\n",
    "    if cfg.accum is not None:\n",
    "        learn_cbs.append(GradientAccumulation(cfg.batch_size))\n",
    "\n",
    "    blurr_model_wrapper = TopicSegmentationModelWrapper(\n",
    "        hf_config=hf_config, hf_model=hf_model, **cfg.custom_model_kwargs\n",
    "    )\n",
    "\n",
    "    learn = Learner(\n",
    "        dls,\n",
    "        blurr_model_wrapper,\n",
    "        model_dir=learner_path,\n",
    "        opt_func=partial(Adam, sqr_mom=cfg.adam_beta2, eps=cfg.adam_eps, wd=cfg.weight_decay),\n",
    "        moms=(cfg.one_cycle_moms_start, cfg.one_cycle_moms_min, cfg.one_cycle_moms_end),\n",
    "        loss_func=PreCalculatedCrossEntropyLoss() if cfg.include_labels else MarginRankingLoss,\n",
    "        metrics=[topic_seg_f1_score],\n",
    "        cbs=learn_cbs,\n",
    "        splitter=blurr_splitter_on_backbone,\n",
    "    )\n",
    "\n",
    "    learn.create_opt()\n",
    "    learn.freeze()\n",
    "\n",
    "    if cfg.use_fp16:\n",
    "        learn = learn.to_fp16()\n",
    "\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = _get_learner(cfg=ExampleCFG, dls=dls, hf_config=hf_config, hf_model=hf_model, learner_path=\"../models\")\n",
    "\n",
    "fit_cbs = []\n",
    "if ExampleCFG.max_grad_norm:\n",
    "    fit_cbs.append(GradientClip(max_norm=ExampleCFG.max_grad_norm))\n",
    "\n",
    "if ExampleCFG.include_gradient_checkpointing:\n",
    "    fit_cbs.append(GradientCheckpointing())\n",
    "\n",
    "if ExampleCFG.save_best_model:\n",
    "    fit_cbs.append(\n",
    "        SaveModelCallback(\n",
    "            monitor=\"valid_loss\",\n",
    "            comp=np.less,\n",
    "            fname=f\"temp_best_loss_topic_segmentation\",\n",
    "            reset_on_fit=False,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(len(learn.opt.param_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.unfreeze()\n",
    "# learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(minimum=1.0964781722577755e-07, steep=0.005248074419796467, valley=0.00013182566908653826, slide=0.0014454397605732083)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.unfreeze()\n",
    "learn.lr_find(suggest_funcs=[minimum, steep, valley, slide])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>topic_seg_f1_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.456956</td>\n",
       "      <td>0.556683</td>\n",
       "      <td>0.781070</td>\n",
       "      <td>01:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.335876</td>\n",
       "      <td>0.568177</td>\n",
       "      <td>0.772840</td>\n",
       "      <td>01:25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with valid_loss value: 0.5566829442977905.\n"
     ]
    }
   ],
   "source": [
    "if ExampleCFG.random_seed:\n",
    "    set_seed(ExampleCFG.random_seed)\n",
    "\n",
    "learn.fit_one_cycle(2, slice(1e-5, 1e-3), cbs=fit_cbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accum: None',\n",
       " 'adam_beta2: 0.99',\n",
       " 'adam_eps: 1e-07',\n",
       " 'batch_size: 8',\n",
       " \"custom_model_kwargs: {'p': 0.1, 'dropout_cls': <class 'torch.nn.modules.dropout.Dropout'>}\"]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f\"{k}: {v}\" for k, v in training.get_train_config_props(ExampleCFG).items()][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 0.33587607741355896\n",
      "valid_loss 0.5681771039962769\n",
      "topic_seg_f1_score 0.7728395061728395\n"
     ]
    }
   ],
   "source": [
    "for m_name, m_val in zip(learn.recorder.metric_names[1:-1], learn.recorder.final_record):\n",
    "    print(m_name, m_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export(\"../models/test_topic_segmentation.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def depth_score_cal(scores):\n",
    "    output_scores = []\n",
    "    for i in range(len(scores)):\n",
    "        lflag = scores[i]\n",
    "        rflag = scores[i]\n",
    "        if i == 0:\n",
    "            hl = scores[i]\n",
    "            for r in range(i + 1, len(scores)):\n",
    "                if rflag <= scores[r]:\n",
    "                    rflag = scores[r]\n",
    "                else:\n",
    "                    break\n",
    "        elif i == len(scores):\n",
    "            hr = scores[i]\n",
    "            for l in range(i - 1, -1, -1):\n",
    "                if lflag <= scores[l]:\n",
    "                    lflag = scores[l]\n",
    "                else:\n",
    "                    break\n",
    "        else:\n",
    "            for r in range(i + 1, len(scores)):\n",
    "                if rflag <= scores[r]:\n",
    "                    rflag = scores[r]\n",
    "                else:\n",
    "                    break\n",
    "            for l in range(i - 1, -1, -1):\n",
    "                if lflag <= scores[l]:\n",
    "                    lflag = scores[l]\n",
    "                else:\n",
    "                    break\n",
    "        depth_score = 0.5 * (lflag + rflag - 2 * scores[i])\n",
    "        output_scores.append(depth_score)\n",
    "\n",
    "    return output_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def _get_validation_preds(\n",
    "    hf_model, hf_tokenizer, val_df, val_course_titles, batch_size=16, threshold_std_coeff=1.0, verbose=False\n",
    "):\n",
    "    hf_model.eval()\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Getting predictions for validatation set ...\")\n",
    "\n",
    "    val_results = []\n",
    "    for ct in val_course_titles:\n",
    "        for ln in val_df[val_df[\"course_title\"] == ct][\"lesson_num\"].unique().tolist():\n",
    "            inf_df = val_df[(val_df[\"course_title\"] == ct) & (val_df[\"lesson_num\"] == ln)].copy()\n",
    "            inf_df.reset_index(inplace=True)\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"processing {ct}: {ln}\")\n",
    "\n",
    "            # gather sequence pairs\n",
    "            seq_pairs = L()\n",
    "            for i in range(len(inf_df) - 1):\n",
    "                seq_a = inf_df.iloc[i][\"seq\"].strip().lower()\n",
    "                seq_b = inf_df.iloc[i + 1][\"seq\"].strip().lower()\n",
    "\n",
    "                seq_pairs.append((seq_a, seq_b))\n",
    "\n",
    "            # score sequence pairs\n",
    "            scores = []\n",
    "            for i in range(0, len(seq_pairs), batch_size):\n",
    "                # print(i)\n",
    "                batch = seq_pairs[i : i + batch_size]\n",
    "                inputs = hf_tokenizer(\n",
    "                    list(batch.itemgot(0)), list(batch.itemgot(1)), padding=True, max_length=True, return_tensors=\"pt\"\n",
    "                ).to(hf_model.device)\n",
    "\n",
    "                batch_scores = hf_model(**inputs)\n",
    "                scores += batch_scores[0][:, 0].detach().cpu()[:, None]\n",
    "\n",
    "            scores = torch.sigmoid(torch.concat(scores)).numpy().tolist()\n",
    "\n",
    "            # calculate depth_scores\n",
    "            depth_scores = depth_score_cal(scores)\n",
    "            threshold = sum(depth_scores) / (len(depth_scores)) + (statistics.stdev(depth_scores) * threshold_std_coeff)\n",
    "\n",
    "            # calculate reference (target) topics and count of sequences in each\n",
    "            # seg_r_labels = reference beginning of new topic\n",
    "            # seg_r = # of sequences in each reference topic\n",
    "            seg_r_labels = []\n",
    "            seg_r = []\n",
    "            tmp = 1\n",
    "\n",
    "            for r_idx, r in inf_df.iterrows():\n",
    "                current_topic = r[\"topic\"]\n",
    "                if r_idx == 0:\n",
    "                    last_seen_topic = r[\"topic\"]\n",
    "\n",
    "                if last_seen_topic != current_topic:\n",
    "                    last_seen_topic = current_topic\n",
    "                    seg_r_labels.append(1)\n",
    "                    seg_r.append(tmp)\n",
    "                    tmp = 1\n",
    "                else:\n",
    "                    seg_r_labels.append(0)\n",
    "                    tmp += 1 if r_idx != 0 else 0\n",
    "\n",
    "            seg_r.append(tmp)\n",
    "\n",
    "            # seg_p_labels = predicted beginning of new topic\n",
    "            # seg_p = # of sequences in each predicted topic\n",
    "\n",
    "            # we add 1 in here to compensate for lopping off the last sequence (which we do cuz it has no next_seq to pair with)\n",
    "            # default everything to 0\n",
    "            seg_p_labels = [0] * (len(depth_scores) + 1)\n",
    "\n",
    "            # loop thru `depth_scores`, if any > threshold mark them as a boundary (beginning of a new topic) and then update `seg_p_labels`\n",
    "            boundary_idxs = []\n",
    "            for i in range(len(depth_scores)):\n",
    "                if depth_scores[i] > threshold:\n",
    "                    boundary_idxs.append(i)\n",
    "\n",
    "            for i in boundary_idxs:\n",
    "                seg_p_labels[i] = 1\n",
    "\n",
    "            tmp = 0\n",
    "            seg_p = []\n",
    "            for idx, is_beg_topic in enumerate(seg_p_labels):\n",
    "                if is_beg_topic == 1 and idx != 0:\n",
    "                    # tmp += 1\n",
    "                    seg_p.append(tmp)\n",
    "                    tmp = 1\n",
    "                else:\n",
    "                    tmp += 1\n",
    "\n",
    "            seg_p.append(tmp)\n",
    "\n",
    "            seg_idxs = [seg_idx for seg_idx, v in enumerate(seg_p_labels) if v == 1 or seg_idx == 0]\n",
    "            inf_df[\"depth_score\"] = depth_scores + [None]\n",
    "            inf_df[\"threshold\"] = threshold\n",
    "            inf_df[\"pred_start\"] = False\n",
    "            inf_df.loc[seg_idxs, \"pred_start\"] = True\n",
    "\n",
    "            val_results.append(inf_df)\n",
    "\n",
    "    return pd.concat(val_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4628\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>course_title</th>\n",
       "      <th>lesson_num</th>\n",
       "      <th>topic</th>\n",
       "      <th>seq</th>\n",
       "      <th>prev_seq</th>\n",
       "      <th>next_seq</th>\n",
       "      <th>is_topic_end</th>\n",
       "      <th>next_topic_begin_seq</th>\n",
       "      <th>other_topic_seqs</th>\n",
       "      <th>depth_score</th>\n",
       "      <th>threshold</th>\n",
       "      <th>pred_start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19012</td>\n",
       "      <td>19012</td>\n",
       "      <td>markowskyart - begginer drawing course</td>\n",
       "      <td>1</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>okay here we are welcome everybody wherever you are here on planet Earth</td>\n",
       "      <td>xxBEGIN_TOPICxx</td>\n",
       "      <td>I'm welcoming you into my studio here in Vancouver British Columbia Canada my</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[name is Michael Markowski and I'm gonna be your drawing instructor for the next, hour or month depending on how many classes you decide to watch so it's, really exciting that there's I see 50 people who are watching right now which is really exciting to have a nice big, audience worth of people and I don't know how many comments have been pouring in here I was looking at a few of those, right started and people from a lot of people from British Columbia and it's great also to see a bunch of people who, have taken classes with me in the past so I guess that might mean I'm possibly, have do...</td>\n",
       "      <td>0.001695</td>\n",
       "      <td>0.00322</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19013</td>\n",
       "      <td>19013</td>\n",
       "      <td>markowskyart - begginer drawing course</td>\n",
       "      <td>1</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>I'm welcoming you into my studio here in Vancouver British Columbia Canada my</td>\n",
       "      <td>okay here we are welcome everybody wherever you are here on planet Earth</td>\n",
       "      <td>name is Michael Markowski and I'm gonna be your drawing instructor for the next</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[okay here we are welcome everybody wherever you are here on planet Earth, hour or month depending on how many classes you decide to watch so it's, really exciting that there's I see 50 people who are watching right now which is really exciting to have a nice big, audience worth of people and I don't know how many comments have been pouring in here I was looking at a few of those, right started and people from a lot of people from British Columbia and it's great also to see a bunch of people who, have taken classes with me in the past so I guess that might mean I'm possibly, have done some...</td>\n",
       "      <td>0.000806</td>\n",
       "      <td>0.00322</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19014</td>\n",
       "      <td>19014</td>\n",
       "      <td>markowskyart - begginer drawing course</td>\n",
       "      <td>1</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>name is Michael Markowski and I'm gonna be your drawing instructor for the next</td>\n",
       "      <td>I'm welcoming you into my studio here in Vancouver British Columbia Canada my</td>\n",
       "      <td>hour or month depending on how many classes you decide to watch so it's</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[okay here we are welcome everybody wherever you are here on planet Earth, I'm welcoming you into my studio here in Vancouver British Columbia Canada my, really exciting that there's I see 50 people who are watching right now which is really exciting to have a nice big, audience worth of people and I don't know how many comments have been pouring in here I was looking at a few of those, right started and people from a lot of people from British Columbia and it's great also to see a bunch of people who, have taken classes with me in the past so I guess that might mean I'm possibly, have don...</td>\n",
       "      <td>0.000616</td>\n",
       "      <td>0.00322</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19015</td>\n",
       "      <td>19015</td>\n",
       "      <td>markowskyart - begginer drawing course</td>\n",
       "      <td>1</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>hour or month depending on how many classes you decide to watch so it's</td>\n",
       "      <td>name is Michael Markowski and I'm gonna be your drawing instructor for the next</td>\n",
       "      <td>really exciting that there's I see 50 people who are watching right now which is really exciting to have a nice big</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[okay here we are welcome everybody wherever you are here on planet Earth, I'm welcoming you into my studio here in Vancouver British Columbia Canada my, name is Michael Markowski and I'm gonna be your drawing instructor for the next, audience worth of people and I don't know how many comments have been pouring in here I was looking at a few of those, right started and people from a lot of people from British Columbia and it's great also to see a bunch of people who, have taken classes with me in the past so I guess that might mean I'm possibly, have done something right in the past and pe...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00322</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19016</td>\n",
       "      <td>19016</td>\n",
       "      <td>markowskyart - begginer drawing course</td>\n",
       "      <td>1</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>really exciting that there's I see 50 people who are watching right now which is really exciting to have a nice big</td>\n",
       "      <td>hour or month depending on how many classes you decide to watch so it's</td>\n",
       "      <td>audience worth of people and I don't know how many comments have been pouring in here I was looking at a few of those</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[okay here we are welcome everybody wherever you are here on planet Earth, I'm welcoming you into my studio here in Vancouver British Columbia Canada my, name is Michael Markowski and I'm gonna be your drawing instructor for the next, hour or month depending on how many classes you decide to watch so it's, right started and people from a lot of people from British Columbia and it's great also to see a bunch of people who, have taken classes with me in the past so I guess that might mean I'm possibly, have done something right in the past and people who've taken my photography, classes and ...</td>\n",
       "      <td>0.004914</td>\n",
       "      <td>0.00322</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   level_0  index                            course_title lesson_num  \\\n",
       "0    19012  19012  markowskyart - begginer drawing course          1   \n",
       "1    19013  19013  markowskyart - begginer drawing course          1   \n",
       "2    19014  19014  markowskyart - begginer drawing course          1   \n",
       "3    19015  19015  markowskyart - begginer drawing course          1   \n",
       "4    19016  19016  markowskyart - begginer drawing course          1   \n",
       "\n",
       "          topic  \\\n",
       "0  Introduction   \n",
       "1  Introduction   \n",
       "2  Introduction   \n",
       "3  Introduction   \n",
       "4  Introduction   \n",
       "\n",
       "                                                                                                                   seq  \\\n",
       "0                                             okay here we are welcome everybody wherever you are here on planet Earth   \n",
       "1                                        I'm welcoming you into my studio here in Vancouver British Columbia Canada my   \n",
       "2                                      name is Michael Markowski and I'm gonna be your drawing instructor for the next   \n",
       "3                                              hour or month depending on how many classes you decide to watch so it's   \n",
       "4  really exciting that there's I see 50 people who are watching right now which is really exciting to have a nice big   \n",
       "\n",
       "                                                                          prev_seq  \\\n",
       "0                                                                  xxBEGIN_TOPICxx   \n",
       "1         okay here we are welcome everybody wherever you are here on planet Earth   \n",
       "2    I'm welcoming you into my studio here in Vancouver British Columbia Canada my   \n",
       "3  name is Michael Markowski and I'm gonna be your drawing instructor for the next   \n",
       "4          hour or month depending on how many classes you decide to watch so it's   \n",
       "\n",
       "                                                                                                                next_seq  \\\n",
       "0                                          I'm welcoming you into my studio here in Vancouver British Columbia Canada my   \n",
       "1                                        name is Michael Markowski and I'm gonna be your drawing instructor for the next   \n",
       "2                                                hour or month depending on how many classes you decide to watch so it's   \n",
       "3    really exciting that there's I see 50 people who are watching right now which is really exciting to have a nice big   \n",
       "4  audience worth of people and I don't know how many comments have been pouring in here I was looking at a few of those   \n",
       "\n",
       "   is_topic_end next_topic_begin_seq  \\\n",
       "0         False                  NaN   \n",
       "1         False                  NaN   \n",
       "2         False                  NaN   \n",
       "3         False                  NaN   \n",
       "4         False                  NaN   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          other_topic_seqs  \\\n",
       "0  [name is Michael Markowski and I'm gonna be your drawing instructor for the next, hour or month depending on how many classes you decide to watch so it's, really exciting that there's I see 50 people who are watching right now which is really exciting to have a nice big, audience worth of people and I don't know how many comments have been pouring in here I was looking at a few of those, right started and people from a lot of people from British Columbia and it's great also to see a bunch of people who, have taken classes with me in the past so I guess that might mean I'm possibly, have do...   \n",
       "1  [okay here we are welcome everybody wherever you are here on planet Earth, hour or month depending on how many classes you decide to watch so it's, really exciting that there's I see 50 people who are watching right now which is really exciting to have a nice big, audience worth of people and I don't know how many comments have been pouring in here I was looking at a few of those, right started and people from a lot of people from British Columbia and it's great also to see a bunch of people who, have taken classes with me in the past so I guess that might mean I'm possibly, have done some...   \n",
       "2  [okay here we are welcome everybody wherever you are here on planet Earth, I'm welcoming you into my studio here in Vancouver British Columbia Canada my, really exciting that there's I see 50 people who are watching right now which is really exciting to have a nice big, audience worth of people and I don't know how many comments have been pouring in here I was looking at a few of those, right started and people from a lot of people from British Columbia and it's great also to see a bunch of people who, have taken classes with me in the past so I guess that might mean I'm possibly, have don...   \n",
       "3  [okay here we are welcome everybody wherever you are here on planet Earth, I'm welcoming you into my studio here in Vancouver British Columbia Canada my, name is Michael Markowski and I'm gonna be your drawing instructor for the next, audience worth of people and I don't know how many comments have been pouring in here I was looking at a few of those, right started and people from a lot of people from British Columbia and it's great also to see a bunch of people who, have taken classes with me in the past so I guess that might mean I'm possibly, have done something right in the past and pe...   \n",
       "4  [okay here we are welcome everybody wherever you are here on planet Earth, I'm welcoming you into my studio here in Vancouver British Columbia Canada my, name is Michael Markowski and I'm gonna be your drawing instructor for the next, hour or month depending on how many classes you decide to watch so it's, right started and people from a lot of people from British Columbia and it's great also to see a bunch of people who, have taken classes with me in the past so I guess that might mean I'm possibly, have done something right in the past and people who've taken my photography, classes and ...   \n",
       "\n",
       "   depth_score  threshold  pred_start  \n",
       "0     0.001695    0.00322        True  \n",
       "1     0.000806    0.00322       False  \n",
       "2     0.000616    0.00322       False  \n",
       "3     0.000000    0.00322       False  \n",
       "4     0.004914    0.00322        True  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_course_titles = train_df.iloc[val_idxs][\"course_title\"].unique().tolist()\n",
    "preds_df = _get_validation_preds(\n",
    "    hf_model,\n",
    "    hf_tokenizer,\n",
    "    raw_train_df,\n",
    "    val_course_titles[:2],\n",
    "    batch_size=16,\n",
    "    threshold_std_coeff=1.0,\n",
    ")\n",
    "\n",
    "print(len(preds_df))\n",
    "preds_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def _get_preds(inf_learner, data, threshold_std_coeff=1.5):\n",
    "    batch_tok_transform = first_blurr_tfm(inf_learner.dls)\n",
    "    batch_size = inf_learner.dls.bs\n",
    "\n",
    "    inf_hf_model = inf_learner.model.hf_model.eval()\n",
    "    inf_hf_tokenizer = batch_tok_transform.hf_tokenizer\n",
    "\n",
    "    # build seq + next_seq pairs\n",
    "    seq_pairs = L()\n",
    "    for i in range(len(data) - 1):\n",
    "        seq_a = data.iloc[i][\"transcript\"].strip().lower()\n",
    "        seq_b = data.iloc[i + 1][\"transcript\"].strip().lower()\n",
    "\n",
    "        seq_pairs.append((seq_a, seq_b))\n",
    "\n",
    "    # get predictions from just the HF model for the `seq_pairs` above\n",
    "    scores = []\n",
    "    for i in range(0, len(seq_pairs), batch_size):\n",
    "        # print(i)\n",
    "        batch = seq_pairs[i : i + batch_size]\n",
    "        inputs = inf_hf_tokenizer(\n",
    "            list(batch.itemgot(0)), list(batch.itemgot(1)), padding=True, max_length=True, return_tensors=\"pt\"\n",
    "        ).to(inf_hf_model.device)\n",
    "\n",
    "        batch_scores = inf_learner.model.hf_model(**inputs)\n",
    "        scores += batch_scores[0][:, 0].detach().cpu()[:, None]\n",
    "\n",
    "    # take the sigmoid so range is between 0 and 1 for each value\n",
    "    scores = torch.sigmoid(torch.concat(scores)).numpy().tolist()\n",
    "\n",
    "    depth_scores = depth_score_cal(scores)\n",
    "\n",
    "    # `threshold_std_coeff` defines a `threshold` based on `depth_score` where any sequence pair with a score > threshold will be\n",
    "    # predicted as a start of a new topic (The paper/code does this differently but the results are abysmal. The std coefficient\n",
    "    # should be tuned to optimize for F1, F2, or whatever\n",
    "    threshold = sum(depth_scores) / (len(depth_scores)) + (statistics.stdev(depth_scores) * threshold_std_coeff)\n",
    "\n",
    "    # get predicted topic starts\n",
    "    # seg_p_labels = predicted beginning of new topic | seg_p = # of sequences in each predicted topic\n",
    "\n",
    "    # we add 1 in here to compensate for lopping off the last sequence (which we do cuz it has no next_seq to pair with)\n",
    "    # default everything to 0\n",
    "    seg_p_labels = [0] * (len(depth_scores) + 1)\n",
    "\n",
    "    # loop thru `depth_scores`, if any > threshold mark them as a boundary (beginning of a new topic) and then update `seg_p_labels`\n",
    "    boundary_idxs = []\n",
    "    for i in range(len(depth_scores)):\n",
    "        if depth_scores[i] > threshold:\n",
    "            boundary_idxs.append(i)\n",
    "\n",
    "    for i in boundary_idxs:\n",
    "        seg_p_labels[i] = 1\n",
    "\n",
    "    tmp = 0\n",
    "    seg_p = []\n",
    "    for idx, is_beg_topic in enumerate(seg_p_labels):\n",
    "        if is_beg_topic == 1 and idx != 0:\n",
    "            # tmp += 1\n",
    "            seg_p.append(tmp)\n",
    "            tmp = 1\n",
    "        else:\n",
    "            tmp += 1\n",
    "\n",
    "    seg_p.append(tmp)\n",
    "\n",
    "    # update inference dataset with depth_score for each row as well as the threshold used and whether it is start of a topic\n",
    "    seg_idxs = [seg_idx for seg_idx, v in enumerate(seg_p_labels) if v == 1 or seg_idx == 0]\n",
    "    data[\"depth_score\"] = depth_scores + [None]\n",
    "    data[\"threshold\"] = threshold\n",
    "    data[\"pred_start\"] = False\n",
    "    data.loc[seg_idxs, \"pred_start\"] = True\n",
    "\n",
    "    # return the updated inference dataset and the topic start indices\n",
    "    return data, seg_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "709\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>course_title</th>\n",
       "      <th>lesson_num</th>\n",
       "      <th>topic</th>\n",
       "      <th>seq</th>\n",
       "      <th>prev_seq</th>\n",
       "      <th>next_seq</th>\n",
       "      <th>is_topic_end</th>\n",
       "      <th>next_topic_begin_seq</th>\n",
       "      <th>other_topic_seqs</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15307</td>\n",
       "      <td>fast.ai 2022 - Part 1</td>\n",
       "      <td>4</td>\n",
       "      <td>Using Huggingface</td>\n",
       "      <td>Hi everybody, and welcome to Practical Deep Learning for Coders Lesson Four, which I think</td>\n",
       "      <td>xxBEGIN_TOPICxx</td>\n",
       "      <td>is the lesson that a lot of the regulars in the community have been most excited about,</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"because it's where we're gonna get some totally new material — totally new topic, we've\", \"never covered before. We're going to cover natural language processing (NLP), and you'll\", \"find there, there is indeed a chapter about that in the book, but we're going to do it in a totally different way to how it's done in the book. In the book we do NLP using the\", 'fast.ai library, using recurrent neural networks (RNNs).', \"Today we're going to do something else, which is we're going to do Transformers, and we're\", \"not even going to use the fast.ai library at all in fact. So, what we're going...</td>\n",
       "      <td>Hi everybody, and welcome to Practical Deep Learning for Coders Lesson Four, which I think</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15308</td>\n",
       "      <td>fast.ai 2022 - Part 1</td>\n",
       "      <td>4</td>\n",
       "      <td>Using Huggingface</td>\n",
       "      <td>is the lesson that a lot of the regulars in the community have been most excited about,</td>\n",
       "      <td>Hi everybody, and welcome to Practical Deep Learning for Coders Lesson Four, which I think</td>\n",
       "      <td>because it's where we're gonna get some totally new material — totally new topic, we've</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Hi everybody, and welcome to Practical Deep Learning for Coders Lesson Four, which I think', \"never covered before. We're going to cover natural language processing (NLP), and you'll\", \"find there, there is indeed a chapter about that in the book, but we're going to do it in a totally different way to how it's done in the book. In the book we do NLP using the\", 'fast.ai library, using recurrent neural networks (RNNs).', \"Today we're going to do something else, which is we're going to do Transformers, and we're\", \"not even going to use the fast.ai library at all in fact. So, what we're go...</td>\n",
       "      <td>is the lesson that a lot of the regulars in the community have been most excited about,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index           course_title lesson_num              topic  \\\n",
       "0  15307  fast.ai 2022 - Part 1          4  Using Huggingface   \n",
       "1  15308  fast.ai 2022 - Part 1          4  Using Huggingface   \n",
       "\n",
       "                                                                                          seq  \\\n",
       "0  Hi everybody, and welcome to Practical Deep Learning for Coders Lesson Four, which I think   \n",
       "1     is the lesson that a lot of the regulars in the community have been most excited about,   \n",
       "\n",
       "                                                                                     prev_seq  \\\n",
       "0                                                                             xxBEGIN_TOPICxx   \n",
       "1  Hi everybody, and welcome to Practical Deep Learning for Coders Lesson Four, which I think   \n",
       "\n",
       "                                                                                  next_seq  \\\n",
       "0  is the lesson that a lot of the regulars in the community have been most excited about,   \n",
       "1  because it's where we're gonna get some totally new material — totally new topic, we've   \n",
       "\n",
       "   is_topic_end next_topic_begin_seq  \\\n",
       "0         False                  NaN   \n",
       "1         False                  NaN   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          other_topic_seqs  \\\n",
       "0  [\"because it's where we're gonna get some totally new material — totally new topic, we've\", \"never covered before. We're going to cover natural language processing (NLP), and you'll\", \"find there, there is indeed a chapter about that in the book, but we're going to do it in a totally different way to how it's done in the book. In the book we do NLP using the\", 'fast.ai library, using recurrent neural networks (RNNs).', \"Today we're going to do something else, which is we're going to do Transformers, and we're\", \"not even going to use the fast.ai library at all in fact. So, what we're going...   \n",
       "1  ['Hi everybody, and welcome to Practical Deep Learning for Coders Lesson Four, which I think', \"never covered before. We're going to cover natural language processing (NLP), and you'll\", \"find there, there is indeed a chapter about that in the book, but we're going to do it in a totally different way to how it's done in the book. In the book we do NLP using the\", 'fast.ai library, using recurrent neural networks (RNNs).', \"Today we're going to do something else, which is we're going to do Transformers, and we're\", \"not even going to use the fast.ai library at all in fact. So, what we're go...   \n",
       "\n",
       "                                                                                   transcript  \n",
       "0  Hi everybody, and welcome to Practical Deep Learning for Coders Lesson Four, which I think  \n",
       "1     is the lesson that a lot of the regulars in the community have been most excited about,  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_df = pd.read_csv(f\"../data/clean/segmentation_train.csv\", index_col=None)\n",
    "\n",
    "val_course_title = \"fast.ai 2022 - Part 1\"\n",
    "val_lesson_num = \"4\"\n",
    "\n",
    "inf_df = raw_train_df[\n",
    "    (raw_train_df[\"course_title\"] == val_course_title) & (raw_train_df[\"lesson_num\"] == val_lesson_num)\n",
    "].copy()\n",
    "inf_df[\"transcript\"] = inf_df[\"seq\"]\n",
    "inf_df.reset_index(inplace=True)\n",
    "\n",
    "print(len(inf_df))\n",
    "inf_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 16, 20, 23, 26, 30, 44, 47, 54]\n",
      "709\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>course_title</th>\n",
       "      <th>lesson_num</th>\n",
       "      <th>topic</th>\n",
       "      <th>seq</th>\n",
       "      <th>prev_seq</th>\n",
       "      <th>next_seq</th>\n",
       "      <th>is_topic_end</th>\n",
       "      <th>next_topic_begin_seq</th>\n",
       "      <th>other_topic_seqs</th>\n",
       "      <th>transcript</th>\n",
       "      <th>depth_score</th>\n",
       "      <th>threshold</th>\n",
       "      <th>pred_start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15307</td>\n",
       "      <td>fast.ai 2022 - Part 1</td>\n",
       "      <td>4</td>\n",
       "      <td>Using Huggingface</td>\n",
       "      <td>Hi everybody, and welcome to Practical Deep Learning for Coders Lesson Four, which I think</td>\n",
       "      <td>xxBEGIN_TOPICxx</td>\n",
       "      <td>is the lesson that a lot of the regulars in the community have been most excited about,</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"because it's where we're gonna get some totally new material — totally new topic, we've\", \"never covered before. We're going to cover natural language processing (NLP), and you'll\", \"find there, there is indeed a chapter about that in the book, but we're going to do it in a totally different way to how it's done in the book. In the book we do NLP using the\", 'fast.ai library, using recurrent neural networks (RNNs).', \"Today we're going to do something else, which is we're going to do Transformers, and we're\", \"not even going to use the fast.ai library at all in fact. So, what we're going...</td>\n",
       "      <td>Hi everybody, and welcome to Practical Deep Learning for Coders Lesson Four, which I think</td>\n",
       "      <td>0.001369</td>\n",
       "      <td>0.002255</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15308</td>\n",
       "      <td>fast.ai 2022 - Part 1</td>\n",
       "      <td>4</td>\n",
       "      <td>Using Huggingface</td>\n",
       "      <td>is the lesson that a lot of the regulars in the community have been most excited about,</td>\n",
       "      <td>Hi everybody, and welcome to Practical Deep Learning for Coders Lesson Four, which I think</td>\n",
       "      <td>because it's where we're gonna get some totally new material — totally new topic, we've</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Hi everybody, and welcome to Practical Deep Learning for Coders Lesson Four, which I think', \"never covered before. We're going to cover natural language processing (NLP), and you'll\", \"find there, there is indeed a chapter about that in the book, but we're going to do it in a totally different way to how it's done in the book. In the book we do NLP using the\", 'fast.ai library, using recurrent neural networks (RNNs).', \"Today we're going to do something else, which is we're going to do Transformers, and we're\", \"not even going to use the fast.ai library at all in fact. So, what we're go...</td>\n",
       "      <td>is the lesson that a lot of the regulars in the community have been most excited about,</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002255</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15309</td>\n",
       "      <td>fast.ai 2022 - Part 1</td>\n",
       "      <td>4</td>\n",
       "      <td>Using Huggingface</td>\n",
       "      <td>because it's where we're gonna get some totally new material — totally new topic, we've</td>\n",
       "      <td>is the lesson that a lot of the regulars in the community have been most excited about,</td>\n",
       "      <td>never covered before. We're going to cover natural language processing (NLP), and you'll</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Hi everybody, and welcome to Practical Deep Learning for Coders Lesson Four, which I think', 'is the lesson that a lot of the regulars in the community have been most excited about,', \"find there, there is indeed a chapter about that in the book, but we're going to do it in a totally different way to how it's done in the book. In the book we do NLP using the\", 'fast.ai library, using recurrent neural networks (RNNs).', \"Today we're going to do something else, which is we're going to do Transformers, and we're\", \"not even going to use the fast.ai library at all in fact. So, what we're goi...</td>\n",
       "      <td>because it's where we're gonna get some totally new material — totally new topic, we've</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.002255</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15310</td>\n",
       "      <td>fast.ai 2022 - Part 1</td>\n",
       "      <td>4</td>\n",
       "      <td>Using Huggingface</td>\n",
       "      <td>never covered before. We're going to cover natural language processing (NLP), and you'll</td>\n",
       "      <td>because it's where we're gonna get some totally new material — totally new topic, we've</td>\n",
       "      <td>find there, there is indeed a chapter about that in the book, but we're going to do it in a totally different way to how it's done in the book. In the book we do NLP using the</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Hi everybody, and welcome to Practical Deep Learning for Coders Lesson Four, which I think', 'is the lesson that a lot of the regulars in the community have been most excited about,', \"because it's where we're gonna get some totally new material — totally new topic, we've\", 'fast.ai library, using recurrent neural networks (RNNs).', \"Today we're going to do something else, which is we're going to do Transformers, and we're\", \"not even going to use the fast.ai library at all in fact. So, what we're going to be\", \"doing today is we're going to be fine-tuning a pre-trained NLP model using a...</td>\n",
       "      <td>never covered before. We're going to cover natural language processing (NLP), and you'll</td>\n",
       "      <td>0.001102</td>\n",
       "      <td>0.002255</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15311</td>\n",
       "      <td>fast.ai 2022 - Part 1</td>\n",
       "      <td>4</td>\n",
       "      <td>Using Huggingface</td>\n",
       "      <td>find there, there is indeed a chapter about that in the book, but we're going to do it in a totally different way to how it's done in the book. In the book we do NLP using the</td>\n",
       "      <td>never covered before. We're going to cover natural language processing (NLP), and you'll</td>\n",
       "      <td>fast.ai library, using recurrent neural networks (RNNs).</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Hi everybody, and welcome to Practical Deep Learning for Coders Lesson Four, which I think', 'is the lesson that a lot of the regulars in the community have been most excited about,', \"because it's where we're gonna get some totally new material — totally new topic, we've\", \"never covered before. We're going to cover natural language processing (NLP), and you'll\", \"Today we're going to do something else, which is we're going to do Transformers, and we're\", \"not even going to use the fast.ai library at all in fact. So, what we're going to be\", \"doing today is we're going to be fine-tuning...</td>\n",
       "      <td>find there, there is indeed a chapter about that in the book, but we're going to do it in a totally different way to how it's done in the book. In the book we do NLP using the</td>\n",
       "      <td>0.002383</td>\n",
       "      <td>0.002255</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index           course_title lesson_num              topic  \\\n",
       "0  15307  fast.ai 2022 - Part 1          4  Using Huggingface   \n",
       "1  15308  fast.ai 2022 - Part 1          4  Using Huggingface   \n",
       "2  15309  fast.ai 2022 - Part 1          4  Using Huggingface   \n",
       "3  15310  fast.ai 2022 - Part 1          4  Using Huggingface   \n",
       "4  15311  fast.ai 2022 - Part 1          4  Using Huggingface   \n",
       "\n",
       "                                                                                                                                                                               seq  \\\n",
       "0                                                                                       Hi everybody, and welcome to Practical Deep Learning for Coders Lesson Four, which I think   \n",
       "1                                                                                          is the lesson that a lot of the regulars in the community have been most excited about,   \n",
       "2                                                                                          because it's where we're gonna get some totally new material — totally new topic, we've   \n",
       "3                                                                                         never covered before. We're going to cover natural language processing (NLP), and you'll   \n",
       "4  find there, there is indeed a chapter about that in the book, but we're going to do it in a totally different way to how it's done in the book. In the book we do NLP using the   \n",
       "\n",
       "                                                                                     prev_seq  \\\n",
       "0                                                                             xxBEGIN_TOPICxx   \n",
       "1  Hi everybody, and welcome to Practical Deep Learning for Coders Lesson Four, which I think   \n",
       "2     is the lesson that a lot of the regulars in the community have been most excited about,   \n",
       "3     because it's where we're gonna get some totally new material — totally new topic, we've   \n",
       "4    never covered before. We're going to cover natural language processing (NLP), and you'll   \n",
       "\n",
       "                                                                                                                                                                          next_seq  \\\n",
       "0                                                                                          is the lesson that a lot of the regulars in the community have been most excited about,   \n",
       "1                                                                                          because it's where we're gonna get some totally new material — totally new topic, we've   \n",
       "2                                                                                         never covered before. We're going to cover natural language processing (NLP), and you'll   \n",
       "3  find there, there is indeed a chapter about that in the book, but we're going to do it in a totally different way to how it's done in the book. In the book we do NLP using the   \n",
       "4                                                                                                                         fast.ai library, using recurrent neural networks (RNNs).   \n",
       "\n",
       "   is_topic_end next_topic_begin_seq  \\\n",
       "0         False                  NaN   \n",
       "1         False                  NaN   \n",
       "2         False                  NaN   \n",
       "3         False                  NaN   \n",
       "4         False                  NaN   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          other_topic_seqs  \\\n",
       "0  [\"because it's where we're gonna get some totally new material — totally new topic, we've\", \"never covered before. We're going to cover natural language processing (NLP), and you'll\", \"find there, there is indeed a chapter about that in the book, but we're going to do it in a totally different way to how it's done in the book. In the book we do NLP using the\", 'fast.ai library, using recurrent neural networks (RNNs).', \"Today we're going to do something else, which is we're going to do Transformers, and we're\", \"not even going to use the fast.ai library at all in fact. So, what we're going...   \n",
       "1  ['Hi everybody, and welcome to Practical Deep Learning for Coders Lesson Four, which I think', \"never covered before. We're going to cover natural language processing (NLP), and you'll\", \"find there, there is indeed a chapter about that in the book, but we're going to do it in a totally different way to how it's done in the book. In the book we do NLP using the\", 'fast.ai library, using recurrent neural networks (RNNs).', \"Today we're going to do something else, which is we're going to do Transformers, and we're\", \"not even going to use the fast.ai library at all in fact. So, what we're go...   \n",
       "2  ['Hi everybody, and welcome to Practical Deep Learning for Coders Lesson Four, which I think', 'is the lesson that a lot of the regulars in the community have been most excited about,', \"find there, there is indeed a chapter about that in the book, but we're going to do it in a totally different way to how it's done in the book. In the book we do NLP using the\", 'fast.ai library, using recurrent neural networks (RNNs).', \"Today we're going to do something else, which is we're going to do Transformers, and we're\", \"not even going to use the fast.ai library at all in fact. So, what we're goi...   \n",
       "3  ['Hi everybody, and welcome to Practical Deep Learning for Coders Lesson Four, which I think', 'is the lesson that a lot of the regulars in the community have been most excited about,', \"because it's where we're gonna get some totally new material — totally new topic, we've\", 'fast.ai library, using recurrent neural networks (RNNs).', \"Today we're going to do something else, which is we're going to do Transformers, and we're\", \"not even going to use the fast.ai library at all in fact. So, what we're going to be\", \"doing today is we're going to be fine-tuning a pre-trained NLP model using a...   \n",
       "4  ['Hi everybody, and welcome to Practical Deep Learning for Coders Lesson Four, which I think', 'is the lesson that a lot of the regulars in the community have been most excited about,', \"because it's where we're gonna get some totally new material — totally new topic, we've\", \"never covered before. We're going to cover natural language processing (NLP), and you'll\", \"Today we're going to do something else, which is we're going to do Transformers, and we're\", \"not even going to use the fast.ai library at all in fact. So, what we're going to be\", \"doing today is we're going to be fine-tuning...   \n",
       "\n",
       "                                                                                                                                                                        transcript  \\\n",
       "0                                                                                       Hi everybody, and welcome to Practical Deep Learning for Coders Lesson Four, which I think   \n",
       "1                                                                                          is the lesson that a lot of the regulars in the community have been most excited about,   \n",
       "2                                                                                          because it's where we're gonna get some totally new material — totally new topic, we've   \n",
       "3                                                                                         never covered before. We're going to cover natural language processing (NLP), and you'll   \n",
       "4  find there, there is indeed a chapter about that in the book, but we're going to do it in a totally different way to how it's done in the book. In the book we do NLP using the   \n",
       "\n",
       "   depth_score  threshold  pred_start  \n",
       "0     0.001369   0.002255        True  \n",
       "1     0.000000   0.002255       False  \n",
       "2     0.000203   0.002255       False  \n",
       "3     0.001102   0.002255       False  \n",
       "4     0.002383   0.002255        True  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_df, seg_idxs = _get_preds(learn, inf_df, threshold_std_coeff=1.0)\n",
    "\n",
    "print(seg_idxs[:10])\n",
    "print(len(preds_df))\n",
    "preds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del learn\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class TopicSegmentationModelTrainer(training.ModelTrainer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        experiment_name,\n",
    "        train_config: TopicSegmentationConfig,\n",
    "        data_path=\"data\",\n",
    "        model_output_path=\"models\",\n",
    "        log_output_path=\"logs\",\n",
    "        log_preds=False,\n",
    "        log_n_preds=None,\n",
    "        use_wandb=False,\n",
    "        verbose=False,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            task=\"topic_segmentation\",\n",
    "            experiment_name=experiment_name,\n",
    "            train_config=train_config,\n",
    "            data_path=data_path,\n",
    "            model_output_path=model_output_path,\n",
    "            log_output_path=log_output_path,\n",
    "            log_preds=log_preds,\n",
    "            log_n_preds=log_n_preds,\n",
    "            use_wandb=use_wandb,\n",
    "            verbose=verbose,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "    def get_training_data(self, on_the_fly=False, split_type=\"cross_validation\"):\n",
    "        return _get_training_data(\n",
    "            cfg=self.train_config, data_dir=self.data_path, on_the_fly=on_the_fly, split_type=split_type\n",
    "        )\n",
    "\n",
    "    def load_learner_or_model(self, model_learner_fpath: str | Path = None, device=\"cpu\", mode=\"eval\"):\n",
    "        if model_learner_fpath is None:\n",
    "            model_learner_fpath = f\"{self.model_output_path}/{self.experiment_name}.pkl\"\n",
    "\n",
    "        learn = load_learner(model_learner_fpath, cpu=device == \"cpu\")\n",
    "        learn.model = learn.model.to(device)\n",
    "        learn.dls = learn.dls.to(device)\n",
    "\n",
    "        if mode == \"eval\":\n",
    "            learn.model = learn.model.eval()\n",
    "        else:\n",
    "            learn.model = learn.model.train()\n",
    "\n",
    "        return learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "@patch\n",
    "def train(self: TopicSegmentationModelTrainer, sweep_config: dict = None):\n",
    "    # setup\n",
    "    start = time.time()\n",
    "    yyyymmddHm = datetime.today().strftime(\"%Y%m%d_%H%m\")\n",
    "    seed = self.train_config.random_seed\n",
    "\n",
    "    # --- step 0: init the WANDB run if logging to wandb and update the training config from the sweep config if doing a sweep\n",
    "    is_sweep = True if sweep_config is not None else False\n",
    "\n",
    "    if self.use_wandb:\n",
    "        run = self.init_wandb_run(is_sweep)\n",
    "\n",
    "    if is_sweep:\n",
    "        self.update_train_config_from_sweep_params(sweep_config[\"parameters\"])\n",
    "\n",
    "    # --- BEGIN TRAINING ---\n",
    "    if self.verbose:\n",
    "        print(f\"Experiment: {self.experiment_name}\")\n",
    "        print(f\"Training config: f{self.get_train_config_props()}\")\n",
    "\n",
    "    # --- step 1: get our TRAINING DATA ---\n",
    "    if self.verbose:\n",
    "        print(\"Preparing training data ...\")\n",
    "\n",
    "    df, trn_idxs, val_idxs, raw_df = self.get_training_data()\n",
    "\n",
    "    # --- step 2: get our HF OBJECTS ---\n",
    "    if self.verbose:\n",
    "        print(\"Building HF objects ...\")\n",
    "\n",
    "    hf_arch, hf_config, hf_tokenizer, hf_model = _get_task_hf_objects(self.train_config)\n",
    "\n",
    "    # --- step 3: DATALOADERS ---\n",
    "    if self.verbose:\n",
    "        print(\"Building DataLoaders ...\")\n",
    "\n",
    "    dls = _get_dls(self.train_config, df, hf_arch, hf_config, hf_tokenizer, hf_model, val_idxs_or_fold=val_idxs)\n",
    "\n",
    "    # --- step 4: LEARNER ---\n",
    "    if self.verbose:\n",
    "        print(\"Building Learner ...\")\n",
    "\n",
    "    learn = _get_learner(self.train_config, dls, hf_config, hf_model, learner_path=self.model_output_path)\n",
    "\n",
    "    # add any learner callbacks req. by the `ModelTrainer`\n",
    "    if self.use_wandb and not is_sweep:\n",
    "        learn.add_cb(WandbCallback(log_preds=False))\n",
    "\n",
    "    # add any fit callbacks req. by the `ModelTrainer`\n",
    "    fit_cbs = []\n",
    "    if self.train_config.max_grad_norm:\n",
    "        fit_cbs.append(GradientClip(max_norm=self.train_config.max_grad_norm))\n",
    "\n",
    "    if self.train_config.include_gradient_checkpointing:\n",
    "        fit_cbs.append(GradientCheckpointing())\n",
    "\n",
    "    if self.train_config.save_best_model:\n",
    "        fit_cbs.append(\n",
    "            SaveModelCallback(\n",
    "                monitor=\"valid_loss\",\n",
    "                comp=np.less,\n",
    "                fname=f\"temp_best_loss_{self.task}_{self.experiment_name}\",\n",
    "                reset_on_fit=False,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # --- step 4: TRAIN ---\n",
    "    if self.verbose:\n",
    "        print(\"Training ...\")\n",
    "\n",
    "    if self.train_config.n_frozen_epochs > 0:\n",
    "        if self.train_config.random_seed and not self.train_config.only_seed_splits:\n",
    "            set_seed(self.train_config.random_seed)\n",
    "\n",
    "        learn.fit_one_cycle(self.train_config.n_frozen_epochs, lr_max=self.train_config.frozen_lr, cbs=fit_cbs)\n",
    "\n",
    "    if self.train_config.n_unfrozen_epochs > 0:\n",
    "        learn.unfreeze()\n",
    "\n",
    "        if self.train_config.random_seed and not self.train_config.only_seed_splits:\n",
    "            set_seed(self.train_config.random_seed)\n",
    "\n",
    "        learn.fit_one_cycle(\n",
    "            self.train_config.n_unfrozen_epochs,\n",
    "            lr_max=slice(self.train_config.unfrozen_lr_min, self.train_config.unfrozen_lr_max),\n",
    "            cbs=fit_cbs,\n",
    "        )\n",
    "\n",
    "    end = time.time()\n",
    "    # --- END TRAINING ---\n",
    "\n",
    "    # grab the final results\n",
    "    res = learn.validate()\n",
    "\n",
    "    if not is_sweep:\n",
    "        # --- step 5: LOG RESULTS ---\n",
    "        if self.verbose:\n",
    "            print(\"Logging results ...\")\n",
    "\n",
    "        # 5a: log high level results (metrics, loss, training configuration)\n",
    "        train_config_df = pd.DataFrame(\n",
    "            [self.get_train_config_props()], columns=[k for k in self.get_train_config_props().keys()]\n",
    "        )\n",
    "        metrics_df = pd.DataFrame([res], columns=learn.recorder.metric_names[2:-1])\n",
    "\n",
    "        results_df = pd.concat([train_config_df, metrics_df], axis=1)\n",
    "        results_df[\"time\"] = end - start\n",
    "        results_df.to_csv(\n",
    "            f\"{self.log_output_path}/{self.task}_{self.experiment_name}_{yyyymmddHm}_results.csv\", index=None\n",
    "        )\n",
    "\n",
    "        # 5b: log actual predictions for the validation set\n",
    "        if self.log_preds:\n",
    "            val_course_titles = df.iloc[val_idxs][\"course_title\"].unique().tolist()\n",
    "            preds_df = _get_validation_preds(\n",
    "                hf_model,\n",
    "                hf_tokenizer,\n",
    "                raw_df,\n",
    "                val_course_titles[: self.log_n_preds],\n",
    "                batch_size=learn.dls[1].bs,\n",
    "                threshold_std_coeff=1.0,\n",
    "                verbose=self.verbose,\n",
    "            )\n",
    "            preds_df.to_csv(\n",
    "                f\"{self.log_output_path}/{self.task}_{self.experiment_name}_{yyyymmddHm}_preds.csv\", index=None\n",
    "            )\n",
    "\n",
    "            if self.use_wandb:\n",
    "                wandb.run.summary[\"valid_loss\"] = results_df.iloc[0][\"valid_loss\"]\n",
    "                wandb.run.summary[\"topic_seg_f1_score\"] = results_df.iloc[0][\"topic_seg_f1_score\"]\n",
    "\n",
    "                table = wandb.Table(data=preds_df)\n",
    "                wandb.log({\"Prediction_Samples\": table})\n",
    "\n",
    "                wandb.run.summary[\"state\"] = \"completed\"\n",
    "\n",
    "        # --- step 5: SAVE MODEL (except when tuning) ---\n",
    "        if self.verbose:\n",
    "            print(\"Saving model ...\")\n",
    "\n",
    "        learn.export(self.model_output_path / f\"{self.task}_{self.experiment_name}.pkl\")\n",
    "    else:\n",
    "        params_to_log_d = {m_name: m_val for m_name, m_val in zip(learn.recorder.metric_names[2:-1], res)}\n",
    "        wandb.log(params_to_log_d)\n",
    "\n",
    "    # clean up\n",
    "    super(self.__class__, self).train(sweep_config)\n",
    "\n",
    "    del learn, dls, hf_model, hf_tokenizer, hf_config\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    if self.verbose:\n",
    "        print(\"End training\")\n",
    "\n",
    "    if not is_sweep:\n",
    "        return results_df, raw_df, df, val_idxs\n",
    "    else:\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example training code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mohmeow\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mohmeow\u001b[0m (\u001b[33mcourse-copilot\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>../logs/wandb/run-20221010_131156-mz9oyjue</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/course-copilot/course-copilot-ml-topic_segmentation/runs/mz9oyjue\" target=\"_blank\">tough-eon-1</a></strong> to <a href=\"https://wandb.ai/course-copilot/course-copilot-ml-topic_segmentation\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment: test_topic_segmentation\n",
      "Training config: f{'accum': None, 'adam_beta2': 0.99, 'adam_eps': 1e-07, 'batch_size': 8, 'custom_model_kwargs': {'p': 0.1, 'dropout_cls': <class 'torch.nn.modules.dropout.Dropout'>}, 'frozen_lr': 0, 'hf_config_kwargs': {'num_labels': 2}, 'hf_model_checkpoint': 'microsoft/deberta-v3-small', 'hf_model_cls': 'AutoModelForSequenceClassification', 'hf_model_kwargs': {}, 'hf_tokenizer_kwargs': {}, 'include_gradient_checkpointing': False, 'include_labels': False, 'lower_case': True, 'max_grad_norm': None, 'max_length': True, 'n_frozen_epochs': 0, 'n_unfrozen_epochs': 2, 'new_special_tokens': None, 'one_cycle_moms_end': 0.8, 'one_cycle_moms_min': 0.7, 'one_cycle_moms_start': 0.8, 'only_seed_splits': True, 'preprocess_strategy': None, 'random_seed': 2022, 'save_best_model': True, 'tok_kwargs': {}, 'training_subset': 0.25, 'truncation_strategy': True, 'unfrozen_lr_max': 0.001, 'unfrozen_lr_min': 1e-05, 'use_adjacent_neg_prob': 0.5, 'use_fp16': True, 'use_next_pos_prob': 0.75, 'val_pct': 0.25, 'weight_decay': 0.0}\n",
      "Preparing training data ...\n",
      "Building HF objects ...\n",
      "Building DataLoaders ...\n",
      "Building Learner ...\n",
      "Training ...\n",
      "Could not gather input dimensions\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>topic_seg_f1_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.462488</td>\n",
       "      <td>0.582567</td>\n",
       "      <td>0.768724</td>\n",
       "      <td>01:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.384275</td>\n",
       "      <td>0.571569</td>\n",
       "      <td>0.759671</td>\n",
       "      <td>01:28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with valid_loss value: 0.5825673341751099.\n",
      "Better model found at epoch 1 with valid_loss value: 0.5715688467025757.\n",
      "Could not gather input dimensions\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging results ...\n",
      "Getting predictions for validatation set ...\n",
      "processing markowskyart - begginer drawing course: 1\n",
      "processing markowskyart - begginer drawing course: 2\n",
      "processing markowskyart - begginer drawing course: 3\n",
      "processing markowskyart - begginer drawing course: 4\n",
      "processing markowskyart - begginer drawing course: 5\n",
      "processing cc - how to invest in stocks: 1\n",
      "Saving model ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d8f8bd2e7754791b3a970ab472903f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='142.475 MB of 149.505 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.95…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>eps_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eps_1</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr_0</td><td>▁▁▂▃▄▅▆▇▇██████▇▇▇▇▆▆▆▆▅▅▄▄▄▃▃▃▂▂▂▂▁▁▁▁▁</td></tr><tr><td>lr_1</td><td>▁▁▂▃▄▅▆▇▇██████▇▇▇▇▆▆▆▆▅▅▄▄▄▃▃▃▂▂▂▂▁▁▁▁▁</td></tr><tr><td>mom_0</td><td>██▇▇▅▄▃▂▂▁▁▁▁▁▁▂▂▂▂▃▃▃▃▄▄▅▅▅▆▆▆▇▇▇▇█████</td></tr><tr><td>mom_1</td><td>██▇▇▅▄▃▂▂▁▁▁▁▁▁▂▂▂▂▃▃▃▃▄▄▅▅▅▆▆▆▇▇▇▇█████</td></tr><tr><td>raw_loss</td><td>███▇▇▅█▃▄▂▂█▇▇▃▃▁▂▃▁▁▄▅▁▂▃▄▃▅▃▆▂▃▄▃▃▁▆▅▆</td></tr><tr><td>sqr_mom_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>sqr_mom_1</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>topic_seg_f1_score</td><td>█▁</td></tr><tr><td>train_loss</td><td>█████▇▆▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▂▂▂▂▂▁▁▁▁▂▂▂▂▂</td></tr><tr><td>train_samples_per_sec</td><td>▁▄▅█▂▅█▄▆▄▇▅▄█▅█▅▃▇▇▃▄▃▅▅▃▄▃▄▅▃▅▆▆▇▅▅▆▂▂</td></tr><tr><td>valid_loss</td><td>█▁</td></tr><tr><td>wd_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>wd_1</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>2</td></tr><tr><td>eps_0</td><td>0.0</td></tr><tr><td>eps_1</td><td>0.0</td></tr><tr><td>lr_0</td><td>0.0</td></tr><tr><td>lr_1</td><td>0.0</td></tr><tr><td>mom_0</td><td>0.8</td></tr><tr><td>mom_1</td><td>0.8</td></tr><tr><td>raw_loss</td><td>0.19263</td></tr><tr><td>sqr_mom_0</td><td>0.99</td></tr><tr><td>sqr_mom_1</td><td>0.99</td></tr><tr><td>state</td><td>completed</td></tr><tr><td>topic_seg_f1_score</td><td>0.75802</td></tr><tr><td>train_loss</td><td>0.38427</td></tr><tr><td>train_samples_per_sec</td><td>28.17576</td></tr><tr><td>valid_loss</td><td>0.5866</td></tr><tr><td>wd_0</td><td>0.0</td></tr><tr><td>wd_1</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">tough-eon-1</strong>: <a href=\"https://wandb.ai/course-copilot/course-copilot-ml-topic_segmentation/runs/mz9oyjue\" target=\"_blank\">https://wandb.ai/course-copilot/course-copilot-ml-topic_segmentation/runs/mz9oyjue</a><br/>Synced 6 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>../logs/wandb/run-20221010_131156-mz9oyjue/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End training\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accum</th>\n",
       "      <th>adam_beta2</th>\n",
       "      <th>adam_eps</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>custom_model_kwargs</th>\n",
       "      <th>frozen_lr</th>\n",
       "      <th>hf_config_kwargs</th>\n",
       "      <th>hf_model_checkpoint</th>\n",
       "      <th>hf_model_cls</th>\n",
       "      <th>hf_model_kwargs</th>\n",
       "      <th>...</th>\n",
       "      <th>unfrozen_lr_max</th>\n",
       "      <th>unfrozen_lr_min</th>\n",
       "      <th>use_adjacent_neg_prob</th>\n",
       "      <th>use_fp16</th>\n",
       "      <th>use_next_pos_prob</th>\n",
       "      <th>val_pct</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>topic_seg_f1_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>8</td>\n",
       "      <td>{'p': 0.1, 'dropout_cls': &lt;class 'torch.nn.modules.dropout.Dropout'&gt;}</td>\n",
       "      <td>0</td>\n",
       "      <td>{'num_labels': 2}</td>\n",
       "      <td>microsoft/deberta-v3-small</td>\n",
       "      <td>AutoModelForSequenceClassification</td>\n",
       "      <td>{}</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.586599</td>\n",
       "      <td>0.758025</td>\n",
       "      <td>202.285863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  accum  adam_beta2      adam_eps  batch_size  \\\n",
       "0  None        0.99  1.000000e-07           8   \n",
       "\n",
       "                                                     custom_model_kwargs  \\\n",
       "0  {'p': 0.1, 'dropout_cls': <class 'torch.nn.modules.dropout.Dropout'>}   \n",
       "\n",
       "   frozen_lr   hf_config_kwargs         hf_model_checkpoint  \\\n",
       "0          0  {'num_labels': 2}  microsoft/deberta-v3-small   \n",
       "\n",
       "                         hf_model_cls hf_model_kwargs  ... unfrozen_lr_max  \\\n",
       "0  AutoModelForSequenceClassification              {}  ...           0.001   \n",
       "\n",
       "   unfrozen_lr_min  use_adjacent_neg_prob  use_fp16 use_next_pos_prob  \\\n",
       "0          0.00001                    0.5      True              0.75   \n",
       "\n",
       "   val_pct  weight_decay  valid_loss topic_seg_f1_score        time  \n",
       "0     0.25           0.0    0.586599           0.758025  202.285863  \n",
       "\n",
       "[1 rows x 39 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = TopicSegmentationModelTrainer(\n",
    "    experiment_name=\"test_topic_segmentation\",\n",
    "    train_config=ExampleCFG,\n",
    "    data_path=\"../data\",\n",
    "    model_output_path=\"../models\",\n",
    "    log_output_path=\"../logs\",\n",
    "    log_preds=True,\n",
    "    log_n_preds=2,\n",
    "    use_wandb=True,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "results_df, raw_df, train_df, train_val_idxs = trainer.train()\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `get_preds`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "@patch\n",
    "def get_preds(self: TopicSegmentationModelTrainer, model_or_learner, data, **kwargs):\n",
    "    threshold_std_coeff = kwargs.get(\"threshold_std_coeff\", 1.0)\n",
    "\n",
    "    preds_df, pred_seg_idxs = _get_preds(model_or_learner, data, threshold_std_coeff=threshold_std_coeff)\n",
    "    return preds_df, pred_seg_idxs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example inference code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 16, 20, 23, 26, 30, 44, 47, 54]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>transcript</th>\n",
       "      <th>depth_score</th>\n",
       "      <th>threshold</th>\n",
       "      <th>pred_start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Using Huggingface</td>\n",
       "      <td>Hi everybody, and welcome to Practical Deep Learning for Coders Lesson Four, which I think</td>\n",
       "      <td>0.001369</td>\n",
       "      <td>0.002255</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Using Huggingface</td>\n",
       "      <td>is the lesson that a lot of the regulars in the community have been most excited about,</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002255</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Using Huggingface</td>\n",
       "      <td>because it's where we're gonna get some totally new material — totally new topic, we've</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.002255</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Using Huggingface</td>\n",
       "      <td>never covered before. We're going to cover natural language processing (NLP), and you'll</td>\n",
       "      <td>0.001102</td>\n",
       "      <td>0.002255</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Using Huggingface</td>\n",
       "      <td>find there, there is indeed a chapter about that in the book, but we're going to do it in a totally different way to how it's done in the book. In the book we do NLP using the</td>\n",
       "      <td>0.002383</td>\n",
       "      <td>0.002255</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               topic  \\\n",
       "0  Using Huggingface   \n",
       "1  Using Huggingface   \n",
       "2  Using Huggingface   \n",
       "3  Using Huggingface   \n",
       "4  Using Huggingface   \n",
       "\n",
       "                                                                                                                                                                        transcript  \\\n",
       "0                                                                                       Hi everybody, and welcome to Practical Deep Learning for Coders Lesson Four, which I think   \n",
       "1                                                                                          is the lesson that a lot of the regulars in the community have been most excited about,   \n",
       "2                                                                                          because it's where we're gonna get some totally new material — totally new topic, we've   \n",
       "3                                                                                         never covered before. We're going to cover natural language processing (NLP), and you'll   \n",
       "4  find there, there is indeed a chapter about that in the book, but we're going to do it in a totally different way to how it's done in the book. In the book we do NLP using the   \n",
       "\n",
       "   depth_score  threshold  pred_start  \n",
       "0     0.001369   0.002255        True  \n",
       "1     0.000000   0.002255       False  \n",
       "2     0.000203   0.002255       False  \n",
       "3     0.001102   0.002255       False  \n",
       "4     0.002383   0.002255        True  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = TopicSegmentationModelTrainer(\n",
    "    \"test_topic_segmentation\", ExampleCFG, \"../data\", \"../models\", \"../logs\", verbose=True\n",
    ")\n",
    "# results_df, train_df, val_idxs = trainer.train()\n",
    "inf_learn = trainer.load_learner_or_model(device=\"cpu\")\n",
    "preds_df, pred_topic_idxs = trainer.get_preds(inf_learn, inf_df[[\"topic\", \"transcript\"]].copy())\n",
    "\n",
    "# cleanup resources\n",
    "del inf_learn\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "# shows final results\n",
    "print(pred_topic_idxs[:10])\n",
    "preds_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `tune`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "default_sweep_config = {\n",
    "    \"method\": \"random\",  # grid | random | bayes\n",
    "    \"name\": \"topic_segmentation_sweep\",\n",
    "    \"metric\": {\"goal\": \"minimize\", \"name\": \"valid_loss\"},\n",
    "    \"parameters\": {\n",
    "        \"unfrozen_lr_min\": {\"max\": 1e-4, \"min\": 1e-6},\n",
    "        \"unfrozen_lr_max\": {\"max\": 1e-3, \"min\": 1e-4},\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 2nqt78ll\n",
      "Sweep URL: https://wandb.ai/course-copilot/course-copilot-ml-topic_segmentation/sweeps/2nqt78ll\n"
     ]
    }
   ],
   "source": [
    "trainer = TopicSegmentationModelTrainer(\n",
    "    experiment_name=\"test_topic_segmentation\",\n",
    "    train_config=ExampleCFG,\n",
    "    data_path=\"../data\",\n",
    "    model_output_path=\"../models\",\n",
    "    log_output_path=\"../logs\",\n",
    "    log_preds=False,\n",
    "    log_n_preds=None,\n",
    "    use_wandb=True,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "sweep_id = trainer.configure_sweep(sweep_config=default_sweep_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wvxi3n4n with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunfrozen_lr_max: 0.0002964642653616338\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunfrozen_lr_min: 8.666728243468805e-05\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>../logs/wandb/run-20221010_131806-wvxi3n4n</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/course-copilot/course-copilot-ml-topic_segmentation/runs/wvxi3n4n\" target=\"_blank\">earthy-sweep-1</a></strong> to <a href=\"https://wandb.ai/course-copilot/course-copilot-ml-topic_segmentation\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/course-copilot/course-copilot-ml-topic_segmentation/sweeps/2nqt78ll\" target=\"_blank\">https://wandb.ai/course-copilot/course-copilot-ml-topic_segmentation/sweeps/2nqt78ll</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment: test_topic_segmentation\n",
      "Training config: f{'accum': None, 'adam_beta2': 0.99, 'adam_eps': 1e-07, 'batch_size': 8, 'custom_model_kwargs': {'p': 0.1, 'dropout_cls': <class 'torch.nn.modules.dropout.Dropout'>}, 'frozen_lr': 0, 'hf_config_kwargs': {'num_labels': 2}, 'hf_model_checkpoint': 'microsoft/deberta-v3-small', 'hf_model_cls': 'AutoModelForSequenceClassification', 'hf_model_kwargs': {}, 'hf_tokenizer_kwargs': {}, 'include_gradient_checkpointing': False, 'include_labels': False, 'lower_case': True, 'max_grad_norm': None, 'max_length': True, 'n_frozen_epochs': 0, 'n_unfrozen_epochs': 2, 'new_special_tokens': None, 'one_cycle_moms_end': 0.8, 'one_cycle_moms_min': 0.7, 'one_cycle_moms_start': 0.8, 'only_seed_splits': True, 'preprocess_strategy': None, 'random_seed': 2022, 'save_best_model': True, 'tok_kwargs': {}, 'training_subset': 0.25, 'truncation_strategy': True, 'unfrozen_lr_max': 0.0002964642653616338, 'unfrozen_lr_min': 8.666728243468805e-05, 'use_adjacent_neg_prob': 0.5, 'use_fp16': True, 'use_next_pos_prob': 0.75, 'val_pct': 0.25, 'weight_decay': 0.0}\n",
      "Preparing training data ...\n",
      "Building HF objects ...\n",
      "Building DataLoaders ...\n",
      "Building Learner ...\n",
      "Training ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>topic_seg_f1_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.434889</td>\n",
       "      <td>0.607325</td>\n",
       "      <td>0.763786</td>\n",
       "      <td>01:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.297782</td>\n",
       "      <td>0.579850</td>\n",
       "      <td>0.768724</td>\n",
       "      <td>01:27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with valid_loss value: 0.6073254942893982.\n",
      "Better model found at epoch 1 with valid_loss value: 0.5798501968383789.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End training\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee1a303a10224751b82344a37f590134",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>topic_seg_f1_score</td><td>▁</td></tr><tr><td>valid_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>topic_seg_f1_score</td><td>0.77366</td></tr><tr><td>valid_loss</td><td>0.58265</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">earthy-sweep-1</strong>: <a href=\"https://wandb.ai/course-copilot/course-copilot-ml-topic_segmentation/runs/wvxi3n4n\" target=\"_blank\">https://wandb.ai/course-copilot/course-copilot-ml-topic_segmentation/runs/wvxi3n4n</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>../logs/wandb/run-20221010_131806-wvxi3n4n/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: l5r5816d with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunfrozen_lr_max: 0.0002667648067607438\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunfrozen_lr_min: 4.856146061559808e-05\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>../logs/wandb/run-20221010_132215-l5r5816d</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/course-copilot/course-copilot-ml-topic_segmentation/runs/l5r5816d\" target=\"_blank\">rich-sweep-2</a></strong> to <a href=\"https://wandb.ai/course-copilot/course-copilot-ml-topic_segmentation\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/course-copilot/course-copilot-ml-topic_segmentation/sweeps/2nqt78ll\" target=\"_blank\">https://wandb.ai/course-copilot/course-copilot-ml-topic_segmentation/sweeps/2nqt78ll</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment: test_topic_segmentation\n",
      "Training config: f{'accum': None, 'adam_beta2': 0.99, 'adam_eps': 1e-07, 'batch_size': 8, 'custom_model_kwargs': {'p': 0.1, 'dropout_cls': <class 'torch.nn.modules.dropout.Dropout'>}, 'frozen_lr': 0, 'hf_config_kwargs': {'num_labels': 2}, 'hf_model_checkpoint': 'microsoft/deberta-v3-small', 'hf_model_cls': 'AutoModelForSequenceClassification', 'hf_model_kwargs': {}, 'hf_tokenizer_kwargs': {}, 'include_gradient_checkpointing': False, 'include_labels': False, 'lower_case': True, 'max_grad_norm': None, 'max_length': True, 'n_frozen_epochs': 0, 'n_unfrozen_epochs': 2, 'new_special_tokens': None, 'one_cycle_moms_end': 0.8, 'one_cycle_moms_min': 0.7, 'one_cycle_moms_start': 0.8, 'only_seed_splits': True, 'preprocess_strategy': None, 'random_seed': 2022, 'save_best_model': True, 'tok_kwargs': {}, 'training_subset': 0.25, 'truncation_strategy': True, 'unfrozen_lr_max': 0.0002667648067607438, 'unfrozen_lr_min': 4.856146061559808e-05, 'use_adjacent_neg_prob': 0.5, 'use_fp16': True, 'use_next_pos_prob': 0.75, 'val_pct': 0.25, 'weight_decay': 0.0}\n",
      "Preparing training data ...\n",
      "Building HF objects ...\n",
      "Building DataLoaders ...\n",
      "Building Learner ...\n",
      "Training ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>topic_seg_f1_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.395206</td>\n",
       "      <td>0.567065</td>\n",
       "      <td>0.772840</td>\n",
       "      <td>01:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.289024</td>\n",
       "      <td>0.579308</td>\n",
       "      <td>0.767901</td>\n",
       "      <td>01:25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with valid_loss value: 0.5670649409294128.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End training\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2c69e77c8414bb49870bc5410a40344",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>topic_seg_f1_score</td><td>▁</td></tr><tr><td>valid_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>topic_seg_f1_score</td><td>0.75802</td></tr><tr><td>valid_loss</td><td>0.59401</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">rich-sweep-2</strong>: <a href=\"https://wandb.ai/course-copilot/course-copilot-ml-topic_segmentation/runs/l5r5816d\" target=\"_blank\">https://wandb.ai/course-copilot/course-copilot-ml-topic_segmentation/runs/l5r5816d</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>../logs/wandb/run-20221010_132215-l5r5816d/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 3x9bljp5 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunfrozen_lr_max: 0.00014688870658243158\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunfrozen_lr_min: 9.855246064537064e-05\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>../logs/wandb/run-20221010_132551-3x9bljp5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/course-copilot/course-copilot-ml-topic_segmentation/runs/3x9bljp5\" target=\"_blank\">true-sweep-3</a></strong> to <a href=\"https://wandb.ai/course-copilot/course-copilot-ml-topic_segmentation\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/course-copilot/course-copilot-ml-topic_segmentation/sweeps/2nqt78ll\" target=\"_blank\">https://wandb.ai/course-copilot/course-copilot-ml-topic_segmentation/sweeps/2nqt78ll</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment: test_topic_segmentation\n",
      "Training config: f{'accum': None, 'adam_beta2': 0.99, 'adam_eps': 1e-07, 'batch_size': 8, 'custom_model_kwargs': {'p': 0.1, 'dropout_cls': <class 'torch.nn.modules.dropout.Dropout'>}, 'frozen_lr': 0, 'hf_config_kwargs': {'num_labels': 2}, 'hf_model_checkpoint': 'microsoft/deberta-v3-small', 'hf_model_cls': 'AutoModelForSequenceClassification', 'hf_model_kwargs': {}, 'hf_tokenizer_kwargs': {}, 'include_gradient_checkpointing': False, 'include_labels': False, 'lower_case': True, 'max_grad_norm': None, 'max_length': True, 'n_frozen_epochs': 0, 'n_unfrozen_epochs': 2, 'new_special_tokens': None, 'one_cycle_moms_end': 0.8, 'one_cycle_moms_min': 0.7, 'one_cycle_moms_start': 0.8, 'only_seed_splits': True, 'preprocess_strategy': None, 'random_seed': 2022, 'save_best_model': True, 'tok_kwargs': {}, 'training_subset': 0.25, 'truncation_strategy': True, 'unfrozen_lr_max': 0.00014688870658243158, 'unfrozen_lr_min': 9.855246064537064e-05, 'use_adjacent_neg_prob': 0.5, 'use_fp16': True, 'use_next_pos_prob': 0.75, 'val_pct': 0.25, 'weight_decay': 0.0}\n",
      "Preparing training data ...\n",
      "Building HF objects ...\n",
      "Building DataLoaders ...\n",
      "Building Learner ...\n",
      "Training ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>topic_seg_f1_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.457043</td>\n",
       "      <td>0.659170</td>\n",
       "      <td>0.729218</td>\n",
       "      <td>01:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.266419</td>\n",
       "      <td>0.602764</td>\n",
       "      <td>0.770370</td>\n",
       "      <td>01:25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with valid_loss value: 0.6591702103614807.\n",
      "Better model found at epoch 1 with valid_loss value: 0.6027644276618958.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End training\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5752e7d79b9446f868e1fd2efc38e2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>topic_seg_f1_score</td><td>▁</td></tr><tr><td>valid_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>topic_seg_f1_score</td><td>0.75473</td></tr><tr><td>valid_loss</td><td>0.62178</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">true-sweep-3</strong>: <a href=\"https://wandb.ai/course-copilot/course-copilot-ml-topic_segmentation/runs/3x9bljp5\" target=\"_blank\">https://wandb.ai/course-copilot/course-copilot-ml-topic_segmentation/runs/3x9bljp5</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>../logs/wandb/run-20221010_132551-3x9bljp5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: xf8n2hrc with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunfrozen_lr_max: 0.0008400970402462487\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunfrozen_lr_min: 8.196114939228642e-05\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>../logs/wandb/run-20221010_132924-xf8n2hrc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/course-copilot/course-copilot-ml-topic_segmentation/runs/xf8n2hrc\" target=\"_blank\">atomic-sweep-4</a></strong> to <a href=\"https://wandb.ai/course-copilot/course-copilot-ml-topic_segmentation\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/course-copilot/course-copilot-ml-topic_segmentation/sweeps/2nqt78ll\" target=\"_blank\">https://wandb.ai/course-copilot/course-copilot-ml-topic_segmentation/sweeps/2nqt78ll</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment: test_topic_segmentation\n",
      "Training config: f{'accum': None, 'adam_beta2': 0.99, 'adam_eps': 1e-07, 'batch_size': 8, 'custom_model_kwargs': {'p': 0.1, 'dropout_cls': <class 'torch.nn.modules.dropout.Dropout'>}, 'frozen_lr': 0, 'hf_config_kwargs': {'num_labels': 2}, 'hf_model_checkpoint': 'microsoft/deberta-v3-small', 'hf_model_cls': 'AutoModelForSequenceClassification', 'hf_model_kwargs': {}, 'hf_tokenizer_kwargs': {}, 'include_gradient_checkpointing': False, 'include_labels': False, 'lower_case': True, 'max_grad_norm': None, 'max_length': True, 'n_frozen_epochs': 0, 'n_unfrozen_epochs': 2, 'new_special_tokens': None, 'one_cycle_moms_end': 0.8, 'one_cycle_moms_min': 0.7, 'one_cycle_moms_start': 0.8, 'only_seed_splits': True, 'preprocess_strategy': None, 'random_seed': 2022, 'save_best_model': True, 'tok_kwargs': {}, 'training_subset': 0.25, 'truncation_strategy': True, 'unfrozen_lr_max': 0.0008400970402462487, 'unfrozen_lr_min': 8.196114939228642e-05, 'use_adjacent_neg_prob': 0.5, 'use_fp16': True, 'use_next_pos_prob': 0.75, 'val_pct': 0.25, 'weight_decay': 0.0}\n",
      "Preparing training data ...\n",
      "Building HF objects ...\n",
      "Building DataLoaders ...\n",
      "Building Learner ...\n",
      "Training ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>topic_seg_f1_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.396438</td>\n",
       "      <td>0.553289</td>\n",
       "      <td>0.798354</td>\n",
       "      <td>01:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.272380</td>\n",
       "      <td>0.460504</td>\n",
       "      <td>0.811523</td>\n",
       "      <td>01:25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with valid_loss value: 0.5532887578010559.\n",
      "Better model found at epoch 1 with valid_loss value: 0.4605042636394501.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End training\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "223f45460ae442599815de30ca6959f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>topic_seg_f1_score</td><td>▁</td></tr><tr><td>valid_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>topic_seg_f1_score</td><td>0.80658</td></tr><tr><td>valid_loss</td><td>0.46773</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">atomic-sweep-4</strong>: <a href=\"https://wandb.ai/course-copilot/course-copilot-ml-topic_segmentation/runs/xf8n2hrc\" target=\"_blank\">https://wandb.ai/course-copilot/course-copilot-ml-topic_segmentation/runs/xf8n2hrc</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>../logs/wandb/run-20221010_132924-xf8n2hrc/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 6kb77a8z with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunfrozen_lr_max: 0.0006178585838591866\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tunfrozen_lr_min: 1.6556729698366223e-05\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>../logs/wandb/run-20221010_133257-6kb77a8z</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/course-copilot/course-copilot-ml-topic_segmentation/runs/6kb77a8z\" target=\"_blank\">splendid-sweep-5</a></strong> to <a href=\"https://wandb.ai/course-copilot/course-copilot-ml-topic_segmentation\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/course-copilot/course-copilot-ml-topic_segmentation/sweeps/2nqt78ll\" target=\"_blank\">https://wandb.ai/course-copilot/course-copilot-ml-topic_segmentation/sweeps/2nqt78ll</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment: test_topic_segmentation\n",
      "Training config: f{'accum': None, 'adam_beta2': 0.99, 'adam_eps': 1e-07, 'batch_size': 8, 'custom_model_kwargs': {'p': 0.1, 'dropout_cls': <class 'torch.nn.modules.dropout.Dropout'>}, 'frozen_lr': 0, 'hf_config_kwargs': {'num_labels': 2}, 'hf_model_checkpoint': 'microsoft/deberta-v3-small', 'hf_model_cls': 'AutoModelForSequenceClassification', 'hf_model_kwargs': {}, 'hf_tokenizer_kwargs': {}, 'include_gradient_checkpointing': False, 'include_labels': False, 'lower_case': True, 'max_grad_norm': None, 'max_length': True, 'n_frozen_epochs': 0, 'n_unfrozen_epochs': 2, 'new_special_tokens': None, 'one_cycle_moms_end': 0.8, 'one_cycle_moms_min': 0.7, 'one_cycle_moms_start': 0.8, 'only_seed_splits': True, 'preprocess_strategy': None, 'random_seed': 2022, 'save_best_model': True, 'tok_kwargs': {}, 'training_subset': 0.25, 'truncation_strategy': True, 'unfrozen_lr_max': 0.0006178585838591866, 'unfrozen_lr_min': 1.6556729698366223e-05, 'use_adjacent_neg_prob': 0.5, 'use_fp16': True, 'use_next_pos_prob': 0.75, 'val_pct': 0.25, 'weight_decay': 0.0}\n",
      "Preparing training data ...\n",
      "Building HF objects ...\n",
      "Building DataLoaders ...\n",
      "Building Learner ...\n",
      "Training ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>topic_seg_f1_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.423982</td>\n",
       "      <td>0.563763</td>\n",
       "      <td>0.781893</td>\n",
       "      <td>01:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.333860</td>\n",
       "      <td>0.548688</td>\n",
       "      <td>0.783539</td>\n",
       "      <td>01:26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with valid_loss value: 0.5637626647949219.\n",
      "Better model found at epoch 1 with valid_loss value: 0.5486881136894226.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End training\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf69bb610b304d5d8d23a4836641f84a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>topic_seg_f1_score</td><td>▁</td></tr><tr><td>valid_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>topic_seg_f1_score</td><td>0.78354</td></tr><tr><td>valid_loss</td><td>0.56118</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">splendid-sweep-5</strong>: <a href=\"https://wandb.ai/course-copilot/course-copilot-ml-topic_segmentation/runs/6kb77a8z\" target=\"_blank\">https://wandb.ai/course-copilot/course-copilot-ml-topic_segmentation/runs/6kb77a8z</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>../logs/wandb/run-20221010_133257-6kb77a8z/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.agent(sweep_id, function=partial(trainer.train, sweep_config=default_sweep_config), count=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `tune_threshold`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('fsdl_2022_course_project')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
